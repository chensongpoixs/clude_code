# å·¥å…·æ¨¡å—ä¼˜åŒ–åˆ†ææŠ¥å‘Š

> **åˆ›å»ºæ—¶é—´**: 2026-01-23  
> **åˆ†æç›®æ ‡**: å¯¹æ ‡ä¸šç•Œæœ€ä½³å®è·µï¼Œè¯†åˆ«é—®é¢˜ç‚¹ï¼Œæå‡º Token èŠ‚çœæ–¹æ¡ˆ

---

## ç›®å½•

1. [å½“å‰æ¶æ„åˆ†æ](#1-å½“å‰æ¶æ„åˆ†æ)
2. [ä¸šç•Œå¯¹æ ‡](#2-ä¸šç•Œå¯¹æ ‡)
3. [é—®é¢˜è¯Šæ–­](#3-é—®é¢˜è¯Šæ–­)
4. [Token èŠ‚çœæ–¹æ¡ˆ](#4-token-èŠ‚çœæ–¹æ¡ˆ)
5. [ä¼˜åŒ–å®ç°ç»†èŠ‚](#5-ä¼˜åŒ–å®ç°ç»†èŠ‚)
6. [å®æ–½ä¼˜å…ˆçº§](#6-å®æ–½ä¼˜å…ˆçº§)

---

## 1. å½“å‰æ¶æ„åˆ†æ

### 1.1 æ¨¡å—ç»“æ„

```
src/clude_code/tooling/
â”œâ”€â”€ local_tools.py          # LocalTools ç±»ï¼šå·¥å…·è°ƒç”¨å…¥å£
â”œâ”€â”€ tool_registry.py        # ToolRegistryï¼šå·¥å…·æ³¨å†Œä¸ç®¡ç†
â”œâ”€â”€ feedback.py             # summarize_tool_resultï¼šç»“æœæ‘˜è¦ä¸å‹ç¼©
â”œâ”€â”€ types.py                # ToolResultã€ToolError ç±»å‹å®šä¹‰
â”œâ”€â”€ tools/                  # å…·ä½“å·¥å…·å®ç°
â”‚   â”œâ”€â”€ read_file.py
â”‚   â”œâ”€â”€ grep.py
â”‚   â”œâ”€â”€ patching.py
â”‚   â””â”€â”€ ...
â””â”€â”€ ...

src/clude_code/orchestrator/agent_loop/
â””â”€â”€ tool_dispatch.py        # ToolSpec å®šä¹‰ + Handler æ˜ å°„ + dispatch_tool
```

### 1.2 å·¥å…·è°ƒç”¨æµç¨‹

```
LLM Output â†’ parse_tool_call â†’ dispatch_tool â†’ handler â†’ ToolResult
                                                            â”‚
                                                            â–¼
                                              summarize_tool_result (feedback.py)
                                                            â”‚
                                                            â–¼
                                              format_feedback_message â†’ LLM
```

### 1.3 å½“å‰å·¥å…·æ•°é‡

| ç±»åˆ« | å·¥å…· |
|------|------|
| æ–‡ä»¶æ“ä½œ | list_dir, read_file, write_file, apply_patch, undo_patch |
| æœç´¢ | grep, glob_file_search, search_semantic |
| æ‰§è¡Œ | run_cmd |
| ç½‘ç»œ | webfetch, websearch, codesearch |
| ä»»åŠ¡ç®¡ç† | todowrite, todoread, run_task, get_task_status |
| äº¤äº’ | display, question |
| å…¶ä»– | load_skill, get_weather, get_weather_forecast |

**æ€»è®¡**: çº¦ 20 ä¸ªå·¥å…·ï¼Œæ¯ä¸ªå·¥å…·çš„ ToolSpec å¹³å‡æ¶ˆè€— **150-300 tokens**ã€‚

---

## 2. ä¸šç•Œå¯¹æ ‡

### 2.1 Claude Codeï¼ˆAnthropicï¼‰

| ç‰¹æ€§ | Claude Code | å½“å‰é¡¹ç›® | å·®è· |
|------|-------------|---------|------|
| å·¥å…· Schema ç²¾ç®€ | âœ… æœ€å°åŒ–å¿…éœ€å‚æ•° | âš ï¸ å†—ä½™æè¿° | ä¸­ |
| åŠ¨æ€å·¥å…·åŠ è½½ | âœ… æŒ‰éœ€åŠ è½½ | âŒ å…¨é‡åŠ è½½ | é«˜ |
| ç»“æœå‹ç¼© | âœ… æ™ºèƒ½æ‘˜è¦ | âœ… å·²å®ç° | ä½ |
| å·¥å…·åˆ†ç»„ | âœ… æŒ‰è§’è‰²åˆ†ç»„ | âŒ æ‰å¹³åˆ—è¡¨ | ä¸­ |
| ç¼“å­˜æœºåˆ¶ | âœ… ç»“æœç¼“å­˜ | âš ï¸ éƒ¨åˆ† | ä¸­ |

### 2.2 Cursor

| ç‰¹æ€§ | Cursor | å½“å‰é¡¹ç›® | å·®è· |
|------|--------|---------|------|
| è¯­ä¹‰å·¥å…·é€‰æ‹© | âœ… æ ¹æ®ä»»åŠ¡æ¨è | âŒ å…¨é‡æš´éœ² | é«˜ |
| æ¸è¿›å¼åŠ è½½ | âœ… å…ˆç»™æ ¸å¿ƒå·¥å…· | âŒ ä¸€æ¬¡æ€§åŠ è½½ | é«˜ |
| å·¥å…·ä½¿ç”¨ç»Ÿè®¡ | âœ… çƒ­åº¦æ’åº | âœ… å·²å®ç° | ä½ |

### 2.3 OpenAI Function Calling

| ç‰¹æ€§ | OpenAI | å½“å‰é¡¹ç›® | å·®è· |
|------|--------|---------|------|
| Schema æ ¼å¼ | JSON Schema ç²¾ç®€ç‰ˆ | âœ… å…¼å®¹ | ä½ |
| å·¥å…·æ•°é‡å»ºè®® | â‰¤10 ä¸ª/è¯·æ±‚ | âš ï¸ 20 ä¸ª | é«˜ |
| æè¿°é•¿åº¦å»ºè®® | â‰¤100 å­—ç¬¦ | âš ï¸ 200+ å­—ç¬¦ | ä¸­ |

---

## 3. é—®é¢˜è¯Šæ–­

### 3.1 ğŸ”´ é«˜ä¼˜å…ˆçº§é—®é¢˜

#### P1: å·¥å…· Schema è¿‡äºå†—é•¿

**å½“å‰é—®é¢˜**:
- æ¯ä¸ª ToolSpec çš„ `description` å¹³å‡ 200+ å­—ç¬¦
- 20 ä¸ªå·¥å…·å…¨é‡æ³¨å…¥ System Prompt
- ä¼°ç®—æ¶ˆè€—: **3000-5000 tokens**

**ç¤ºä¾‹ï¼ˆå½“å‰ï¼‰**:
```python
description=(
    "ç”¨äºåœ¨å·¥ä½œåŒºå†…æŒ‰æ­£åˆ™æœç´¢æ–‡æœ¬å†…å®¹ï¼ˆGrep / Ripgrepï¼‰ã€‚æ”¯æŒ C/C++/Java ç­‰å¤šç§è¯­è¨€çš„è‡ªåŠ¨åç¼€åŒ¹é…ã€‚\n"
    "å¦‚æœä½ åœ¨å¯»æ‰¾ç‰¹å®šè¯­è¨€çš„å®šä¹‰ï¼ˆå¦‚ C++ ç±»æˆ– Java æ–¹æ³•ï¼‰ï¼ŒæŒ‡å®š 'language' å‚æ•°å°†æå¤§æé«˜å‡†ç¡®ç‡ã€‚"
)
# çº¦ 120 å­—ç¬¦ = ~40 tokens
```

**ä¸šç•Œæ ‡å‡†ï¼ˆClaude Codeï¼‰**:
```python
description="Search files with regex pattern"
# çº¦ 35 å­—ç¬¦ = ~10 tokens
```

**èŠ‚çœæ½œåŠ›**: æ¯ä¸ªå·¥å…·èŠ‚çœ 30 tokens Ã— 20 å·¥å…· = **600 tokens**

#### P2: å…¨é‡å·¥å…·æ³¨å…¥

**å½“å‰é—®é¢˜**:
- æ‰€æœ‰ 20 ä¸ªå·¥å…·åœ¨æ¯æ¬¡è¯·æ±‚éƒ½æ³¨å…¥ System Prompt
- ç”¨æˆ·ä»…è¯¢é—®"ä½ å¥½"æ—¶ä¹ŸåŠ è½½ grepã€apply_patch ç­‰å·¥å…·

**ä¸šç•Œåšæ³•ï¼ˆåŠ¨æ€å·¥å…·é›†ï¼‰**:
```
æ„å›¾: GENERAL_CHAT â†’ å·¥å…·é›†: [display]
æ„å›¾: CODE_ANALYSIS â†’ å·¥å…·é›†: [read_file, grep, search_semantic]
æ„å›¾: CODE_MODIFICATION â†’ å·¥å…·é›†: [read_file, grep, apply_patch, write_file]
```

**èŠ‚çœæ½œåŠ›**: æ ¹æ®æ„å›¾å‡å°‘ 50-80% å·¥å…· = **1500-4000 tokens**

#### P3: å·¥å…·ç»“æœå†—ä½™

**å½“å‰é—®é¢˜**:
- `feedback.py` å·²åšå‹ç¼©ï¼Œä½†æŸäº›åœºæ™¯ä»è¿”å›è¿‡å¤šæ•°æ®
- `read_file` è¿”å›å®Œæ•´æ–‡ä»¶å†…å®¹è€Œéè¯­ä¹‰çª—å£
- `grep` è¿”å› 20 æ¡ç»“æœï¼Œæ¯æ¡ 200 å­—ç¬¦é¢„è§ˆ

**ç¤ºä¾‹ï¼ˆå½“å‰ grep è¿”å›ï¼‰**:
```json
{
  "hits": [
    {"path": "a.py", "line": 10, "preview": "def foo(): # 200 chars..."},
    {"path": "b.py", "line": 20, "preview": "def bar(): # 200 chars..."},
    // ... 20 æ¡
  ]
}
```

**ä¸šç•Œåšæ³•ï¼ˆåˆ†å±‚æ‘˜è¦ï¼‰**:
```json
{
  "summary": "Found 45 matches in 8 files",
  "top_hits": [
    {"path": "a.py", "lines": "10,15,20", "context": "function definitions"}
  ],
  "full_results_available": true
}
```

**èŠ‚çœæ½œåŠ›**: å‡å°‘ 50% ç»“æœä½“ç§¯ = **500-2000 tokens/æ¬¡**

### 3.2 ğŸŸ¡ ä¸­ä¼˜å…ˆçº§é—®é¢˜

#### P4: ç¼ºä¹å·¥å…·ä½¿ç”¨çƒ­åº¦ä¼˜åŒ–

**å½“å‰çŠ¶æ€**: `ToolRegistry` æœ‰ `get_popular_tools()` ä½†æœªç”¨äº Prompt ä¼˜åŒ–

**ä¼˜åŒ–æ–¹æ¡ˆ**: é«˜é¢‘å·¥å…·æ’åœ¨å‰é¢ï¼Œä½é¢‘å·¥å…·ç®€åŒ–æè¿°

#### P5: ç¼ºä¹å·¥å…·ä¾èµ–æ¨æ–­

**å½“å‰çŠ¶æ€**: LLM å¯èƒ½è°ƒç”¨ `apply_patch` è€Œæœªå…ˆ `read_file`

**ä¼˜åŒ–æ–¹æ¡ˆ**: æä¾›å·¥å…·é“¾å»ºè®®ï¼ˆTool Chain Hintsï¼‰

#### P6: å·¥å…·å‚æ•°é»˜è®¤å€¼æœªåœ¨ Schema å±‚é¢ä¼˜åŒ–

**å½“å‰çŠ¶æ€**: é»˜è®¤å€¼åœ¨ handler å’Œ schema ä¸­é‡å¤å®šä¹‰

**ä¼˜åŒ–æ–¹æ¡ˆ**: ç»Ÿä¸€åœ¨ schema å®šä¹‰ï¼Œhandler ä»…è´Ÿè´£æ‰§è¡Œ

---

## 4. Token èŠ‚çœæ–¹æ¡ˆ

### 4.1 æ–¹æ¡ˆæ€»è§ˆ

| æ–¹æ¡ˆ | é¢„ä¼°èŠ‚çœ | å®ç°å¤æ‚åº¦ | ä¼˜å…ˆçº§ |
|------|---------|-----------|--------|
| A: å·¥å…·æè¿°ç²¾ç®€ | 600 tokens | ä½ | P0 |
| B: åŠ¨æ€å·¥å…·é›† | 1500-4000 tokens | ä¸­ | P0 |
| C: ç»“æœåˆ†å±‚å‹ç¼© | 500-2000 tokens/æ¬¡ | ä¸­ | P1 |
| D: å·¥å…·çƒ­åº¦æ’åº | 100-300 tokens | ä½ | P2 |
| E: å·¥å…·é“¾æç¤º | é—´æ¥èŠ‚çœ | ä¸­ | P2 |
| F: å‚æ•°é»˜è®¤å€¼ä¼˜åŒ– | 100 tokens | ä½ | P3 |

### 4.2 æ–¹æ¡ˆ A: å·¥å…·æè¿°ç²¾ç®€

#### 4.2.1 ç²¾ç®€è§„åˆ™

1. **Summary**: â‰¤50 å­—ç¬¦ï¼Œçº¯åŠŸèƒ½æè¿°
2. **Description**: â‰¤100 å­—ç¬¦ï¼Œä»…å…³é”®æç¤º
3. **å‚æ•°æè¿°**: â‰¤30 å­—ç¬¦

#### 4.2.2 ç²¾ç®€ç¤ºä¾‹

**Before**:
```python
ToolSpec(
    name="grep",
    summary="å…¨èƒ½è·¨è¯­è¨€ä»£ç æœç´¢å™¨ã€‚",
    description=(
        "ç”¨äºåœ¨å·¥ä½œåŒºå†…æŒ‰æ­£åˆ™æœç´¢æ–‡æœ¬å†…å®¹ï¼ˆGrep / Ripgrepï¼‰ã€‚æ”¯æŒ C/C++/Java ç­‰å¤šç§è¯­è¨€çš„è‡ªåŠ¨åç¼€åŒ¹é…ã€‚\n"
        "å¦‚æœä½ åœ¨å¯»æ‰¾ç‰¹å®šè¯­è¨€çš„å®šä¹‰ï¼ˆå¦‚ C++ ç±»æˆ– Java æ–¹æ³•ï¼‰ï¼ŒæŒ‡å®š 'language' å‚æ•°å°†æå¤§æé«˜å‡†ç¡®ç‡ã€‚"
    ),
    args_schema=_obj_schema(
        properties={
            "pattern": {"type": "string", "description": "æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼Œæ”¯æŒæ ‡å‡†æ­£åˆ™è¯­æ³•"},
            "path": {"type": "string", "default": ".", "description": "æœç´¢è·¯å¾„ï¼ˆç›¸å¯¹å·¥ä½œåŒºï¼‰"},
            "language": {"type": "string", "default": "all", "description": "è¯­è¨€ç±»å‹ï¼šcpp/java/python/all"},
            "include_glob": {"type": ["string", "null"], "description": "é¢å¤– glob è¿‡æ»¤ï¼Œå¦‚ *.cpp"},
            "ignore_case": {"type": "boolean", "default": False, "description": "æ˜¯å¦å¿½ç•¥å¤§å°å†™"},
            "max_hits": {"type": "integer", "default": 200, "description": "æœ€å¤§è¿”å›æ¡ç›®æ•°"},
        },
        required=["pattern"],
    ),
)
```

**After**:
```python
ToolSpec(
    name="grep",
    summary="æ­£åˆ™æœç´¢ä»£ç ",
    description="åœ¨å·¥ä½œåŒºæŒ‰æ­£åˆ™æœç´¢ã€‚æ”¯æŒ language è¿‡æ»¤ã€‚",
    args_schema=_obj_schema(
        properties={
            "pattern": {"type": "string", "description": "æ­£åˆ™æ¨¡å¼"},
            "path": {"type": "string", "default": "."},
            "language": {"type": "string", "default": "all", "enum": ["all","cpp","java","python","go","rust","js","ts"]},
            "ignore_case": {"type": "boolean", "default": False},
            "max_hits": {"type": "integer", "default": 100},
        },
        required=["pattern"],
    ),
)
```

**Token å¯¹æ¯”**:
- Before: ~120 tokens
- After: ~50 tokens
- èŠ‚çœ: **70 tokens/å·¥å…·**

### 4.3 æ–¹æ¡ˆ B: åŠ¨æ€å·¥å…·é›†

#### 4.3.1 å·¥å…·åˆ†ç»„å®šä¹‰

```python
# src/clude_code/tooling/tool_groups.py

TOOL_GROUPS = {
    "minimal": ["display"],  # çº¯å¯¹è¯
    "readonly": ["list_dir", "read_file", "grep", "glob_file_search", "search_semantic"],
    "write": ["apply_patch", "write_file", "undo_patch"],
    "exec": ["run_cmd"],
    "web": ["webfetch", "websearch", "codesearch"],
    "task": ["todowrite", "todoread", "run_task", "get_task_status"],
    "utility": ["question", "load_skill", "get_weather", "get_weather_forecast"],
}

# æ„å›¾åˆ°å·¥å…·é›†çš„æ˜ å°„
INTENT_TO_TOOLS = {
    "GENERAL_CHAT": ["minimal"],
    "CODE_ANALYSIS": ["readonly"],
    "CODE_MODIFICATION": ["readonly", "write"],
    "CODE_EXECUTION": ["readonly", "write", "exec"],
    "WEB_RESEARCH": ["readonly", "web"],
    "TASK_MANAGEMENT": ["readonly", "task"],
}
```

#### 4.3.2 åŠ¨æ€æ³¨å…¥é€»è¾‘

```python
# åœ¨ AgentLoop._build_system_prompt() ä¸­

def _get_tools_for_intent(self, intent: str) -> list[ToolSpec]:
    """æ ¹æ®æ„å›¾è¿”å›ç²¾ç®€çš„å·¥å…·é›†"""
    from clude_code.tooling.tool_groups import INTENT_TO_TOOLS, TOOL_GROUPS
    
    group_names = INTENT_TO_TOOLS.get(intent, ["readonly"])
    tool_names = set()
    for gn in group_names:
        tool_names.update(TOOL_GROUPS.get(gn, []))
    
    return [spec for spec in iter_tool_specs() if spec.name in tool_names]

def _build_tools_prompt(self, intent: str) -> str:
    """ç”Ÿæˆç²¾ç®€çš„å·¥å…·æç¤º"""
    tools = self._get_tools_for_intent(intent)
    
    lines = ["## å¯ç”¨å·¥å…·"]
    for t in tools:
        # ç´§å‡‘æ ¼å¼ï¼šä¸€è¡Œä¸€ä¸ªå·¥å…·
        args_hint = ", ".join(f"{k}={v.get('default','?')}" for k, v in t.args_schema.get("properties", {}).items())
        lines.append(f"- {t.name}({args_hint}): {t.summary}")
    
    return "\n".join(lines)
```

#### 4.3.3 æ•ˆæœå¯¹æ¯”

| åœºæ™¯ | å½“å‰å·¥å…·æ•° | ä¼˜åŒ–å | Token èŠ‚çœ |
|------|-----------|--------|-----------|
| é—²èŠ | 20 | 1 | ~2800 |
| ä»£ç åˆ†æ | 20 | 5 | ~2100 |
| ä»£ç ä¿®æ”¹ | 20 | 8 | ~1680 |
| å…¨åŠŸèƒ½ | 20 | 20 | 0 |

### 4.4 æ–¹æ¡ˆ C: ç»“æœåˆ†å±‚å‹ç¼©

#### 4.4.1 ä¸‰å±‚å‹ç¼©ç­–ç•¥

```python
# src/clude_code/tooling/feedback.py

class ResultCompressor:
    """å·¥å…·ç»“æœåˆ†å±‚å‹ç¼©å™¨"""
    
    # å‹ç¼©çº§åˆ«
    LEVEL_SUMMARY = "summary"      # ä»…æ‘˜è¦ï¼ˆæœ€çœ tokenï¼‰
    LEVEL_COMPACT = "compact"      # ç´§å‡‘ï¼ˆé»˜è®¤ï¼‰
    LEVEL_DETAILED = "detailed"    # è¯¦ç»†ï¼ˆé¦–æ¬¡è°ƒç”¨æˆ–æ˜¾å¼è¯·æ±‚ï¼‰
    
    def compress(self, tool: str, result: ToolResult, level: str = "compact") -> dict:
        if not result.ok:
            return {"tool": tool, "ok": False, "error": result.error}
        
        if level == self.LEVEL_SUMMARY:
            return self._to_summary(tool, result)
        elif level == self.LEVEL_COMPACT:
            return self._to_compact(tool, result)
        else:
            return self._to_detailed(tool, result)
    
    def _to_summary(self, tool: str, result: ToolResult) -> dict:
        """ä»…è¿”å›ç»Ÿè®¡æ‘˜è¦"""
        payload = result.payload or {}
        
        if tool == "grep":
            hits = payload.get("hits", [])
            files = set(h.get("path") for h in hits if isinstance(h, dict))
            return {
                "tool": tool,
                "ok": True,
                "summary": f"Found {len(hits)} matches in {len(files)} files",
                "has_more": len(hits) > 0,
            }
        
        if tool == "read_file":
            text = payload.get("text", "")
            return {
                "tool": tool,
                "ok": True,
                "summary": f"Read {len(text)} chars, {len(text.splitlines())} lines",
                "has_more": True,
            }
        
        # å…¶ä»–å·¥å…·...
        return {"tool": tool, "ok": True, "summary": "completed"}
    
    def _to_compact(self, tool: str, result: ToolResult) -> dict:
        """è¿”å›ç´§å‡‘ç»“æœï¼ˆå½“å‰ summarize_tool_result çš„å¢å¼ºç‰ˆï¼‰"""
        # å¤ç”¨ç°æœ‰é€»è¾‘ï¼Œä½†è¿›ä¸€æ­¥å‹ç¼©
        # - grep: ä»… top 5 hitsï¼Œpreview é™åˆ¶ 100 å­—ç¬¦
        # - read_file: ä»…è¯­ä¹‰çª—å£ï¼Œé™åˆ¶ 2000 å­—ç¬¦
        # - list_dir: ä»… top 10 items
        pass
    
    def _to_detailed(self, tool: str, result: ToolResult) -> dict:
        """è¿”å›å®Œæ•´ç»“æœï¼ˆé¦–æ¬¡è°ƒç”¨æˆ–æ˜¾å¼è¯·æ±‚ï¼‰"""
        return {"tool": tool, "ok": True, **result.payload}
```

#### 4.4.2 è‡ªé€‚åº”å‹ç¼©çº§åˆ«

```python
def get_compression_level(tool: str, context_utilization: float, call_count: int) -> str:
    """æ ¹æ®ä¸Šä¸‹æ–‡ä½¿ç”¨ç‡å’Œè°ƒç”¨æ¬¡æ•°å†³å®šå‹ç¼©çº§åˆ«"""
    
    # ä¸Šä¸‹æ–‡ç´§å¼ æ—¶å¼ºåˆ¶æ‘˜è¦
    if context_utilization > 0.8:
        return ResultCompressor.LEVEL_SUMMARY
    
    # é¦–æ¬¡è°ƒç”¨ç»™è¯¦ç»†ç»“æœ
    if call_count == 0:
        return ResultCompressor.LEVEL_DETAILED
    
    # é‡å¤è°ƒç”¨ç»™ç´§å‡‘ç»“æœ
    if call_count >= 2:
        return ResultCompressor.LEVEL_SUMMARY
    
    return ResultCompressor.LEVEL_COMPACT
```

### 4.5 æ–¹æ¡ˆ D: å·¥å…·çƒ­åº¦æ’åº

```python
def get_tools_sorted_by_usage(tools: list[ToolSpec], metrics: dict[str, ToolMetrics]) -> list[ToolSpec]:
    """æŒ‰ä½¿ç”¨çƒ­åº¦æ’åºå·¥å…·ï¼Œé«˜é¢‘å·¥å…·åœ¨å‰"""
    def sort_key(t: ToolSpec) -> tuple:
        m = metrics.get(t.name)
        if not m:
            return (0, t.priority)
        return (m.call_count, t.priority)
    
    return sorted(tools, key=sort_key, reverse=True)

def generate_tools_prompt_with_priority(tools: list[ToolSpec], metrics: dict) -> str:
    """ç”Ÿæˆå¸¦ä¼˜å…ˆçº§æç¤ºçš„å·¥å…·åˆ—è¡¨"""
    sorted_tools = get_tools_sorted_by_usage(tools, metrics)
    
    lines = ["## å·¥å…·ï¼ˆæŒ‰ä½¿ç”¨é¢‘ç‡æ’åºï¼‰"]
    for i, t in enumerate(sorted_tools):
        # å‰ 5 ä¸ªå·¥å…·å®Œæ•´æè¿°
        if i < 5:
            lines.append(f"### {t.name}")
            lines.append(f"{t.summary}")
            lines.append(f"å‚æ•°: {t.example_args}")
        else:
            # åç»­å·¥å…·ä»…åç§°
            lines.append(f"- {t.name}: {t.summary}")
    
    return "\n".join(lines)
```

---

## 5. ä¼˜åŒ–å®ç°ç»†èŠ‚

### 5.1 å·¥å…·æè¿°ç²¾ç®€ï¼ˆæ–¹æ¡ˆ Aï¼‰

#### 5.1.1 ä¿®æ”¹æ–‡ä»¶

- `src/clude_code/orchestrator/agent_loop/tool_dispatch.py`

#### 5.1.2 å®ç°æ­¥éª¤

1. å®šä¹‰ç²¾ç®€æè¿°è§„èŒƒ
2. é€ä¸ªå·¥å…·é‡å†™ summary/description
3. ç®€åŒ– args_schema ä¸­çš„ description
4. éªŒè¯ LLM ç†è§£åº¦ï¼ˆå›å½’æµ‹è¯•ï¼‰

#### 5.1.3 ç²¾ç®€åçš„å·¥å…·æè¿°æ¨¡æ¿

```python
# å·¥å…·æè¿°ç²¾ç®€æ¨¡æ¿
TOOL_DESCRIPTIONS = {
    "list_dir": ("åˆ—å‡ºç›®å½•", "æŸ¥çœ‹ç›®å½•å†…å®¹"),
    "read_file": ("è¯»å–æ–‡ä»¶", "æ”¯æŒ offset/limit åˆ†æ®µ"),
    "glob_file_search": ("æŒ‰åæœç´¢æ–‡ä»¶", "æ”¯æŒ ** é€’å½’"),
    "grep": ("æ­£åˆ™æœç´¢ä»£ç ", "æ”¯æŒè¯­è¨€è¿‡æ»¤"),
    "apply_patch": ("è¡¥ä¸ç¼–è¾‘", "åŸºäºä¸Šä¸‹æ–‡æ›¿æ¢"),
    "undo_patch": ("å›æ»šè¡¥ä¸", "åŸºäº undo_id"),
    "write_file": ("å†™å…¥æ–‡ä»¶", "æ”¯æŒè¿½åŠ /æ’å…¥"),
    "run_cmd": ("æ‰§è¡Œå‘½ä»¤", "éœ€ç¡®è®¤"),
    "search_semantic": ("è¯­ä¹‰æœç´¢", "å‘é‡ RAG"),
    "display": ("æ˜¾ç¤ºæ¶ˆæ¯", "è¾“å‡ºåˆ° UI"),
    "webfetch": ("è·å–ç½‘é¡µ", "è½¬ Markdown"),
    "websearch": ("ç½‘é¡µæœç´¢", "DuckDuckGo"),
    "codesearch": ("ä»£ç æœç´¢", "GitHub/Sourcegraph"),
    "todowrite": ("åˆ›å»ºä»»åŠ¡", ""),
    "todoread": ("è¯»å–ä»»åŠ¡", ""),
    "question": ("å‘ç”¨æˆ·æé—®", ""),
    "load_skill": ("åŠ è½½æŠ€èƒ½", ""),
    "run_task": ("è¿è¡Œå­ä»»åŠ¡", ""),
    "get_task_status": ("è·å–ä»»åŠ¡çŠ¶æ€", ""),
    "get_weather": ("è·å–å¤©æ°”", ""),
    "get_weather_forecast": ("è·å–å¤©æ°”é¢„æŠ¥", ""),
}
```

### 5.2 åŠ¨æ€å·¥å…·é›†ï¼ˆæ–¹æ¡ˆ Bï¼‰

#### 5.2.1 æ–°å¢æ–‡ä»¶

- `src/clude_code/tooling/tool_groups.py`

#### 5.2.2 å®Œæ•´å®ç°

```python
# src/clude_code/tooling/tool_groups.py

from __future__ import annotations
from typing import TYPE_CHECKING
from enum import Enum

if TYPE_CHECKING:
    from clude_code.orchestrator.agent_loop.tool_dispatch import ToolSpec


class ToolGroup(Enum):
    """å·¥å…·åˆ†ç»„"""
    MINIMAL = "minimal"      # ä»… display
    READONLY = "readonly"    # åªè¯»æ“ä½œ
    WRITE = "write"          # å†™æ–‡ä»¶
    EXEC = "exec"            # æ‰§è¡Œå‘½ä»¤
    WEB = "web"              # ç½‘ç»œæ“ä½œ
    TASK = "task"            # ä»»åŠ¡ç®¡ç†
    UTILITY = "utility"      # å®ç”¨å·¥å…·


# å·¥å…·åˆ†ç»„å®šä¹‰
TOOL_GROUPS: dict[str, list[str]] = {
    "minimal": ["display"],
    "readonly": ["list_dir", "read_file", "grep", "glob_file_search", "search_semantic"],
    "write": ["apply_patch", "write_file", "undo_patch"],
    "exec": ["run_cmd"],
    "web": ["webfetch", "websearch", "codesearch"],
    "task": ["todowrite", "todoread", "run_task", "get_task_status"],
    "utility": ["question", "load_skill", "get_weather", "get_weather_forecast"],
}


# æ„å›¾åˆ°å·¥å…·é›†çš„æ˜ å°„
INTENT_TO_GROUPS: dict[str, list[str]] = {
    "GENERAL_CHAT": ["minimal"],
    "CAPABILITY_INQUIRY": ["minimal"],
    "CODE_ANALYSIS": ["readonly"],
    "CODE_MODIFICATION": ["readonly", "write"],
    "CODE_EXECUTION": ["readonly", "write", "exec"],
    "ERROR_DIAGNOSIS": ["readonly", "exec"],
    "WEB_RESEARCH": ["readonly", "web"],
    "TASK_MANAGEMENT": ["readonly", "task"],
    "SECURITY_CONSULTING": ["readonly"],
    "PROJECT_DESIGN": ["readonly", "write"],
    # é»˜è®¤
    "UNKNOWN": ["readonly", "write", "exec"],
}


def get_tools_for_intent(intent: str, all_tools: dict[str, "ToolSpec"]) -> list["ToolSpec"]:
    """
    æ ¹æ®æ„å›¾è¿”å›ç²¾ç®€çš„å·¥å…·é›†ã€‚
    
    Args:
        intent: æ„å›¾ç±»åˆ«åç§°
        all_tools: æ‰€æœ‰å·¥å…·çš„å­—å…¸ {name: ToolSpec}
    
    Returns:
        ç²¾ç®€çš„ ToolSpec åˆ—è¡¨
    """
    group_names = INTENT_TO_GROUPS.get(intent, INTENT_TO_GROUPS["UNKNOWN"])
    
    tool_names: set[str] = set()
    for gn in group_names:
        tool_names.update(TOOL_GROUPS.get(gn, []))
    
    return [spec for name, spec in all_tools.items() if name in tool_names]


def get_tool_count_by_intent(intent: str) -> int:
    """è·å–æŸæ„å›¾å¯¹åº”çš„å·¥å…·æ•°é‡"""
    group_names = INTENT_TO_GROUPS.get(intent, INTENT_TO_GROUPS["UNKNOWN"])
    tool_names: set[str] = set()
    for gn in group_names:
        tool_names.update(TOOL_GROUPS.get(gn, []))
    return len(tool_names)


def estimate_token_savings(intent: str, total_tools: int, avg_tokens_per_tool: int = 150) -> int:
    """ä¼°ç®— Token èŠ‚çœé‡"""
    intent_tools = get_tool_count_by_intent(intent)
    saved_tools = total_tools - intent_tools
    return saved_tools * avg_tokens_per_tool
```

#### 5.2.3 AgentLoop é›†æˆ

```python
# src/clude_code/orchestrator/agent_loop/agent_loop.py

from clude_code.tooling.tool_groups import get_tools_for_intent

def _build_tools_prompt(self, intent: str) -> str:
    """æ ¹æ®æ„å›¾ç”Ÿæˆç²¾ç®€çš„å·¥å…·æç¤º"""
    from clude_code.orchestrator.agent_loop.tool_dispatch import TOOL_REGISTRY
    
    # è·å–æ„å›¾å¯¹åº”çš„å·¥å…·é›†
    tools = get_tools_for_intent(intent, TOOL_REGISTRY)
    
    if not tools:
        return ""
    
    lines = ["## å¯ç”¨å·¥å…·æ¸…å•"]
    for t in tools:
        # ç´§å‡‘æ ¼å¼
        example = json.dumps(t.example_args, ensure_ascii=False)
        lines.append(f"  - {t.name}: {example}")
    
    return "\n".join(lines)
```

### 5.3 ç»“æœåˆ†å±‚å‹ç¼©ï¼ˆæ–¹æ¡ˆ Cï¼‰

#### 5.3.1 ä¿®æ”¹æ–‡ä»¶

- `src/clude_code/tooling/feedback.py`

#### 5.3.2 å¢å¼ºå®ç°

```python
# src/clude_code/tooling/feedback.py

# æ·»åŠ å‹ç¼©çº§åˆ«å¸¸é‡
COMPRESSION_SUMMARY = "summary"
COMPRESSION_COMPACT = "compact"
COMPRESSION_DETAILED = "detailed"

# å„å·¥å…·çš„å‹ç¼©é…ç½®
TOOL_COMPRESSION_CONFIG = {
    "grep": {
        "summary_fields": ["hits_total", "files_matched"],
        "compact_max_hits": 5,
        "compact_preview_len": 100,
        "detailed_max_hits": 20,
        "detailed_preview_len": 200,
    },
    "read_file": {
        "summary_fields": ["chars_total", "lines_total"],
        "compact_max_chars": 2000,
        "detailed_max_chars": 4000,
    },
    "list_dir": {
        "summary_fields": ["items_total", "dirs", "files"],
        "compact_max_items": 10,
        "detailed_max_items": 50,
    },
    "run_cmd": {
        "summary_fields": ["exit_code", "output_lines"],
        "compact_max_chars": 1000,
        "detailed_max_chars": 3000,
    },
}


def get_compression_level(
    tool: str,
    context_utilization: float,
    tool_call_count: int,
) -> str:
    """
    æ ¹æ®ä¸Šä¸‹æ–‡ä½¿ç”¨ç‡å’Œå·¥å…·è°ƒç”¨æ¬¡æ•°å†³å®šå‹ç¼©çº§åˆ«ã€‚
    
    è§„åˆ™ï¼š
    - ä¸Šä¸‹æ–‡ > 80%: å¼ºåˆ¶ summary
    - é¦–æ¬¡è°ƒç”¨: detailed
    - é‡å¤è°ƒç”¨ >= 2: summary
    - å…¶ä»–: compact
    """
    if context_utilization > 0.8:
        return COMPRESSION_SUMMARY
    
    if tool_call_count == 0:
        return COMPRESSION_DETAILED
    
    if tool_call_count >= 2:
        return COMPRESSION_SUMMARY
    
    return COMPRESSION_COMPACT


def summarize_tool_result_v2(
    tool: str,
    tr: ToolResult,
    keywords: set[str] | None = None,
    compression_level: str = COMPRESSION_COMPACT,
) -> dict[str, Any]:
    """
    å¢å¼ºç‰ˆå·¥å…·ç»“æœæ‘˜è¦ï¼ˆæ”¯æŒåˆ†å±‚å‹ç¼©ï¼‰ã€‚
    """
    if not tr.ok:
        return {"tool": tool, "ok": False, "error": tr.error}
    
    payload = tr.payload or {}
    config = TOOL_COMPRESSION_CONFIG.get(tool, {})
    
    if compression_level == COMPRESSION_SUMMARY:
        return _to_summary(tool, payload, config)
    elif compression_level == COMPRESSION_COMPACT:
        return _to_compact(tool, payload, config, keywords)
    else:
        return _to_detailed(tool, payload, config, keywords)


def _to_summary(tool: str, payload: dict, config: dict) -> dict:
    """ä»…è¿”å›ç»Ÿè®¡æ‘˜è¦"""
    summary_fields = config.get("summary_fields", [])
    
    result = {"tool": tool, "ok": True, "level": "summary"}
    
    if tool == "grep":
        hits = payload.get("hits", [])
        files = set(h.get("path") for h in hits if isinstance(h, dict))
        result["stats"] = f"{len(hits)} hits in {len(files)} files"
    
    elif tool == "read_file":
        text = payload.get("text", "")
        result["stats"] = f"{len(text)} chars, {len(text.splitlines())} lines"
    
    elif tool == "list_dir":
        items = payload.get("items", [])
        result["stats"] = f"{len(items)} items"
    
    elif tool == "run_cmd":
        result["exit_code"] = payload.get("exit_code")
        out = payload.get("output", "")
        result["stats"] = f"{len(out.splitlines())} lines output"
    
    else:
        result["stats"] = "completed"
    
    result["has_more"] = True
    return result
```

---

## 6. å®æ–½ä¼˜å…ˆçº§

### 6.1 å®æ–½è®¡åˆ’

| é˜¶æ®µ | æ–¹æ¡ˆ | é¢„æœŸæ•ˆæœ | å·¥æ—¶ |
|------|------|---------|------|
| Phase 1 | A: æè¿°ç²¾ç®€ | -600 tokens/è¯·æ±‚ | 2h |
| Phase 2 | B: åŠ¨æ€å·¥å…·é›† | -1500~4000 tokens/è¯·æ±‚ | 4h |
| Phase 3 | C: ç»“æœåˆ†å±‚å‹ç¼© | -500~2000 tokens/æ¬¡è°ƒç”¨ | 4h |
| Phase 4 | D+E+F: ä¼˜åŒ–å¢å¼º | -200~500 tokens | 2h |

### 6.2 é¢„æœŸæ€»æ”¶ç›Š

| åœºæ™¯ | å½“å‰æ¶ˆè€— | ä¼˜åŒ–å | èŠ‚çœæ¯”ä¾‹ |
|------|---------|--------|---------|
| ç®€å•å¯¹è¯ | ~5000 tokens | ~1500 tokens | 70% |
| ä»£ç åˆ†æ | ~8000 tokens | ~4000 tokens | 50% |
| ä»£ç ä¿®æ”¹ | ~12000 tokens | ~6000 tokens | 50% |

### 6.3 é£é™©è¯„ä¼°

| é£é™© | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|---------|
| æè¿°è¿‡ç®€å¯¼è‡´ LLM è¯¯è§£ | ä¸­ | ä¿ç•™å…³é”®æç¤ºï¼›å›å½’æµ‹è¯• |
| åŠ¨æ€å·¥å…·é›†é—æ¼å¿…è¦å·¥å…· | ä¸­ | æ„å›¾åˆ†ç±»å‡†ç¡®ï¼›å…œåº•å…¨é‡ |
| å‹ç¼©è¿‡åº¦ä¸¢å¤±å…³é”®ä¿¡æ¯ | ä½ | ä¿ç•™ has_more æ ‡å¿—ï¼›å…è®¸é‡æŸ¥ |

---

## 7. åç»­è¡ŒåŠ¨

1. **ç«‹å³**: å®æ–½æ–¹æ¡ˆ Aï¼ˆå·¥å…·æè¿°ç²¾ç®€ï¼‰
2. **æœ¬å‘¨**: å®æ–½æ–¹æ¡ˆ Bï¼ˆåŠ¨æ€å·¥å…·é›†ï¼‰
3. **ä¸‹å‘¨**: å®æ–½æ–¹æ¡ˆ Cï¼ˆç»“æœåˆ†å±‚å‹ç¼©ï¼‰
4. **æŒç»­**: ç›‘æ§ Token ä½¿ç”¨é‡ï¼Œè¿­ä»£ä¼˜åŒ–

---

*æ–‡æ¡£ç‰ˆæœ¬: 1.0.0 | æœ€åæ›´æ–°: 2026-01-23*

