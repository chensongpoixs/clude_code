# ReAct å†³ç­–å¡ä½é—®é¢˜åˆ†æä¸è§£å†³æ–¹æ¡ˆ (ReAct Decision Hang Analysis & Solution)

> **Issue (é—®é¢˜)**: ReAct å†³ç­–é˜¶æ®µä¸€ç›´æ˜¾ç¤º 0% å®Œæˆï¼ŒLLM è¯·æ±‚æ— å“åº”  
> **Root Cause (æ ¹å› )**: `max_tokens` é…ç½®å¼‚å¸¸ï¼ˆ409600ï¼‰å¯¼è‡´æ¨¡å‹å°è¯•ç”Ÿæˆè¿‡é•¿è¾“å‡º  
> **Priority (ä¼˜å…ˆçº§)**: P0 (Critical / å…³é”®)

---

## 1. é—®é¢˜åˆ†æ (Problem Analysis)

### 1.1 ç°è±¡æè¿° (Symptoms)
ä»æˆªå›¾å¯è§ï¼š
- **çŠ¶æ€**: `EXECUTING`ï¼Œæ“ä½œ `LLM è¯·æ±‚`
- **è¿›åº¦**: `[ReAct å†³ç­–/ç›´æ¥å›ç­”]` 0% å®Œæˆ
- **å‚æ•°**: `max_tokens=409600`ï¼ˆå¼‚å¸¸å¤§ï¼‰
- **äº‹ä»¶**: `step=10 llm_request_params` åæ— åç»­å“åº”

### 1.2 æ ¹å› å®šä½ (Root Cause)

#### ğŸ”´ é—®é¢˜ 1: `max_tokens` é…ç½®é”™è¯¯
**ä½ç½®**: `src/clude_code/config.py:14`
```python
max_tokens: int = Field(default=409600, ge=1)  # âŒ é”™è¯¯ï¼šè¿™æ˜¯ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼Œä¸æ˜¯è¾“å‡ºé™åˆ¶
```

**å½±å“**:
- `max_tokens` åœ¨ OpenAI API ä¸­è¡¨ç¤º**è¾“å‡º token é™åˆ¶**ï¼ˆé€šå¸¸ 512-2048ï¼‰
- 409600 ä¼šå¯¼è‡´æ¨¡å‹å°è¯•ç”Ÿæˆæé•¿è¾“å‡ºï¼Œå¯èƒ½ï¼š
  - è§¦å‘æœåŠ¡ç«¯è¶…æ—¶
  - æ¶ˆè€—å¤§é‡è®¡ç®—èµ„æº
  - å¯¼è‡´è¯·æ±‚å¡æ­»

#### ğŸŸ¡ é—®é¢˜ 2: è¶…æ—¶å¤„ç†ä¸å¤Ÿå¥å£®
**ä½ç½®**: `src/clude_code/llm/llama_cpp_http.py:123`
```python
with httpx.Client(timeout=self.timeout_s) as client:  # é»˜è®¤ 120 ç§’
    r = client.post(url, json=payload)
```

**å½±å“**:
- è™½ç„¶ä»£ç æœ‰ `TimeoutException` å¤„ç†ï¼Œä½†å¼‚å¸¸å¯èƒ½æœªæ­£ç¡®ä¼ æ’­åˆ° UI
- UI å±‚é¢ç¼ºå°‘è¶…æ—¶æç¤ºå’Œé‡è¯•æœºåˆ¶

#### ğŸŸ¡ é—®é¢˜ 3: é”™è¯¯åé¦ˆé“¾è·¯ä¸å®Œæ•´
**ä½ç½®**: `src/clude_code/orchestrator/agent_loop/react.py:37`
```python
assistant = _llm_chat("react_fallback", None)  # å¦‚æœè¿™é‡ŒæŠ›å¼‚å¸¸ï¼ŒUI å¯èƒ½æ”¶ä¸åˆ°äº‹ä»¶
```

**å½±å“**:
- LLM è¯·æ±‚å¤±è´¥æ—¶ï¼Œ`_ev` äº‹ä»¶æµå¯èƒ½ä¸­æ–­
- UI æ— æ³•æ„ŸçŸ¥åˆ°é”™è¯¯ï¼Œä¸€ç›´æ˜¾ç¤º"ç­‰å¾…ä¸­"

---

## 2. è§£å†³æ–¹æ¡ˆ (Solutions)

### 2.0 ä¸šç•Œåšæ³•å¯¹é½ï¼ˆIndustry Playbook / ä¸šç•Œå¤„ç½®æ‰‹å†Œï¼‰

ä¸šç•Œï¼ˆClaude Code/Aider/Cursor/OpenCodeï¼‰åœ¨å¤„ç†â€œLLM è¯·æ±‚å¡ä½/æ— é™ç­‰å¾…â€æ—¶ï¼Œé€šå¸¸éµå¾ªåŒä¸€å¥—å·¥ç¨‹æŠ¤æ ï¼ˆGuardrails/æŠ¤æ ï¼‰ï¼š

1. **Hard Limitsï¼ˆç¡¬é™åˆ¶ï¼‰**ï¼š
   - è¾“å‡º token ä¸Šé™ï¼ˆ`max_tokens`ï¼‰å¿…é¡»åˆç†ï¼ˆå…¸å‹ 512~2048ï¼‰ã€‚
   - è¯·æ±‚è¶…æ—¶ï¼ˆ`timeout_s`ï¼‰å¿…é¡»å¯é…ç½®ï¼ˆå…¸å‹ 30~120sï¼‰ï¼Œå¹¶åœ¨ UI æ˜ç¡®å±•ç¤ºâ€œå·²è¶…æ—¶/å¯é‡è¯•â€ã€‚
2. **Circuit Breakerï¼ˆç†”æ–­å™¨ï¼‰**ï¼š
   - åŒä¸€é˜¶æ®µè¿ç»­è¶…æ—¶/å¤±è´¥è¶…è¿‡é˜ˆå€¼ï¼Œç›´æ¥ä¸­æ­¢å¹¶æç¤ºâ€œç¼©å°é—®é¢˜/æ£€æŸ¥æ¨¡å‹æœåŠ¡â€ã€‚
3. **User-visible Failureï¼ˆç”¨æˆ·å¯è§å¤±è´¥ï¼‰**ï¼š
   - å¤±è´¥å¿…é¡»æˆä¸º UI äº‹ä»¶ï¼ˆä¾‹å¦‚ `llm_error`ï¼‰ï¼Œè€Œä¸æ˜¯é™é»˜å¯¼è‡´â€œ0% ç­‰å¾…ä¸­â€ã€‚
4. **Retry Policyï¼ˆé‡è¯•ç­–ç•¥ï¼‰**ï¼š
   - åªå¯¹æ˜ç¡®å¹‚ç­‰çš„ LLM è¯·æ±‚åšæœ‰é™æ¬¡æ•°é‡è¯•ï¼ˆä¾‹å¦‚ 1~2 æ¬¡ï¼‰ï¼Œå¹¶åšé€€é¿ï¼ˆBackoff/é€€é¿ï¼‰ã€‚
5. **Observabilityï¼ˆå¯è§‚æµ‹æ€§ï¼‰**ï¼š
   - è®°å½•è¯·æ±‚å¼€å§‹æ—¶é—´ã€è€—æ—¶ã€è¶…æ—¶åŸå› ã€å…³é”®å‚æ•°ï¼ˆmodel/max_tokens/messages_countï¼‰ï¼Œå†™å…¥ audit/traceã€‚

### 2.1 P0: ä¿®å¤ `max_tokens` é…ç½®ï¼ˆç«‹å³ä¿®å¤ï¼‰

**ä¿®æ”¹æ–‡ä»¶**: `src/clude_code/config.py`

```python
# Before (ä¿®æ”¹å‰)
max_tokens: int = Field(default=409600, ge=1)  # âŒ é”™è¯¯

# After (ä¿®æ”¹å)
max_tokens: int = Field(default=1024, ge=1, le=8192, description="LLM è¾“å‡º token é™åˆ¶ï¼ˆéä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼‰")
```

**è¯´æ˜**:
- 1024 æ˜¯åˆç†çš„é»˜è®¤å€¼ï¼ˆé€‚åˆå¤§å¤šæ•°ä»»åŠ¡ï¼‰
- `le=8192` é˜²æ­¢ç”¨æˆ·é…ç½®è¿‡å¤§å€¼
- æ·»åŠ æè¿°æ˜ç¡®è¿™æ˜¯"è¾“å‡ºé™åˆ¶"ï¼Œä¸æ˜¯ä¸Šä¸‹æ–‡çª—å£

### 2.2 P0: å¢å¼ºè¶…æ—¶ä¸é”™è¯¯å¤„ç†ï¼ˆç«‹å³ä¿®å¤ï¼‰

**ä¿®æ”¹æ–‡ä»¶**: `src/clude_code/orchestrator/agent_loop/react.py`

```python
# åœ¨ execute_react_fallback_loop ä¸­å¢åŠ å¼‚å¸¸æ•è·
try:
    assistant = _llm_chat("react_fallback", None)
except RuntimeError as e:
    error_msg = str(e)
    if "timeout" in error_msg.lower():
        _ev("llm_error", {"error": "timeout", "message": f"LLM è¯·æ±‚è¶…æ—¶ï¼ˆ{loop.llm.timeout_s}ç§’ï¼‰"})
        loop.logger.error(f"[red]LLM è¯·æ±‚è¶…æ—¶: {error_msg}[/red]")
        return AgentTurn(
            assistant_text=f"LLM è¯·æ±‚è¶…æ—¶ï¼ˆ{loop.llm.timeout_s}ç§’ï¼‰ã€‚è¯·æ£€æŸ¥æ¨¡å‹æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œï¼Œæˆ–å°è¯•é™ä½ max_tokensã€‚",
            tool_used=False,
            trace_id=trace_id,
            events=events,
        )
    else:
        _ev("llm_error", {"error": "request_failed", "message": error_msg})
        loop.logger.error(f"[red]LLM è¯·æ±‚å¤±è´¥: {error_msg}[/red]")
        return AgentTurn(
            assistant_text=f"LLM è¯·æ±‚å¤±è´¥: {error_msg}",
            tool_used=False,
            trace_id=trace_id,
            events=events,
        )
```

### 2.3 P1: UI å±‚é¢è¶…æ—¶æç¤ºï¼ˆåç»­ä¼˜åŒ–ï¼‰

**ä¿®æ”¹æ–‡ä»¶**: `src/clude_code/plugins/ui/opencode_tui.py`

åœ¨ `_refresh_ops` ä¸­æ£€æµ‹ LLM è¯·æ±‚æ˜¯å¦è¶…æ—¶ï¼š
```python
# å¦‚æœ LLM è¯·æ±‚è¶…è¿‡ timeout_s * 1.5ï¼Œæ˜¾ç¤ºè¶…æ—¶è­¦å‘Š
if elapsed_ms > (self._agent.cfg.llm.timeout_s * 1500):
    # æ˜¾ç¤ºè¶…æ—¶è­¦å‘Š
    self._push_chat_log("âš ï¸ LLM è¯·æ±‚å¯èƒ½å·²è¶…æ—¶ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æœåŠ¡", style="yellow")
```

---

## 3. éªŒè¯æ­¥éª¤ (Verification Steps)

1. **ä¿®å¤é…ç½®åé‡å¯**:
   ```bash
   # ä¿®æ”¹ config.py åï¼Œé‡å¯ clude chat
   clude chat --live --live-ui opencode
   ```

2. **éªŒè¯ `max_tokens`**:
   - æŸ¥çœ‹ TUI ä¸­çš„ `llm_request_params` äº‹ä»¶
   - ç¡®è®¤ `max_tokens` ä¸º 1024ï¼ˆæˆ–åˆç†å€¼ï¼‰

3. **æµ‹è¯•è¶…æ—¶å¤„ç†**:
   - æ•…æ„åœæ­¢æ¨¡å‹æœåŠ¡
   - ç¡®è®¤ UI æ˜¾ç¤ºé”™è¯¯æç¤ºï¼Œè€Œéä¸€ç›´ç­‰å¾…

---

## 4. é¢„é˜²æªæ–½ (Prevention)

1. **é…ç½®æ ¡éªŒ**: åœ¨ `LLMConfig` åˆå§‹åŒ–æ—¶æ ¡éªŒ `max_tokens <= 8192`
2. **æ–‡æ¡£æ›´æ–°**: åœ¨ `docs/18-troubleshooting-faq.md` ä¸­è¡¥å……æ­¤é—®é¢˜
3. **ç›‘æ§å‘Šè­¦**: åœ¨ UI ä¸­æ˜¾ç¤º LLM è¯·æ±‚è€—æ—¶ï¼Œè¶…è¿‡é˜ˆå€¼æ—¶æç¤º

4. **ç†”æ–­ç­–ç•¥ï¼ˆCircuit Breaker / ç†”æ–­ï¼‰**ï¼š
   - è¿ç»­ N æ¬¡ LLM è¶…æ—¶ï¼ˆä¾‹å¦‚ N=2ï¼‰åï¼Œç›´æ¥åœæ­¢æœ¬è½®å¹¶è¾“å‡ºâ€œæœåŠ¡å¼‚å¸¸/å»ºè®®é™ä½ max_tokens/æ£€æŸ¥ base_urlâ€ã€‚

---

## 5. ç›¸å…³æ–‡ä»¶ (Related Files)

- **é…ç½®**: `src/clude_code/config.py`
- **LLM å®¢æˆ·ç«¯**: `src/clude_code/llm/llama_cpp_http.py`
- **ReAct å¾ªç¯**: `src/clude_code/orchestrator/agent_loop/react.py`
- **UIï¼ˆç•Œé¢ï¼‰**: `src/clude_code/plugins/ui/opencode_tui.py`

