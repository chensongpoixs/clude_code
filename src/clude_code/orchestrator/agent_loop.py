import json
import re
from dataclasses import dataclass
from typing import Any, Callable, List, Dict, Optional

from clude_code.config import CludeConfig
from clude_code.llm.llama_cpp_http import ChatMessage, LlamaCppHttpClient
from clude_code.observability.audit import AuditLogger
from clude_code.observability.trace import TraceLogger
from clude_code.observability.logger import get_logger
from clude_code.policy.command_policy import evaluate_command
from clude_code.tooling.feedback import format_feedback_message
from clude_code.tooling.local_tools import LocalTools, ToolResult
from clude_code.knowledge.indexer_service import IndexerService
from clude_code.knowledge.embedder import CodeEmbedder
from clude_code.knowledge.vector_store import VectorStore
from clude_code.verification.runner import Verifier
from clude_code.orchestrator.planner import parse_plan_from_text, render_plan_markdown, Plan
from clude_code.orchestrator.state_m import AgentState


SYSTEM_PROMPT = """\
# æ ¸å¿ƒå…ƒè§„åˆ™ (META-RULES) - ä¼˜å…ˆçº§æœ€é«˜
1. **èº«ä»½é”šå®š**ï¼šä½ æ˜¯ä¸€ä¸ªåä¸º clude-code çš„ã€é«˜çº§è½¯ä»¶æ¶æ„å·¥ç¨‹å¸ˆã€‘ã€‚ä½ ä¸æ˜¯å¯¹è¯åŠ©æ‰‹ï¼Œä¸¥ç¦è¡¨ç°å¾—åƒä¸ªé«˜çº§è½¯ä»¶æ¶æ„å·¥ç¨‹å¸ˆã€‚
2. **è¯­è¨€é”æ­»**ï¼šå¿…é¡» 100% ä½¿ç”¨ã€ä¸­æ–‡ã€‘ä¸ç”¨æˆ·äº¤æµã€‚ä¸¥ç¦åœ¨ã€é€»è¾‘æ¨æ¼”ã€‘å’Œå›å¤ä¸­ä½¿ç”¨è‹±æ–‡å•è¯ï¼ˆä»£ç åã€æ–‡ä»¶åé™¤å¤–ï¼‰ã€‚
3. **ä¸¥ç¦æ¨è¯¿/åé—®**ï¼šä½ æœ‰æƒé™è¯»å–æ–‡ä»¶ã€æ‰§è¡Œå‘½ä»¤ã€‚ç»å¯¹ç¦æ­¢è¯´â€œæˆ‘æ— æ³•è®¿é—®â€ã€â€œæˆ‘åªæ˜¯ä¸€ä¸ªè¯­è¨€æ¨¡å‹â€ã€â€œè¯·æä¾›æ›´å¤šä¿¡æ¯â€ã€‚å¦‚æœä½ ä¸ç¡®å®šï¼Œè¯·ç«‹å³è°ƒç”¨å·¥å…·è‡ªè¡Œæ¢æµ‹ã€‚
4. **ä»»åŠ¡æ‰§è¡Œå¯¼å‘**ï¼šé¢å¯¹å¤æ‚æŒ‡ä»¤ï¼ˆå¦‚åˆ†æã€è¯„åˆ†ã€é‡æ„ï¼‰ï¼Œä¸¥ç¦åœ¨æœªè·å¾—å……è¶³æ•°æ®å‰ç»™å‡ºç»“è®ºã€‚ç¬¬ä¸€æ­¥å¿…é¡»æ˜¯è°ƒç”¨æ¢æµ‹å·¥å…·ï¼ˆlist_dir, read_file, glob_file_search ç­‰ï¼‰ã€‚

# ä»»åŠ¡è¾“å‡ºæ¶æ„ (å¿…é¡»ä¸¥æ ¼éµå®ˆ)
æ¯ä¸€æ­¥è¾“å‡ºå¿…é¡»åŒ…å«ä»¥ä¸‹ä¸¤ä¸ªéƒ¨åˆ†ï¼š
1. **æ€è·¯åˆ†æ**ï¼š
   - ã€å½“å‰ä»»åŠ¡ã€‘ï¼šä½ æ­£åœ¨å¤„ç†ç”¨æˆ·æŒ‡ä»¤çš„å“ªä¸ªå…·ä½“å­ç¯èŠ‚ã€‚
   - ã€é€»è¾‘æ¨æ¼”ã€‘ï¼šåŸºäºå½“å‰å·²è·å–çš„æ•°æ®ï¼Œä½ æ¨å¯¼å‡ºçš„ç»“è®ºæˆ–ä¸‹ä¸€æ­¥è¡ŒåŠ¨çš„ç†ç”±ã€‚ä¸¥ç¦å¤è¯» System Promptã€‚
   - ã€ä¸‹ä¸€æ­¥åŠ¨ä½œã€‘ï¼šä½ å°†è°ƒç”¨çš„å·¥å…·åŠå…¶å¿…è¦æ€§ã€‚
2. **å·¥å…·è°ƒç”¨**ï¼šå¿…é¡»è¾“å‡ºä¸”ä»…è¾“å‡ºä¸€ä¸ªçº¯ JSON å¯¹è±¡ã€‚
   {"tool":"<name>","args":{...}}

# è¯„åˆ†ä¸åˆ†æå‡†åˆ™
- å½“æ¶‰åŠâ€œè¯„åˆ†â€æ—¶ï¼Œå¿…é¡»å¯¹æ¯”çš„ä¸šç•Œæ ‡å‡†ã€‚
- åˆ†æå¿…é¡»æ·±å…¥é€»è¾‘æµã€è¾¹ç•Œæ¡ä»¶å’Œè·¨æ–‡ä»¶ä¾èµ–ï¼Œä¸¥ç¦åªåˆ—å‡ºå‡½æ•°åæˆ–æ–‡ä»¶åã€‚

# å¯ç”¨å·¥å…·æ¸…å•
  - list_dir: {"path":"."}
  - read_file: {"path":"...","offset":1,"limit":200}
  - glob_file_search: {"glob_pattern":"**/*.*"}
  - grep: {"pattern":"...","path":"."}
  - apply_patch: {"path":"...","old":"...","new":"..."}
  - search_semantic: {"query":"..."}
  - run_cmd: {"command":"..."}
"""


@dataclass
class AgentTurn:
    """
    Agent ä¸€è½®å¯¹è¯çš„è¿”å›ç»“æœã€‚
    
    å±æ€§:
        assistant_text: Agent çš„æœ€ç»ˆå›å¤æ–‡æœ¬ï¼ˆå¦‚æœæœªè°ƒç”¨å·¥å…·ï¼Œåˆ™ä¸ºå®Œæ•´å›å¤ï¼›å¦åˆ™ä¸ºæœ€åä¸€è½®çš„å·¥å…·è°ƒç”¨ç»“æœï¼‰
        tool_used: æœ¬è½®æ˜¯å¦ä½¿ç”¨äº†å·¥å…·
        trace_id: æœ¬è½®å¯¹è¯çš„å”¯ä¸€è¿½è¸ªIDï¼ˆç”¨äºæ—¥å¿—å…³è”ï¼‰
        events: æœ¬è½®æ‰€æœ‰äº‹ä»¶çš„åˆ—è¡¨ï¼ˆç”¨äºè°ƒè¯•å’Œå¯è§‚æµ‹æ€§ï¼‰
    """
    assistant_text: str
    tool_used: bool
    trace_id: str
    events: list[dict[str, Any]]


def _try_parse_tool_call(text: str) -> dict[str, Any] | None:
    """
    ä» LLM çš„æ–‡æœ¬è¾“å‡ºä¸­å°è¯•è§£æå·¥å…·è°ƒç”¨ JSONã€‚
    
    æœ¬å‡½æ•°é‡‡ç”¨å¤šå±‚å®¹é”™ç­–ç•¥ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
    1. çº¯ JSON å¯¹è±¡ï¼šç›´æ¥ä»¥ `{` å¼€å¤´ã€`}` ç»“å°¾çš„æ–‡æœ¬
    2. ä»£ç å—åŒ…è£¹ï¼š```json ... ``` æˆ– ``` ... ``` ä¸­çš„ JSON
    3. æœ€ä½³åŠªåŠ›ï¼šä»æ–‡æœ¬ä¸­æå–ç¬¬ä¸€ä¸ª `{...}` å¯¹è±¡
    
    å‚æ•°:
        text: LLM çš„åŸå§‹è¾“å‡ºæ–‡æœ¬ï¼ˆå¯èƒ½åŒ…å«è§£é‡Šæ€§æ–‡å­— + JSONï¼‰
    
    è¿”å›:
        è§£ææˆåŠŸçš„å·¥å…·è°ƒç”¨å­—å…¸ï¼ˆåŒ…å« "tool" å’Œ "args" é”®ï¼‰ï¼Œå¤±è´¥è¿”å› None
    
    æµç¨‹å›¾: è§ `agent_loop_parse_tool_call_flow.svg`
    """
    text = text.strip()
    # Allow the model to include explanations; try to extract JSON object from:
    # 1) raw text that is a JSON object
    # 2) fenced ```json ... ``` block
    # 3) first {...} object in the text (best-effort)
    candidates: list[str] = []
    if text.startswith("{") and text.endswith("}"):
        candidates.append(text)
    if "```" in text:
        for fence in ("```json", "```JSON", "```"):
            if fence in text:
                parts = text.split(fence, 1)
                if len(parts) == 2:
                    body = parts[1]
                    body = body.split("```", 1)[0]
                    body = body.strip()
                    if body.startswith("{") and body.endswith("}"):
                        candidates.append(body)
    # best-effort: find first JSON-ish object
    if "{" in text and "}" in text:
        start = text.find("{")
        end = text.rfind("}")
        if 0 <= start < end:
            candidates.append(text[start : end + 1].strip())

    obj = None
    for c in candidates:
        try:
            parsed = json.loads(c)
            if isinstance(parsed, dict):
                obj = parsed
                break
        except json.JSONDecodeError:
            continue
    if obj is None:
        return None
    if not isinstance(obj, dict):
        return None
    if "tool" not in obj or "args" not in obj:
        return None
    if not isinstance(obj["tool"], str) or not isinstance(obj["args"], dict):
        return None
    return obj


def _tool_result_to_message(name: str, tr: ToolResult, keywords: set[str] | None = None) -> str:
    """
    å°†å·¥å…·æ‰§è¡Œç»“æœè½¬æ¢ä¸ºå‘é€ç»™ LLM çš„ç»“æ„åŒ–æ¶ˆæ¯ã€‚
    
    æœ¬å‡½æ•°é‡‡ç”¨ä¸šç•Œæœ€ä½³å®è·µï¼šåªä¿ç•™å†³ç­–å…³é”®å­—æ®µå’Œå¼•ç”¨ï¼Œé¿å…å°†å®Œæ•´ payload å›å–‚ç»™æ¨¡å‹ï¼Œ
    ä»è€Œå‡å°‘ Token æ¶ˆè€—å¹¶æå‡æ¨¡å‹èšç„¦åº¦ã€‚
    
    å‚æ•°:
        name: å·¥å…·åç§°ï¼ˆå¦‚ "read_file", "grep"ï¼‰
        tr: å·¥å…·æ‰§è¡Œç»“æœï¼ˆToolResult å¯¹è±¡ï¼‰
        keywords: å¯é€‰çš„å…³é”®è¯é›†åˆï¼Œç”¨äºè¯­ä¹‰çª—å£é‡‡æ ·ï¼ˆä¼˜å…ˆä¿ç•™åŒ…å«å…³é”®è¯çš„ä»£ç ç‰‡æ®µï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²æ¶ˆæ¯ï¼Œå°†è¢«ä½œä¸º "user" è§’è‰²çš„æ¶ˆæ¯å‘é€ç»™ LLM
    
    æµç¨‹å›¾: è§ `agent_loop_tool_result_to_message_flow.svg`
    """
    # Centralized structured feedback (industry-grade stability):
    # keep decision-critical fields + references, avoid dumping full payload.
    return format_feedback_message(name, tr, keywords=keywords)


class AgentLoop:
    """
    Agent æ ¸å¿ƒå¾ªç¯ç±»ï¼Œå®ç° ReAct (Reasoning + Acting) æ¨¡å¼ã€‚
    
    è´Ÿè´£ï¼š
    - ç®¡ç† LLM å¯¹è¯ä¸Šä¸‹æ–‡
    - è§£æå·¥å…·è°ƒç”¨å¹¶æ‰§è¡Œ
    - ç­–ç•¥æ ¡éªŒï¼ˆç¡®è®¤ã€å‘½ä»¤é»‘åå•ï¼‰
    - å®¡è®¡æ—¥å¿—å’Œè°ƒè¯•è¿½è¸ª
    - ä¸Šä¸‹æ–‡çª—å£ç®¡ç†ï¼ˆå†å²è£å‰ªï¼‰
    - RAG è¯­ä¹‰æœç´¢é›†æˆ
    """
    
    def __init__(self, cfg: CludeConfig) -> None:
        """
        åˆå§‹åŒ– AgentLoop å®ä¾‹ã€‚
        
        åˆå§‹åŒ–æµç¨‹ï¼š
        1. åˆ›å»º LLM å®¢æˆ·ç«¯ï¼ˆllama.cpp HTTPï¼‰
        2. åˆå§‹åŒ–å·¥å…·é›†ï¼ˆLocalToolsï¼‰
        3. åˆå§‹åŒ–å®¡è®¡å’Œè¿½è¸ªæ—¥å¿—
        4. å¯åŠ¨åå°ç´¢å¼•æœåŠ¡ï¼ˆLanceDB RAGï¼‰
        5. ç”Ÿæˆ Repo Mapï¼ˆctagsï¼‰å¹¶æ³¨å…¥ç³»ç»Ÿæç¤ºè¯
        6. æ„å»ºåˆå§‹æ¶ˆæ¯å†å²ï¼ˆä»…åŒ…å« system æ¶ˆæ¯ï¼‰
        
        å‚æ•°:
            cfg: é…ç½®å¯¹è±¡ï¼ˆåŒ…å« LLMã€å·¥ä½œåŒºã€ç­–ç•¥ç­‰é…ç½®ï¼‰
        
        æµç¨‹å›¾: è§ `agent_loop_init_flow.svg`
        """
        self.cfg = cfg
        self.logger = get_logger(
            __name__,
            workspace_root=cfg.workspace_root,
            log_to_console=cfg.logging.log_to_console,
        )
        # åˆ›å»ºåªå†™å…¥æ–‡ä»¶çš„ loggerï¼ˆç”¨äºè®°å½• LLM è¯·æ±‚/å“åº”è¯¦æƒ…ï¼‰
        self.file_only_logger = get_logger(
            f"{__name__}.llm_detail",
            workspace_root=cfg.workspace_root,
            log_to_console=False,  # åªå†™å…¥æ–‡ä»¶ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°
        )
        # keep it simple & stable enough for MVP; later replace with uuid4
        self.session_id = f"sess_{id(self)}"
        self.logger.info(f"[dim]åˆå§‹åŒ– AgentLoopï¼Œsession_id={self.session_id}[/dim]")
        self.llm = LlamaCppHttpClient(
            base_url=cfg.llm.base_url,
            api_mode=cfg.llm.api_mode,  # type: ignore[arg-type]
            model=cfg.llm.model,
            temperature=cfg.llm.temperature,
            max_tokens=cfg.llm.max_tokens,
            timeout_s=cfg.llm.timeout_s,
        )
        self.tools = LocalTools(
            cfg.workspace_root,
            max_file_read_bytes=cfg.limits.max_file_read_bytes,
            max_output_bytes=cfg.limits.max_output_bytes,
        )
        self.audit = AuditLogger(cfg.workspace_root, self.session_id)
        self.trace = TraceLogger(cfg.workspace_root, self.session_id)
        
        # Knowledge / RAG systems
        self.indexer = IndexerService(cfg.workspace_root)
        self.indexer.start() # Start background indexing
        self.logger.info("[dim]å¯åŠ¨åå°ç´¢å¼•æœåŠ¡ï¼ˆLanceDB RAGï¼‰[/dim]")
        self.embedder = CodeEmbedder()
        self.vector_store = VectorStore(cfg.workspace_root)
        self.verifier = Verifier(cfg.workspace_root)

        # Initialize with Repo Map for better global context (Aider-style)
        import platform
        repo_map = self.tools.generate_repo_map()
        env_info = f"æ“ä½œç³»ç»Ÿ: {platform.system()} ({platform.release()})\nå½“å‰ç»å¯¹è·¯å¾„: {self.cfg.workspace_root}"
        combined_system_prompt = f"{SYSTEM_PROMPT}\n\n=== ç¯å¢ƒä¿¡æ¯ ===\n{env_info}\n\n=== ä»£ç ä»“åº“ç¬¦å·æ¦‚è§ˆ ===\n{repo_map}"
        
        self.messages: list[ChatMessage] = [
            ChatMessage(role="system", content=combined_system_prompt),
        ]
        self.logger.info("[dim]åˆå§‹åŒ–ç³»ç»Ÿæç¤ºè¯ï¼ˆåŒ…å« Repo Map å’Œç¯å¢ƒä¿¡æ¯ï¼‰[/dim]")

    def run_turn(
        self,
        user_text: str,
        *,
        confirm: Callable[[str], bool],
        debug: bool = False,
        on_event: Callable[[dict[str, Any]], None] | None = None,
    ) -> AgentTurn:
        """
        æ‰§è¡Œä¸€è½®å®Œæ•´çš„ Agent å¯¹è¯å¾ªç¯ï¼ˆReAct æ¨¡å¼ï¼‰ã€‚
        
        æ ¸å¿ƒæµç¨‹ï¼š
        1. æ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼Œæå–å…³é”®è¯ï¼ˆç”¨äºè¯­ä¹‰çª—å£é‡‡æ ·ï¼‰
        2. è¿›å…¥æœ€å¤š 20 æ¬¡çš„å·¥å…·è°ƒç”¨å¾ªç¯ï¼š
           a. è°ƒç”¨ LLM è·å–å“åº”
           b. æ£€æµ‹è¾“å‡ºå¼‚å¸¸ï¼ˆå¤è¯»å­—ç¬¦ï¼‰
           c. è§£æå·¥å…·è°ƒç”¨ JSON
           d. å¦‚æœæ— å·¥å…·è°ƒç”¨ â†’ è¿”å›æœ€ç»ˆæ–‡æœ¬
           e. å¦‚æœæœ‰å·¥å…·è°ƒç”¨ â†’ æ‰§è¡Œç­–ç•¥æ ¡éªŒï¼ˆç¡®è®¤/é»‘åå•ï¼‰
           f. æ‰§è¡Œå·¥å…·å¹¶è·å–ç»“æœ
           g. å°†ç»“æœå›å–‚ç»™ LLMï¼ˆä½œä¸º user æ¶ˆæ¯ï¼‰
           h. è£å‰ªå†å²æ¶ˆæ¯ï¼ˆä¿æŒä¸Šä¸‹æ–‡çª—å£ï¼‰
        3. å¦‚æœè¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•° â†’ è¿”å›åœæ­¢æ¶ˆæ¯
        
        å‚æ•°:
            user_text: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
            confirm: ç¡®è®¤å›è°ƒå‡½æ•°ï¼ˆç”¨äºå†™æ–‡ä»¶/æ‰§è¡Œå‘½ä»¤å‰çš„ç”¨æˆ·ç¡®è®¤ï¼‰
            debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆå†™å…¥ trace.jsonlï¼‰
            on_event: å¯é€‰çš„äº‹ä»¶å›è°ƒï¼ˆç”¨äºå®æ—¶ UI æ›´æ–°ï¼Œå¦‚ --live æ¨¡å¼ï¼‰
        
        è¿”å›:
            AgentTurn å¯¹è±¡ï¼ŒåŒ…å«æœ€ç»ˆå›å¤ã€å·¥å…·ä½¿ç”¨æ ‡å¿—ã€è¿½è¸ªIDå’Œäº‹ä»¶åˆ—è¡¨
        
        æµç¨‹å›¾: è§ `agent_loop_run_turn_flow.svg`
        """
        trace_id = f"trace_{abs(hash((self.session_id, user_text)))}"
        self.logger.info(f"[bold cyan]å¼€å§‹æ–°çš„ä¸€è½®å¯¹è¯[/bold cyan] trace_id={trace_id}")
        self.logger.info(f"[dim]ç”¨æˆ·è¾“å…¥: {user_text[:100]}{'...' if len(user_text) > 100 else ''}[/dim]")
        
        # Extract intent keywords for semantic windowing (MVP: simple regex)
        keywords = set(re.findall(r'\w{4,}', user_text.lower()))
        # Filter common non-useful words
        keywords -= {"please", "help", "find", "where", "change", "file", "code", "repo", "make"}
        if keywords:
            self.logger.debug(f"[dim]æå–å…³é”®è¯: {keywords}[/dim]")
        
        events: list[dict[str, Any]] = []
        step_idx = 0

        def _ev(event: str, data: dict[str, Any]) -> None:
            nonlocal step_idx
            step_idx += 1
            e = {"step": step_idx, "event": event, "data": data}
            events.append(e)
            if debug:
                # keep trace log verbose, but trim huge fields
                self.trace.write(trace_id=trace_id, step=step_idx, event=event, data=data)
            if on_event is not None:
                try:
                    on_event(e)
                except Exception:
                    # Never allow UI callbacks to break the agent loop.
                    pass

        def _normalize_messages_for_llama(stage: str, *, step_id: str | None = None) -> None:
            """
            å‘é€ç»™ llama.cpp å‰çš„â€œç»Ÿä¸€å‡ºå£â€è§„èŒƒåŒ–ï¼š
            - åˆå¹¶è¿ç»­çš„ user/user æˆ– assistant/assistantï¼ˆé¿å… chat template æŠ¥ 500ï¼‰
            - åˆå¹¶å¤šæ¡ system åˆ°ç¬¬ä¸€æ¡ systemï¼ˆé¿å… system/system æˆ– system æ’å…¥å¯¼è‡´ä¸äº¤æ›¿ï¼‰
            - å¦‚æœ system åæ„å¤–å‡ºç° assistantï¼Œåˆ™å¹¶å…¥ systemï¼ˆä¿æŒä¸¥æ ¼ alternationï¼‰
            å¤‡æ³¨ï¼šè¿™ä¸æ˜¯â€œæ”¹é€»è¾‘â€ï¼Œåªæ˜¯â€œä¿è¯è¾“å…¥å¥‘çº¦æ»¡è¶³åç«¯æ¨¡æ¿çº¦æŸâ€ã€‚
            """
            if not self.messages:
                return

            original_len = len(self.messages)
            merged_pairs = 0
            merged_system = 0
            merged_into_system_from_assistant = 0

            # 1) ä¿ç•™/åˆå¹¶ system
            system_msg: ChatMessage | None = None
            idx = 0
            if self.messages[0].role == "system":
                system_msg = self.messages[0]
                idx = 1

            out: list[ChatMessage] = []
            if system_msg is not None:
                out.append(system_msg)

            expected = "user"  # system åå¿…é¡»ä» user å¼€å§‹

            # 2) é€æ¡è§„èŒƒåŒ–
            for m in self.messages[idx:]:
                role = m.role
                content = m.content

                # å¤š systemï¼šå¹¶å…¥ç¬¬ä¸€æ¡ system
                if role == "system":
                    if out and out[0].role == "system":
                        merged_system += 1
                        out[0] = ChatMessage(
                            role="system",
                            content=out[0].content + "\n\n" + content,
                        )
                        continue
                    # æ²¡æœ‰ system åˆ™ä½œä¸º system èµ·å§‹
                    out.insert(0, m)
                    continue

                # system åå‡ºç° assistantï¼ˆä¸ç¬¦åˆä¸¥æ ¼æ¨¡æ¿ï¼‰ï¼šå¹¶å…¥ system
                if expected == "user" and (not out or out[-1].role == "system") and role == "assistant":
                    if out and out[0].role == "system":
                        merged_into_system_from_assistant += 1
                        out[0] = ChatMessage(
                            role="system",
                            content=out[0].content + "\n\n" + "[å†å² assistant å‰ç½®ä¿¡æ¯]\n" + content,
                        )
                        continue
                    # æ²¡æœ‰ system æ—¶ï¼Œç›´æ¥ä¸¢å¼ƒè¿™æ¡ assistantï¼ˆæå°‘è§ï¼‰
                    merged_pairs += 1
                    continue

                # æ­£å¸¸äº¤æ›¿ï¼šæŒ‰ expected æ¥å…¥
                if role == expected:
                    out.append(m)
                    expected = "assistant" if expected == "user" else "user"
                    continue

                # éé¢„æœŸè§’è‰²ï¼šåªå¯èƒ½æ˜¯è¿ç»­ user/user æˆ– assistant/assistant
                if out and out[-1].role == role:
                    merged_pairs += 1
                    out[-1] = ChatMessage(role=role, content=out[-1].content + "\n\n" + content)
                    continue

                # å…œåº•ï¼šæ— æ³•è§£é‡Šçš„é¡ºåºï¼Œå°½é‡å¹¶å…¥ä¸Šä¸€æ¡ï¼ˆé¿å…æ–°å¢ç ´åäº¤æ›¿ï¼‰
                if out:
                    merged_pairs += 1
                    out[-1] = ChatMessage(role=out[-1].role, content=out[-1].content + "\n\n" + content)
                    continue

            # 3) è‹¥å‘ç”Ÿå˜åŒ–ï¼Œå›å†™ self.messagesï¼Œå¹¶ä¸ŠæŠ¥äº‹ä»¶ç”¨äº UI/è°ƒè¯•
            if len(out) != original_len or merged_pairs or merged_system or merged_into_system_from_assistant:
                self.messages = out
                self._trim_history(max_messages=30)
                _ev(
                    "messages_normalized",
                    {
                        "stage": stage,
                        "step_id": step_id,
                        "before": original_len,
                        "after": len(self.messages),
                        "merged_pairs": merged_pairs,
                        "merged_system": merged_system,
                        "merged_assistant_into_system": merged_into_system_from_assistant,
                    },
                )

        def _llm_chat(stage: str, *, step_id: str | None = None) -> str:
            """
            llama.cpp è°ƒç”¨ç»Ÿä¸€å‡ºå£ï¼š
            - å…ˆåš messages è§„èŒƒåŒ–ï¼ˆä¿è¯ role äº¤æ›¿ï¼‰
            - å†å‘èµ· HTTP è¯·æ±‚
            """
            _normalize_messages_for_llama(stage, step_id=step_id)
            return self.llm.chat(self.messages)

        # ---- Phase 3: Explicit Planning & Two-level Orchestration ----
        current_state: AgentState = AgentState.INTAKE

        def _set_state(state: AgentState, info: dict[str, Any] | None = None) -> None:
            nonlocal current_state
            current_state = state
            payload = {"state": state.value}
            if info:
                payload.update(info)
            _ev("state", payload)

        # æ³¨æ„ï¼šllama.cpp çš„ chat template å¯èƒ½è¦æ±‚ä¸¥æ ¼ user/assistant äº¤æ›¿ã€‚
        # å› æ­¤åœ¨â€œè§„åˆ’é˜¶æ®µâ€æˆ‘ä»¬ä¸èƒ½å†é¢å¤–æ’å…¥ä¸€ä¸ªè¿ç»­çš„ user æ¶ˆæ¯ã€‚
        # åšæ³•ï¼šæŠŠâ€œè¿›å…¥è§„åˆ’â€çš„æç¤ºå¹¶å…¥åŒä¸€æ¡ user æ¶ˆæ¯å†…å®¹ä¸­ï¼ˆä»ä¿ç•™åŸå§‹ user_text çš„å®¡è®¡è®°å½•ï¼‰ã€‚
        planning_prompt = None
        if self.cfg.orchestrator.enable_planning:
            planning_prompt = (
                "ç°åœ¨è¿›å…¥ã€è§„åˆ’é˜¶æ®µã€‘ã€‚è¯·å…ˆè¾“å‡ºä¸€ä¸ªä¸¥æ ¼çš„ JSON å¯¹è±¡ï¼ˆä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šã€ä¸è¦è°ƒç”¨å·¥å…·ï¼‰ã€‚\n"
                "JSON å¿…é¡»ç¬¦åˆä»¥ä¸‹ç»“æ„ï¼š\n"
                "{\n"
                '  \"title\": \"ä»»åŠ¡å…¨å±€ç›®æ ‡\",\n'
                '  \"steps\": [\n'
                "    {\n"
                '      \"id\": \"step_1\",\n'
                '      \"description\": \"å¯æ‰§è¡Œä¸”å¯éªŒè¯çš„åŠ¨ä½œï¼ˆå¯è·¨æ–‡ä»¶ï¼‰\",\n'
                '      \"dependencies\": [],\n'
                '      \"status\": \"pending\",\n'
                '      \"tools_expected\": [\"read_file\",\"grep\",\"apply_patch\"]\n'
                "    }\n"
                "  ],\n"
                '  \"verification_policy\": \"run_verify\" \n'
                "}\n\n"
                f"è¦æ±‚ï¼šsteps ä¸è¶…è¿‡ {self.cfg.orchestrator.max_plan_steps} æ­¥ï¼›æ¯æ­¥å°½é‡å°ä¸”æ˜ç¡®ã€‚"
            )

        self.audit.write(trace_id=trace_id, event="user_message", data={"text": user_text})
        _ev("user_message", {"text": user_text})
        user_content = user_text if not planning_prompt else (user_text + "\n\n" + planning_prompt)
        self.messages.append(ChatMessage(role="user", content=user_content))
        # Keep history bounded to reduce context size
        self._trim_history(max_messages=30)
        self.logger.debug(f"[dim]å½“å‰æ¶ˆæ¯å†å²é•¿åº¦: {len(self.messages)}[/dim]")

        tool_used = False
        did_modify_code = False

        # 1) è§„åˆ’é˜¶æ®µï¼šå°è¯•ç”Ÿæˆæ˜¾å¼ Planï¼ˆè·¨æ–‡ä»¶ä»»åŠ¡æ›´ç¨³å¥ï¼‰
        plan: Plan | None = None
        if self.cfg.orchestrator.enable_planning:
            _set_state(AgentState.PLANNING, {"reason": "enable_planning"})
            self.logger.info("[bold magenta]ğŸ§© è¿›å…¥è§„åˆ’é˜¶æ®µï¼šç”Ÿæˆæ˜¾å¼ Plan[/bold magenta]")

            plan_attempts = 0
            while plan_attempts <= self.cfg.orchestrator.planning_retry:
                plan_attempts += 1
                _ev("planning_llm_request", {"attempt": plan_attempts})
                assistant_plan = _llm_chat("planning", step_id=None)
                _ev("planning_llm_response", {"text": assistant_plan[:4000], "truncated": len(assistant_plan) > 4000})

                # ä¿å­˜ assistant è¾“å‡ºï¼Œä¿æŒå¯¹è¯å®Œæ•´å¯å›æ”¾
                self.messages.append(ChatMessage(role="assistant", content=assistant_plan))
                self._trim_history(max_messages=30)
                try:
                    parsed = parse_plan_from_text(assistant_plan)
                    # è½¯é™åˆ¶ï¼šæˆªæ–­è¿‡é•¿è®¡åˆ’
                    if len(parsed.steps) > self.cfg.orchestrator.max_plan_steps:
                        parsed.steps = parsed.steps[: self.cfg.orchestrator.max_plan_steps]
                    plan = parsed
                    self.audit.write(
                        trace_id=trace_id,
                        event="plan_generated",
                        data={"title": plan.title, "steps": [s.model_dump() for s in plan.steps]},
                    )
                    _ev("plan_generated", {"title": plan.title, "steps": len(plan.steps)})
                    self.logger.info("[green]âœ“ è®¡åˆ’ç”ŸæˆæˆåŠŸ[/green]")
                    # å±•ç¤ºè®¡åˆ’æ‘˜è¦ï¼ˆä¾¿äºç”¨æˆ· review å’Œè°ƒè¯•ï¼‰
                    plan_summary = render_plan_markdown(plan)
                    self.logger.info(f"[dim]è®¡åˆ’æ‘˜è¦:\n{plan_summary}[/dim]")
                    self.file_only_logger.info("ç”Ÿæˆè®¡åˆ’:\n" + plan_summary)
                    break
                except Exception as e:
                    self.logger.warning(f"[yellow]âš  è®¡åˆ’è§£æå¤±è´¥ï¼ˆattempt={plan_attempts}ï¼‰: {e}[/yellow]")
                    self.audit.write(trace_id=trace_id, event="plan_parse_failed", data={"attempt": plan_attempts, "error": str(e)})
                    _ev("plan_parse_failed", {"attempt": plan_attempts, "error": str(e)})
                    # ç»™æ¨¡å‹ä¸€æ¬¡è‡ªçº æœºä¼š
                    self.messages.append(
                        ChatMessage(
                            role="user",
                            content="ä¸Šé¢çš„è¾“å‡ºæ— æ³•è§£æä¸º Plan JSONã€‚è¯·åªè¾“å‡ºä¸€ä¸ªä¸¥æ ¼ JSON å¯¹è±¡ï¼ˆä¸è¦è§£é‡Šï¼Œä¸è¦ä»£ç å—ï¼‰ã€‚",
                        )
                    )
                    self._trim_history(max_messages=30)

        # 2) æ‰§è¡Œé˜¶æ®µï¼šæœ‰ Plan å°±æŒ‰æ­¥æ‰§è¡Œï¼›å¦åˆ™é™çº§ä¸ºæ—§çš„ ReAct å¾ªç¯
        if plan is not None:
            _set_state(AgentState.EXECUTING, {"steps": len(plan.steps)})
            self.logger.info("[bold magenta]â–¶ è¿›å…¥æ‰§è¡Œé˜¶æ®µï¼šæŒ‰ Plan æ­¥éª¤ç¼–æ’[/bold magenta]")

            replans_used = 0
            step_cursor = 0
            while True:
                if plan is None:
                    break
                if step_cursor >= len(plan.steps):
                    break

                step = plan.steps[step_cursor]

                # ä¾èµ–æ£€æŸ¥ï¼šç¡®ä¿æ‰€æœ‰ä¾èµ–æ­¥éª¤å·²å®Œæˆ
                completed_ids = {s.id for s in plan.steps if s.status == "done"}
                unmet_deps = [dep for dep in step.dependencies if dep not in completed_ids]
                if unmet_deps:
                    self.logger.warning(f"[yellow]âš  æ­¥éª¤ {step.id} æœ‰æœªæ»¡è¶³çš„ä¾èµ–: {unmet_deps}ï¼Œè·³è¿‡å¹¶æ ‡è®°ä¸º blocked[/yellow]")
                    step.status = "blocked"
                    self.audit.write(trace_id=trace_id, event="plan_step_blocked", data={"step_id": step.id, "unmet_deps": unmet_deps})
                    _ev("plan_step_blocked", {"step_id": step.id, "unmet_deps": unmet_deps})
                    step_cursor += 1
                    continue

                step.status = "in_progress"
                self.audit.write(trace_id=trace_id, event="plan_step_start", data={"step_id": step.id, "description": step.description})
                _ev("plan_step_start", {"step_id": step.id, "idx": step_cursor + 1, "total": len(plan.steps)})

                # æ¯ä¸ªæ­¥éª¤å†…éƒ¨ï¼Œå…è®¸è‹¥å¹²æ¬¡å·¥å…·è°ƒç”¨ï¼ˆé˜²æ­¢æ­»å¾ªç¯ï¼‰
                for iteration in range(self.cfg.orchestrator.max_step_tool_calls):
                    self.logger.info(
                        f"[bold yellow]â†’ æ‰§è¡Œæ­¥éª¤ {step_cursor + 1}/{len(plan.steps)}: {step.id}ï¼ˆè½®æ¬¡ {iteration + 1}/{self.cfg.orchestrator.max_step_tool_calls}ï¼‰[/bold yellow]"
                    )
                    _ev("llm_request", {"messages": len(self.messages), "step_id": step.id, "iteration": iteration + 1})

                    step_prompt = (
                        f"ç°åœ¨æ‰§è¡Œè®¡åˆ’æ­¥éª¤ï¼š{step.id}\n"
                        f"æ­¥éª¤æè¿°ï¼š{step.description}\n"
                        f"å»ºè®®å·¥å…·ï¼š{', '.join(step.tools_expected) if step.tools_expected else 'ï¼ˆè‡ªè¡Œé€‰æ‹©ï¼‰'}\n\n"
                        "è§„åˆ™ï¼š\n"
                        "1) å¦‚æœéœ€è¦å·¥å…·ï¼šåªè¾“å‡ºä¸€ä¸ªå·¥å…·è°ƒç”¨ JSONï¼ˆä¸ç³»ç»Ÿè¦æ±‚ä¸€è‡´ï¼‰ã€‚\n"
                        "2) å¦‚æœæœ¬æ­¥éª¤å·²å®Œæˆä¸”ä¸éœ€è¦å·¥å…·ï¼šåªè¾“å‡ºå­—ç¬¦ä¸²ã€STEP_DONEã€‘ã€‚\n"
                        "3) å¦‚æœæœ¬æ­¥éª¤å¤±è´¥ä¸”éœ€è¦é‡è§„åˆ’ï¼šåªè¾“å‡ºå­—ç¬¦ä¸²ã€REPLANã€‘ã€‚\n"
                    )
                    self.messages.append(ChatMessage(role="user", content=step_prompt))
                    self._trim_history(max_messages=30)

                    assistant = _llm_chat("execute_step", step_id=step.id)
                    _ev("llm_response", {"text": assistant[:4000], "truncated": len(assistant) > 4000, "step_id": step.id})

                    # stuttering é˜²æŠ¤æ²¿ç”¨
                    if assistant.count("[") > 50 or assistant.count("{") > 50:
                        self.logger.warning("[red]æ£€æµ‹åˆ°æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼ˆå¤è¯»å­—ç¬¦ï¼‰ï¼Œå·²å¼ºåˆ¶æˆªæ–­[/red]")
                        assistant = "æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼šæ£€æµ‹åˆ°è¿‡å¤šçš„é‡å¤å­—ç¬¦ï¼Œå·²å¼ºåˆ¶æˆªæ–­ã€‚"
                        _ev("stuttering_detected", {"length": len(assistant), "step_id": step.id})

                    # å…ˆæ£€æŸ¥æ§åˆ¶æ ‡è®°ï¼ˆå®¹é”™ï¼šå…è®¸æ¨¡å‹è¾“å‡ºé¢å¤–ç©ºæ ¼ã€æ¢è¡Œæˆ–å¸¦ä¸­æ–‡æ ‡ç‚¹ï¼‰
                    a_strip = assistant.strip()
                    # å®¹é”™åŒ¹é… STEP_DONE
                    if "STEP_DONE" in a_strip or "ã€STEP_DONEã€‘" in a_strip or a_strip.upper().startswith("STEP_DONE"):
                        self.messages.append(ChatMessage(role="assistant", content=assistant))
                        self._trim_history(max_messages=30)
                        step.status = "done"
                        self.audit.write(trace_id=trace_id, event="plan_step_done", data={"step_id": step.id})
                        _ev("plan_step_done", {"step_id": step.id})
                        break
                    # å®¹é”™åŒ¹é… REPLAN
                    if "REPLAN" in a_strip or "ã€REPLANã€‘" in a_strip or a_strip.upper().startswith("REPLAN"):
                        self.messages.append(ChatMessage(role="assistant", content=assistant))
                        self._trim_history(max_messages=30)
                        step.status = "failed"
                        self.audit.write(trace_id=trace_id, event="plan_step_replan_requested", data={"step_id": step.id})
                        _ev("plan_step_replan_requested", {"step_id": step.id})
                        break

                    # å°è¯•è§£æå·¥å…·è°ƒç”¨
                    tool_call = _try_parse_tool_call(assistant)
                    if tool_call is None:
                        # æœªç»™å‡ºå·¥å…·ï¼Œä¹Ÿæ²¡ç»™å‡º DONE/REPLANï¼šæç¤ºæ¨¡å‹çº æ­£ï¼Œç»§ç»­æœ¬æ­¥éª¤
                        self.messages.append(ChatMessage(role="assistant", content=assistant))
                        self._trim_history(max_messages=30)
                        self.messages.append(
                            ChatMessage(
                                role="user",
                                content="ä½ çš„è¾“å‡ºæ—¢ä¸æ˜¯å·¥å…·è°ƒç”¨ JSONï¼Œä¹Ÿä¸æ˜¯ã€STEP_DONEã€‘/ã€REPLANã€‘ã€‚è¯·ä¸¥æ ¼æŒ‰è§„åˆ™è¾“å‡ºã€‚",
                            )
                        )
                        self._trim_history(max_messages=30)
                        continue

                    name = tool_call["tool"]
                    args = tool_call["args"]
                    _ev("tool_call_parsed", {"tool": name, "args": args, "step_id": step.id})

                    # è®°å½• assistant çš„å·¥å…·è°ƒç”¨ JSONï¼ˆä¿æŒ llama.cpp role äº¤æ›¿ï¼‰
                    clean_assistant = json.dumps(tool_call, ensure_ascii=False)
                    self.messages.append(ChatMessage(role="assistant", content=clean_assistant))
                    self._trim_history(max_messages=30)

                    # confirmations + policyï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰
                    if name in {"write_file", "apply_patch", "undo_patch"} and self.cfg.policy.confirm_write:
                        decision = confirm(f"ç¡®è®¤å†™æ–‡ä»¶ï¼Ÿtool={name} args={args}")
                        self.audit.write(trace_id=trace_id, event="confirm_write", data={"tool": name, "args": args, "allow": decision})
                        _ev("confirm_write", {"tool": name, "allow": decision, "step_id": step.id})
                        if not decision:
                            msg = _tool_result_to_message(name, ToolResult(False, error={"code": "E_DENIED", "message": "user denied"}), keywords=keywords)
                            self.messages.append(ChatMessage(role="user", content=msg))
                            self._trim_history(max_messages=30)
                            continue

                    if name == "run_cmd" and self.cfg.policy.confirm_exec:
                        decision = confirm(f"ç¡®è®¤æ‰§è¡Œå‘½ä»¤ï¼Ÿtool={name} args={args}")
                        self.audit.write(trace_id=trace_id, event="confirm_exec", data={"tool": name, "args": args, "allow": decision})
                        _ev("confirm_exec", {"tool": name, "allow": decision, "step_id": step.id})
                        if not decision:
                            msg = _tool_result_to_message(name, ToolResult(False, error={"code": "E_DENIED", "message": "user denied"}), keywords=keywords)
                            self.messages.append(ChatMessage(role="user", content=msg))
                            self._trim_history(max_messages=30)
                            continue

                    if name == "run_cmd":
                        cmd_str = str(args.get("command", ""))
                        dec = evaluate_command(cmd_str, allow_network=self.cfg.policy.allow_network)
                        if not dec.ok:
                            self.audit.write(trace_id=trace_id, event="policy_deny_cmd", data={"command": cmd_str, "reason": dec.reason})
                            _ev("policy_deny_cmd", {"command": cmd_str, "reason": dec.reason, "step_id": step.id})
                            msg = _tool_result_to_message(name, ToolResult(False, error={"code": "E_POLICY_DENIED", "message": dec.reason}), keywords=keywords)
                            self.messages.append(ChatMessage(role="user", content=msg))
                            self._trim_history(max_messages=30)
                            continue

                    tool_used = True
                    result = self._dispatch_tool(name, args)

                    if name in {"write_file", "apply_patch", "undo_patch"} and result.ok:
                        did_modify_code = True

                    # Phase2 éªŒè¯é—­ç¯ï¼šä¿æŒç°æœ‰è¡Œä¸ºï¼ˆå·¥å…·åè§¦å‘ï¼‰
                    if result.ok and name in {"write_file", "apply_patch", "undo_patch", "run_cmd"}:
                        v_res = self.verifier.run_verify()
                        _ev("autofix_check", {"ok": v_res.ok, "type": v_res.type, "summary": v_res.summary, "step_id": step.id})
                        if not v_res.ok:
                            v_msg = f"\n\n[éªŒè¯å¤±è´¥ - è‡ªåŠ¨è‡ªæ£€ç»“æœ]\nçŠ¶æ€: {v_res.summary}\n"
                            if v_res.errors:
                                v_msg += "å…·ä½“é”™è¯¯:\n"
                                for err in v_res.errors:
                                    v_msg += f"- {err.file}:{err.line} {err.message}\n"
                            if result.payload is None:
                                result = ToolResult(ok=True, payload={"verification_error": v_msg})
                            else:
                                result.payload["verification_error"] = v_msg

                    _ev("tool_result", {"tool": name, "ok": result.ok, "error": result.error, "step_id": step.id})
                    self.messages.append(ChatMessage(role="user", content=_tool_result_to_message(name, result, keywords=keywords)))
                    self._trim_history(max_messages=30)
                    self.audit.write(trace_id=trace_id, event="tool_call", data={"tool": name, "args": args, "ok": result.ok, "error": result.error})

                # æ­¥éª¤è¿­ä»£å¾ªç¯ç»“æŸåå¼ºåˆ¶ç†”æ–­ï¼šå¦‚æœçŠ¶æ€ä»æ˜¯ in_progressï¼Œæ ‡è®°ä¸º failedï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
                if step.status == "in_progress":
                    self.logger.warning(f"[yellow]âš  æ­¥éª¤ {step.id} è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ä½†æœªå®Œæˆï¼Œå¼ºåˆ¶æ ‡è®°ä¸º failed[/yellow]")
                    step.status = "failed"
                    self.audit.write(trace_id=trace_id, event="plan_step_max_iter", data={"step_id": step.id, "max_iter": self.cfg.orchestrator.max_step_tool_calls})
                    _ev("plan_step_max_iter", {"step_id": step.id, "max_iter": self.cfg.orchestrator.max_step_tool_calls})

                # æ­¥éª¤ç»“æŸåï¼Œæ ¹æ®çŠ¶æ€æ¨è¿›
                if step.status == "done":
                    step_cursor += 1
                    continue

                # å¦‚æœæ­¥éª¤è¦æ±‚é‡è§„åˆ’ï¼šé™åˆ¶æ¬¡æ•°ï¼Œé¿å…æ— é™å¾ªç¯
                if step.status == "failed":
                    if replans_used >= self.cfg.orchestrator.max_replans:
                        self.logger.warning("[red]âš  è¾¾åˆ°æœ€å¤§é‡è§„åˆ’æ¬¡æ•°ï¼Œåœæ­¢[/red]")
                        _ev("stop_reason", {"reason": "max_replans_reached", "limit": self.cfg.orchestrator.max_replans})
                        return AgentTurn(
                            assistant_text="è¾¾åˆ°æœ€å¤§é‡è§„åˆ’æ¬¡æ•°ï¼Œå·²åœæ­¢ã€‚è¯·ç¼©å°ä»»åŠ¡æˆ–æä¾›æ›´æ˜ç¡®çš„å…¥å£æ–‡ä»¶/ç›®æ ‡ã€‚",
                            tool_used=tool_used,
                            trace_id=trace_id,
                            events=events,
                        )

                    replans_used += 1
                    # å…ˆè¿›å…¥ RECOVERING çŠ¶æ€ï¼ˆç”¨äº UI å±•ç¤ºå’Œå®¡è®¡ï¼‰
                    _set_state(AgentState.RECOVERING, {"reason": "step_failed", "step_id": step.id, "replans_used": replans_used})
                    _set_state(AgentState.PLANNING, {"reason": "replan", "replans_used": replans_used})
                    self.logger.info(f"[bold magenta]ğŸ” è§¦å‘é‡è§„åˆ’ï¼ˆç¬¬ {replans_used} æ¬¡ï¼‰[/bold magenta]")

                    replan_prompt = (
                        "å‡ºç°é˜»å¡/å¤±è´¥ï¼Œéœ€è¦é‡è§„åˆ’ã€‚è¯·è¾“å‡ºæ–°çš„ Plan JSONï¼ˆä¸¥æ ¼ JSONï¼Œä¸è¦è§£é‡Šï¼Œä¸è¦è°ƒç”¨å·¥å…·ï¼‰ã€‚\n"
                        f"é™åˆ¶ï¼šsteps ä¸è¶…è¿‡ {self.cfg.orchestrator.max_plan_steps}ã€‚\n"
                        "è¯·ç»“åˆå½“å‰å¯¹è¯ä¸­çš„é”™è¯¯ä¸å·¥å…·åé¦ˆï¼Œç”Ÿæˆæ›´å¯æ‰§è¡Œçš„æ­¥éª¤ã€‚"
                    )
                    self.messages.append(ChatMessage(role="user", content=replan_prompt))
                    self._trim_history(max_messages=30)
                    assistant_plan = _llm_chat("replan", step_id=step.id)
                    self.messages.append(ChatMessage(role="assistant", content=assistant_plan))
                    self._trim_history(max_messages=30)
                    try:
                        plan = parse_plan_from_text(assistant_plan)
                        if len(plan.steps) > self.cfg.orchestrator.max_plan_steps:
                            plan.steps = plan.steps[: self.cfg.orchestrator.max_plan_steps]
                        self.audit.write(
                            trace_id=trace_id,
                            event="plan_replanned",
                            data={"title": plan.title, "steps": [s.model_dump() for s in plan.steps], "replans_used": replans_used},
                        )
                        _ev("plan_replanned", {"title": plan.title, "steps": len(plan.steps), "replans_used": replans_used})
                        _set_state(AgentState.EXECUTING, {"steps": len(plan.steps)})
                        step_cursor = 0
                        continue
                    except Exception as e:
                        self.logger.warning(f"[yellow]âš  é‡è§„åˆ’è§£æå¤±è´¥: {e}[/yellow]")
                        self.audit.write(trace_id=trace_id, event="plan_replan_parse_failed", data={"error": str(e)})
                        _ev("plan_replan_parse_failed", {"error": str(e)})
                        # å¤±è´¥åˆ™é™çº§é€€å‡º
                        return AgentTurn(
                            assistant_text="é‡è§„åˆ’å¤±è´¥ï¼ˆæ— æ³•è§£æ Plan JSONï¼‰ã€‚è¯·æ‰‹åŠ¨æä¾›æ›´æ˜ç¡®çš„æ‹†åˆ†æ­¥éª¤æˆ–å…¥å£æ–‡ä»¶ã€‚",
                            tool_used=tool_used,
                            trace_id=trace_id,
                            events=events,
                        )

                # å¤„ç† blocked æ­¥éª¤ï¼šæ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ­¥éª¤éƒ½è¢« blockedï¼ˆæ­»é”æ£€æµ‹ï¼‰
                if step.status == "blocked":
                    all_blocked_or_done = all(s.status in ("blocked", "done") for s in plan.steps)
                    if all_blocked_or_done and any(s.status == "blocked" for s in plan.steps):
                        self.logger.error("[red]âœ— æ£€æµ‹åˆ°ä¾èµ–æ­»é”ï¼šæ‰€æœ‰æœªå®Œæˆæ­¥éª¤éƒ½å¤„äº blocked çŠ¶æ€[/red]")
                        _ev("stop_reason", {"reason": "dependency_deadlock"})
                        return AgentTurn(
                            assistant_text="æ£€æµ‹åˆ°ä¾èµ–æ­»é”ï¼šæ‰€æœ‰æœªå®Œæˆæ­¥éª¤éƒ½å¤„äº blocked çŠ¶æ€ã€‚è¯·æ£€æŸ¥è®¡åˆ’ä¸­çš„ä¾èµ–å…³ç³»ã€‚",
                            tool_used=tool_used,
                            trace_id=trace_id,
                            events=events,
                        )
                    step_cursor += 1
                    continue

                # å…¶ä»–çŠ¶æ€ï¼ˆå¡ä½/æœªå®Œæˆï¼‰ï¼šç†”æ–­
                _ev("stop_reason", {"reason": "step_not_completed", "step_id": step.id})
                return AgentTurn(
                    assistant_text=f"æ­¥éª¤æœªèƒ½å®Œæˆä¸”æœªè§¦å‘é‡è§„åˆ’ï¼š{step.id}ã€‚è¯·ç¼©å°è¯¥æ­¥éª¤æˆ–æä¾›æ›´å¤šçº¦æŸã€‚",
                    tool_used=tool_used,
                    trace_id=trace_id,
                    events=events,
                )

            # 3) æœ€ç»ˆéªŒè¯é˜¶æ®µï¼ˆå¦‚æœæœ¬è½®æœ‰ä¿®æ”¹ä»£ç ï¼‰
            _set_state(AgentState.VERIFYING, {"did_modify_code": did_modify_code})
            if did_modify_code:
                self.logger.info("[bold magenta]ğŸ” è¿›å…¥æœ€ç»ˆéªŒè¯é˜¶æ®µ[/bold magenta]")
                v_res = self.verifier.run_verify()
                _ev("final_verify", {"ok": v_res.ok, "type": v_res.type, "summary": v_res.summary})
                if not v_res.ok:
                    # æœ€ç»ˆéªŒè¯å¤±è´¥ï¼šä½œä¸ºæœ€ç»ˆè¾“å‡ºè¿”å›ï¼ˆä¹Ÿå¯åœ¨æœªæ¥å¼•å…¥è‡ªåŠ¨ä¿®å¤å›åˆï¼‰
                    text = f"æœ€ç»ˆéªŒè¯å¤±è´¥ï¼š{v_res.summary}\n"
                    if v_res.errors:
                        for err in v_res.errors[:10]:
                            text += f"- {err.file}:{err.line} {err.message}\n"
                    _set_state(AgentState.DONE, {"ok": False})
                    return AgentTurn(assistant_text=text, tool_used=tool_used, trace_id=trace_id, events=events)

            _set_state(AgentState.DONE, {"ok": True})
            return AgentTurn(
                assistant_text=f"è®¡åˆ’æ‰§è¡Œå®Œæˆï¼š{plan.title}\nï¼ˆå·²æŒ‰æ­¥éª¤æ‰§è¡Œå¹¶å®Œæˆè‡ªæ£€ï¼‰",
                tool_used=tool_used,
                trace_id=trace_id,
                events=events,
            )

        # ---- Fallback: original single-level ReAct loop ----
        _set_state(AgentState.EXECUTING, {"mode": "react_fallback"})
        for iteration in range(20):  # hard stop to avoid infinite loops
            self.logger.info(f"[bold yellow]â†’ ç¬¬ {iteration + 1} è½®ï¼šè¯·æ±‚ LLMï¼ˆæ¶ˆæ¯æ•°={len(self.messages)}ï¼‰[/bold yellow]")
            _ev("llm_request", {"messages": len(self.messages)})
            
            # è®°å½•è¯·æ±‚å‚æ•°åˆ°æ–‡ä»¶ï¼ˆä¸è¾“å‡ºåˆ°å±å¹•ï¼‰
            request_params = {
                "model": self.llm.model,
                "temperature": self.llm.temperature,
                "max_tokens": self.llm.max_tokens,
                "api_mode": self.llm.api_mode,
                "base_url": self.llm.base_url,
                "messages_count": len(self.messages),
                "messages": [
                    {
                        "role": msg.role,
                        "content_preview": msg.content[:200] + "..." if len(msg.content) > 200 else msg.content,
                        "content_length": len(msg.content),
                    }
                    for msg in self.messages
                ],
            }
            self.file_only_logger.info(f"è¯·æ±‚å¤§æ¨¡å‹å‚æ•°: {json.dumps(request_params, ensure_ascii=False, indent=2)}")
            
            assistant = _llm_chat("react_fallback", step_id=None)
            
            # Robustness: Detect repetitive/broken outputs (stuttering)
            if assistant.count("[") > 50 or assistant.count("{") > 50:
                self.logger.warning("[red]æ£€æµ‹åˆ°æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼ˆå¤è¯»å­—ç¬¦ï¼‰ï¼Œå·²å¼ºåˆ¶æˆªæ–­[/red]")
                assistant = "æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼šæ£€æµ‹åˆ°è¿‡å¤šçš„é‡å¤å­—ç¬¦ï¼Œå·²å¼ºåˆ¶æˆªæ–­ã€‚è¯·é‡æ–°æè¿°ä½ çš„éœ€æ±‚æˆ–å°è¯•ç¼©å°ä»»åŠ¡èŒƒå›´ã€‚"
                _ev("stuttering_detected", {"length": len(assistant)})

            _ev("llm_response", {"text": assistant[:4000], "truncated": len(assistant) > 4000})
            self.logger.debug(f"[dim]LLM å“åº”é•¿åº¦: {len(assistant)} å­—ç¬¦[/dim]")
            
            # è§£æå·¥å…·è°ƒç”¨ï¼ˆåªè§£æä¸€æ¬¡ï¼‰
            tool_call = _try_parse_tool_call(assistant)
            
            # è®°å½•å“åº”æ•°æ®åˆ°æ–‡ä»¶ï¼ˆä¸è¾“å‡ºåˆ°å±å¹•ï¼‰
            response_data = {
                "text_length": len(assistant),
                "text_preview": assistant[:500] + "..." if len(assistant) > 500 else assistant,
                "truncated": len(assistant) > 500,
                "has_tool_call": tool_call is not None,
                "tool_call": tool_call if tool_call else None,
            }
            self.file_only_logger.info(f"å¤§æ¨¡å‹è¿”å›æ•°æ®: {json.dumps(response_data, ensure_ascii=False, indent=2)}")
            if tool_call is None:
                self.logger.info("[bold green]âœ“ LLM è¿”å›æœ€ç»ˆå›å¤ï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰[/bold green]")
                self.messages.append(ChatMessage(role="assistant", content=assistant))
                self.audit.write(trace_id=trace_id, event="assistant_text", data={"text": assistant})
                _ev("final_text", {"text": assistant[:4000], "truncated": len(assistant) > 4000})
                self._trim_history(max_messages=30)
                return AgentTurn(assistant_text=assistant, tool_used=tool_used, trace_id=trace_id, events=events)

            name = tool_call["tool"]
            args = tool_call["args"]
            self.logger.info(f"[bold blue]ğŸ”§ è§£æåˆ°å·¥å…·è°ƒç”¨: {name}[/bold blue]")
            self.logger.debug(f"[dim]å·¥å…·å‚æ•°: {json.dumps(args, ensure_ascii=False, indent=2)[:200]}[/dim]")
            _ev("tool_call_parsed", {"tool": name, "args": args})

            # Robustness: Keep assistant history clean. 
            # If there's a tool call, we only store the JSON part in the message history
            # to prevent the model from getting distracted by its own previous CoT/noise.
            clean_assistant = json.dumps(tool_call, ensure_ascii=False)
            self.messages.append(ChatMessage(role="assistant", content=clean_assistant))
            
            _ev("assistant_tool_call_recorded", {"tool": name})
            self._trim_history(max_messages=30)

            # policy confirmations (MVP): only guard write/exec
            if name in {"write_file", "apply_patch", "undo_patch"} and self.cfg.policy.confirm_write:
                self.logger.info(f"[yellow]âš  éœ€è¦ç”¨æˆ·ç¡®è®¤å†™æ–‡ä»¶æ“ä½œ: {name}[/yellow]")
                decision = confirm(f"ç¡®è®¤å†™æ–‡ä»¶ï¼Ÿtool={name} args={args}")
                self.audit.write(trace_id=trace_id, event="confirm_write", data={"tool": name, "args": args, "allow": decision})
                _ev("confirm_write", {"tool": name, "allow": decision})
                if not decision:
                    self.logger.warning(f"[red]âœ— ç”¨æˆ·æ‹’ç»å†™æ–‡ä»¶æ“ä½œ: {name}[/red]")
                    msg = _tool_result_to_message(name, ToolResult(False, error={"code": "E_DENIED", "message": "user denied"}), keywords=keywords)
                    self.messages.append(ChatMessage(role="user", content=msg))
                    _ev("denied_by_user", {"tool": name})
                    self._trim_history(max_messages=30)
                    continue
                else:
                    self.logger.info(f"[green]âœ“ ç”¨æˆ·ç¡®è®¤å†™æ–‡ä»¶æ“ä½œ: {name}[/green]")
            if name in {"run_cmd"} and self.cfg.policy.confirm_exec:
                self.logger.info(f"[yellow]âš  éœ€è¦ç”¨æˆ·ç¡®è®¤æ‰§è¡Œå‘½ä»¤: {name}[/yellow]")
                decision = confirm(f"ç¡®è®¤æ‰§è¡Œå‘½ä»¤ï¼Ÿtool={name} args={args}")
                self.audit.write(trace_id=trace_id, event="confirm_exec", data={"tool": name, "args": args, "allow": decision})
                _ev("confirm_exec", {"tool": name, "allow": decision})
                if not decision:
                    self.logger.warning(f"[red]âœ— ç”¨æˆ·æ‹’ç»æ‰§è¡Œå‘½ä»¤: {name}[/red]")
                    msg = _tool_result_to_message(name, ToolResult(False, error={"code": "E_DENIED", "message": "user denied"}), keywords=keywords)
                    self.messages.append(ChatMessage(role="user", content=msg))
                    _ev("denied_by_user", {"tool": name})
                    self._trim_history(max_messages=30)
                    continue
                else:
                    self.logger.info(f"[green]âœ“ ç”¨æˆ·ç¡®è®¤æ‰§è¡Œå‘½ä»¤: {name}[/green]")

            # minimal command policy (denylist)
            if name == "run_cmd":
                cmd = str(args.get("command", ""))
                dec = evaluate_command(cmd, allow_network=self.cfg.policy.allow_network)
                if not dec.ok:
                    self.logger.warning(f"[red]âœ— ç­–ç•¥æ‹’ç»å‘½ä»¤: {cmd} (åŸå› : {dec.reason})[/red]")
                    self.audit.write(trace_id=trace_id, event="policy_deny_cmd", data={"command": cmd, "reason": dec.reason})
                    _ev("policy_deny_cmd", {"command": cmd, "reason": dec.reason})
                    msg = _tool_result_to_message(name, ToolResult(False, error={"code": "E_POLICY_DENIED", "message": dec.reason}), keywords=keywords)
                    self.messages.append(ChatMessage(role="user", content=msg))
                    self._trim_history(max_messages=30)
                    continue
                else:
                    self.logger.debug(f"[dim]ç­–ç•¥æ£€æŸ¥é€šè¿‡: {cmd}[/dim]")

            tool_used = True
            self.logger.info(f"[bold cyan]â–¶ æ‰§è¡Œå·¥å…·: {name}[/bold cyan]")
            result = self._dispatch_tool(name, args)
            
            # --- Phase 2: Self-healing Loop (Verification) ---
            # If the tool modifies code, trigger automatic verification
            if result.ok and name in {"write_file", "apply_patch", "undo_patch", "run_cmd"}:
                self.logger.info("[bold magenta]ğŸ” è‡ªåŠ¨è§¦å‘éªŒè¯é—­ç¯...[/bold magenta]")
                v_res = self.verifier.run_verify()
                _ev("autofix_check", {"ok": v_res.ok, "type": v_res.type, "summary": v_res.summary})
                
                if not v_res.ok:
                    self.logger.warning(f"[yellow]âš  éªŒè¯å¤±è´¥: {v_res.summary}[/yellow]")
                    # Append verification error to tool result to force LLM to see it
                    v_msg = f"\n\n[éªŒè¯å¤±è´¥ - è‡ªåŠ¨è‡ªæ£€ç»“æœ]\nçŠ¶æ€: {v_res.summary}\n"
                    if v_res.errors:
                        v_msg += "å…·ä½“é”™è¯¯:\n"
                        for err in v_res.errors:
                            v_msg += f"- {err.file}:{err.line} {err.message}\n"
                    
                    # Wrap the original payload if it exists
                    if result.payload is None:
                        result = ToolResult(ok=True, payload={"verification_error": v_msg})
                    else:
                        result.payload["verification_error"] = v_msg
                else:
                    self.logger.info(f"[green]âœ“ éªŒè¯é€šè¿‡: {v_res.summary}[/green]")

            if result.ok:
                self.logger.info(f"[green]âœ“ å·¥å…·æ‰§è¡ŒæˆåŠŸ: {name}[/green]")
            else:
                self.logger.error(f"[red]âœ— å·¥å…·æ‰§è¡Œå¤±è´¥: {name} (é”™è¯¯: {result.error})[/red]")
            _ev("tool_result", {"tool": name, "ok": result.ok, "error": result.error, "payload": result.payload})
            # feed tool result back to model as user message (works with most chat templates)
            self.messages.append(ChatMessage(role="user", content=_tool_result_to_message(name, result, keywords=keywords)))
            self.logger.debug(f"[dim]å·¥å…·ç»“æœå·²å›å–‚ç»™ LLM[/dim]")
            _ev("tool_result_fed_back", {"tool": name})
            self._trim_history(max_messages=30)
            audit_data: dict[str, Any] = {"tool": name, "args": args, "ok": result.ok, "error": result.error}
            if name in {"apply_patch", "undo_patch"} and result.ok and result.payload:
                # record hashes/undo_id for traceability
                audit_data["payload"] = result.payload
            self.audit.write(trace_id=trace_id, event="tool_call", data=audit_data)

        self.logger.warning("[red]âš  è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆ20ï¼‰ï¼Œåœæ­¢ä»¥é¿å…æ­»å¾ªç¯[/red]")
        _ev("stop_reason", {"reason": "max_tool_calls_reached", "limit": 20})
        return AgentTurn(
            assistant_text="è¾¾åˆ°æœ¬è½®æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆ20ï¼‰ï¼Œå·²åœæ­¢ä»¥é¿å…æ­»å¾ªç¯ã€‚è¯·ç¼©å°ä»»åŠ¡æˆ–æä¾›æ›´å¤šçº¦æŸ/å…¥å£æ–‡ä»¶ã€‚",
            tool_used=tool_used,
            trace_id=trace_id,
            events=events,
        )

    def _trim_history(self, *, max_messages: int) -> None:
        """
        è£å‰ªå¯¹è¯å†å²ï¼Œä¿æŒä¸Šä¸‹æ–‡çª—å£åœ¨åˆç†èŒƒå›´å†…ã€‚
        
        è£å‰ªç­–ç•¥ï¼š
        1. å§‹ç»ˆä¿ç•™ç¬¬ä¸€æ¡ system æ¶ˆæ¯ï¼ˆåŒ…å«æ ¸å¿ƒæŒ‡ä»¤å’Œ Repo Mapï¼‰
        2. ä»å°¾éƒ¨å‘å‰è£å‰ªï¼Œä½†ç¡®ä¿è£å‰ªåçš„ç¬¬ä¸€æ¡æ¶ˆæ¯æ˜¯ 'user' è§’è‰²
           ï¼ˆæ»¡è¶³ llama.cpp ç­‰ä¸¥æ ¼ chat template çš„ user/assistant äº¤æ›¿è¦æ±‚ï¼‰
        3. å¦‚æœå½“å‰æ¶ˆæ¯æ•° <= max_messagesï¼Œåˆ™ä¸è¿›è¡Œè£å‰ª
        
        å‚æ•°:
            max_messages: æœ€å¤§ä¿ç•™æ¶ˆæ¯æ•°ï¼ˆåŒ…æ‹¬ system æ¶ˆæ¯ï¼‰
        
        æµç¨‹å›¾: è§ `agent_loop_trim_history_flow.svg`
        """
        old_len = len(self.messages)
        if old_len <= max_messages:
            return
        
        system = self.messages[0]
        # We need an odd number of messages in the tail if the last one is 'user'
        # or just ensure the first message of the tail is 'user'.
        tail_start_idx = len(self.messages) - (max_messages - 1)
        
        # Move forward until we find a 'user' message to keep parity
        while tail_start_idx < len(self.messages) and self.messages[tail_start_idx].role != "user":
            tail_start_idx += 1
            
        tail = self.messages[tail_start_idx:]
        self.messages = [system, *tail]
        self.logger.debug(f"[dim]å†å²è£å‰ª: {old_len} â†’ {len(self.messages)} æ¡æ¶ˆæ¯[/dim]")

    def _dispatch_tool(self, name: str, args: dict[str, Any]) -> ToolResult:
        """
        æ ¹æ®å·¥å…·åç§°åˆ†å‘åˆ°å¯¹åº”çš„å·¥å…·æ‰§è¡Œå‡½æ•°ã€‚
        
        æ”¯æŒçš„å·¥å…·ï¼š
        - list_dir: åˆ—å‡ºç›®å½•å†…å®¹
        - read_file: è¯»å–æ–‡ä»¶ï¼ˆæ”¯æŒ offset/limitï¼‰
        - glob_file_search: æŒ‰æ¨¡å¼æœç´¢æ–‡ä»¶
        - grep: æ–‡æœ¬æœç´¢ï¼ˆä¼˜å…ˆ ripgrepï¼Œé™çº§ Pythonï¼‰
        - apply_patch: åº”ç”¨ä»£ç è¡¥ä¸ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰
        - undo_patch: å›æ»šè¡¥ä¸ï¼ˆåŸºäº undo_idï¼‰
        - write_file: å†™å…¥æ–‡ä»¶
        - run_cmd: æ‰§è¡Œå‘½ä»¤
        - search_semantic: è¯­ä¹‰æœç´¢ï¼ˆå‘é‡ RAGï¼‰
        
        å‚æ•°:
            name: å·¥å…·åç§°
            args: å·¥å…·å‚æ•°å­—å…¸
        
        è¿”å›:
            ToolResult å¯¹è±¡ï¼ˆåŒ…å« ok/error/payloadï¼‰
        
        å¼‚å¸¸å¤„ç†:
            - KeyError: ç¼ºå°‘å¿…éœ€å‚æ•° â†’ è¿”å› E_INVALID_ARGS
            - å…¶ä»–å¼‚å¸¸: å·¥å…·æ‰§è¡Œå¤±è´¥ â†’ è¿”å› E_TOOL
        
        æµç¨‹å›¾: è§ `agent_loop_dispatch_tool_flow.svg`
        """
        try:
            if name == "list_dir":
                return self.tools.list_dir(path=args.get("path", "."))
            if name == "read_file":
                return self.tools.read_file(path=args["path"], offset=args.get("offset"), limit=args.get("limit"))
            if name == "glob_file_search":
                return self.tools.glob_file_search(glob_pattern=args["glob_pattern"], target_directory=args.get("target_directory", "."))
            if name == "grep":
                return self.tools.grep(
                    pattern=args["pattern"],
                    path=args.get("path", "."),
                    ignore_case=bool(args.get("ignore_case", False)),
                    max_hits=int(args.get("max_hits", 200)),
                )
            if name == "apply_patch":
                return self.tools.apply_patch(
                    path=args["path"],
                    old=args["old"],
                    new=args["new"],
                    expected_replacements=int(args.get("expected_replacements", 1)),
                    fuzzy=bool(args.get("fuzzy", False)),
                    min_similarity=float(args.get("min_similarity", 0.92)),
                )
            if name == "undo_patch":
                return self.tools.undo_patch(
                    undo_id=args["undo_id"],
                    force=bool(args.get("force", False)),
                )
            if name == "write_file":
                return self.tools.write_file(path=args["path"], text=args.get("text", ""))
            if name == "run_cmd":
                return self.tools.run_cmd(command=args["command"], cwd=args.get("cwd", "."))
            if name == "search_semantic":
                return self._semantic_search(query=args["query"])
            return ToolResult(False, error={"code": "E_NO_TOOL", "message": f"unknown tool: {name}"})
        except KeyError as e:
            return ToolResult(False, error={"code": "E_INVALID_ARGS", "message": f"missing arg: {e}"})
        except Exception as e:
            return ToolResult(False, error={"code": "E_TOOL", "message": str(e)})

    def _semantic_search(self, query: str) -> ToolResult:
        """
        æ‰§è¡Œè¯­ä¹‰æœç´¢ï¼ˆå‘é‡ RAGï¼‰ã€‚
        
        æµç¨‹ï¼š
        1. ä½¿ç”¨ CodeEmbedder å°†æŸ¥è¯¢æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
        2. åœ¨ VectorStoreï¼ˆLanceDBï¼‰ä¸­æœç´¢æœ€ç›¸ä¼¼çš„ä»£ç å—ï¼ˆtop 5ï¼‰
        3. å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸º ToolResult
        
        å‚æ•°:
            query: æœç´¢æŸ¥è¯¢æ–‡æœ¬ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
        
        è¿”å›:
            ToolResult å¯¹è±¡ï¼Œpayload åŒ…å«ï¼š
            - query: åŸå§‹æŸ¥è¯¢
            - hits: æœç´¢ç»“æœåˆ—è¡¨ï¼ˆæ¯ä¸ªåŒ…å« path/start_line/end_line/textï¼‰
        
        å¼‚å¸¸å¤„ç†:
            ä»»ä½•å¼‚å¸¸éƒ½ä¼šè¿”å› E_SEMANTIC_SEARCH é”™è¯¯
        
        æµç¨‹å›¾: è§ `agent_loop_semantic_search_flow.svg`
        """
        try:
            self.logger.debug(f"[dim]æ‰§è¡Œè¯­ä¹‰æœç´¢: {query[:50]}...[/dim]")
            q_vector = self.embedder.embed_query(query)
            hits = self.vector_store.search(q_vector, limit=5)
            self.logger.info(f"[green]âœ“ è¯­ä¹‰æœç´¢æ‰¾åˆ° {len(hits)} ä¸ªç»“æœ[/green]")
            
            payload_hits = []
            for h in hits:
                payload_hits.append({
                    "path": h.get("path"),
                    "start_line": h.get("start_line"),
                    "end_line": h.get("end_line"),
                    "text": h.get("text")
                })
            
            return ToolResult(True, payload={"query": query, "hits": payload_hits})
        except Exception as e:
            self.logger.error(f"[red]âœ— è¯­ä¹‰æœç´¢å¤±è´¥: {e}[/red]")
            return ToolResult(False, error={"code": "E_SEMANTIC_SEARCH", "message": str(e)})


