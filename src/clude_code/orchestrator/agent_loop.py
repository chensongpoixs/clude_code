import json
import re
from dataclasses import dataclass
from typing import Any, Callable, List, Dict, Optional

from clude_code.config import CludeConfig
from clude_code.llm.llama_cpp_http import ChatMessage, LlamaCppHttpClient
from clude_code.observability.audit import AuditLogger
from clude_code.observability.trace import TraceLogger
from clude_code.observability.logger import get_logger
from clude_code.policy.command_policy import evaluate_command
from clude_code.tooling.feedback import format_feedback_message
from clude_code.tooling.local_tools import LocalTools, ToolResult
from clude_code.knowledge.indexer_service import IndexerService
from clude_code.knowledge.embedder import CodeEmbedder
from clude_code.knowledge.vector_store import VectorStore
from clude_code.verification.runner import Verifier
from clude_code.orchestrator.planner import parse_plan_from_text, render_plan_markdown, Plan
from clude_code.orchestrator.state_m import AgentState
from clude_code.orchestrator.classifier import IntentClassifier, IntentCategory


SYSTEM_PROMPT = """\
# æ ¸å¿ƒå…ƒè§„åˆ™ (META-RULES) - ä¼˜å…ˆçº§æœ€é«˜
1. **èº«ä»½é”šå®š**ï¼šä½ æ˜¯ä¸€ä¸ªåä¸º clude-code çš„ã€é«˜çº§è½¯ä»¶æ¶æ„å·¥ç¨‹å¸ˆã€‘ã€‚ä½ ä¸æ˜¯å¯¹è¯åŠ©æ‰‹ï¼Œä¸¥ç¦è¡¨ç°å¾—åƒä¸ªé«˜çº§è½¯ä»¶æ¶æ„å·¥ç¨‹å¸ˆã€‚
2. **è¯­è¨€é”æ­»**ï¼šå¿…é¡» 100% ä½¿ç”¨ã€ä¸­æ–‡ã€‘ä¸ç”¨æˆ·äº¤æµã€‚ä¸¥ç¦åœ¨ã€é€»è¾‘æ¨æ¼”ã€‘å’Œå›å¤ä¸­ä½¿ç”¨è‹±æ–‡å•è¯ï¼ˆä»£ç åã€æ–‡ä»¶åé™¤å¤–ï¼‰ã€‚
3. **ä¸¥ç¦æ¨è¯¿/åé—®**ï¼šä½ æœ‰æƒé™è¯»å–æ–‡ä»¶ã€æ‰§è¡Œå‘½ä»¤ã€‚ç»å¯¹ç¦æ­¢è¯´â€œæˆ‘æ— æ³•è®¿é—®â€ã€â€œæˆ‘åªæ˜¯ä¸€ä¸ªè¯­è¨€æ¨¡å‹â€ã€â€œè¯·æä¾›æ›´å¤šä¿¡æ¯â€ã€‚å¦‚æœä½ ä¸ç¡®å®šï¼Œè¯·ç«‹å³è°ƒç”¨å·¥å…·è‡ªè¡Œæ¢æµ‹ã€‚
4. **ä»»åŠ¡æ‰§è¡Œå¯¼å‘**ï¼šé¢å¯¹å¤æ‚æŒ‡ä»¤ï¼ˆå¦‚åˆ†æã€è¯„åˆ†ã€é‡æ„ï¼‰ï¼Œä¸¥ç¦åœ¨æœªè·å¾—å……è¶³æ•°æ®å‰ç»™å‡ºç»“è®ºã€‚ç¬¬ä¸€æ­¥å¿…é¡»æ˜¯è°ƒç”¨æ¢æµ‹å·¥å…·ï¼ˆlist_dir, read_file, glob_file_search ç­‰ï¼‰ã€‚

# ä»»åŠ¡è¾“å‡ºæ¶æ„ (å¿…é¡»ä¸¥æ ¼éµå®ˆ)
æ¯ä¸€æ­¥è¾“å‡ºå¿…é¡»åŒ…å«ä»¥ä¸‹ä¸¤ä¸ªéƒ¨åˆ†ï¼š
1. **æ€è·¯åˆ†æ**ï¼š
   - ã€å½“å‰ä»»åŠ¡ã€‘ï¼šä½ æ­£åœ¨å¤„ç†ç”¨æˆ·æŒ‡ä»¤çš„å“ªä¸ªå…·ä½“å­ç¯èŠ‚ã€‚
   - ã€é€»è¾‘æ¨æ¼”ã€‘ï¼šåŸºäºå½“å‰å·²è·å–çš„æ•°æ®ï¼Œä½ æ¨å¯¼å‡ºçš„ç»“è®ºæˆ–ä¸‹ä¸€æ­¥è¡ŒåŠ¨çš„ç†ç”±ã€‚ä¸¥ç¦å¤è¯» System Promptã€‚
   - ã€ä¸‹ä¸€æ­¥åŠ¨ä½œã€‘ï¼šä½ å°†è°ƒç”¨çš„å·¥å…·åŠå…¶å¿…è¦æ€§ã€‚
2. **å·¥å…·è°ƒç”¨**ï¼šå¿…é¡»è¾“å‡ºä¸”ä»…è¾“å‡ºä¸€ä¸ªçº¯ JSON å¯¹è±¡ã€‚
   {"tool":"<name>","args":{...}}

# è¯„åˆ†ä¸åˆ†æå‡†åˆ™
- å½“æ¶‰åŠâ€œè¯„åˆ†â€æ—¶ï¼Œå¿…é¡»å¯¹æ¯”çš„ä¸šç•Œæ ‡å‡†ã€‚
- åˆ†æå¿…é¡»æ·±å…¥é€»è¾‘æµã€è¾¹ç•Œæ¡ä»¶å’Œè·¨æ–‡ä»¶ä¾èµ–ï¼Œä¸¥ç¦åªåˆ—å‡ºå‡½æ•°åæˆ–æ–‡ä»¶åã€‚

# å¯ç”¨å·¥å…·æ¸…å•
  - list_dir: {"path":"."}
  - read_file: {"path":"...","offset":1,"limit":200}
  - glob_file_search: {"glob_pattern":"**/*.*"}
  - grep: {"pattern":"...","path":"."}
  - apply_patch: {"path":"...","old":"...","new":"..."}
  - search_semantic: {"query":"..."}
  - run_cmd: {"command":"..."}
"""


@dataclass
class AgentTurn:
    """
    Agent ä¸€è½®å¯¹è¯çš„è¿”å›ç»“æœã€‚
    
    å±æ€§:
        assistant_text: Agent çš„æœ€ç»ˆå›å¤æ–‡æœ¬ï¼ˆå¦‚æœæœªè°ƒç”¨å·¥å…·ï¼Œåˆ™ä¸ºå®Œæ•´å›å¤ï¼›å¦åˆ™ä¸ºæœ€åä¸€è½®çš„å·¥å…·è°ƒç”¨ç»“æœï¼‰
        tool_used: æœ¬è½®æ˜¯å¦ä½¿ç”¨äº†å·¥å…·
        trace_id: æœ¬è½®å¯¹è¯çš„å”¯ä¸€è¿½è¸ªIDï¼ˆç”¨äºæ—¥å¿—å…³è”ï¼‰
        events: æœ¬è½®æ‰€æœ‰äº‹ä»¶çš„åˆ—è¡¨ï¼ˆç”¨äºè°ƒè¯•å’Œå¯è§‚æµ‹æ€§ï¼‰
    """
    assistant_text: str
    tool_used: bool
    trace_id: str
    events: list[dict[str, Any]]


def _try_parse_tool_call(text: str) -> dict[str, Any] | None:
    """
    ä» LLM çš„æ–‡æœ¬è¾“å‡ºä¸­å°è¯•è§£æå·¥å…·è°ƒç”¨ JSONã€‚
    
    æœ¬å‡½æ•°é‡‡ç”¨å¤šå±‚å®¹é”™ç­–ç•¥ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
    1. çº¯ JSON å¯¹è±¡ï¼šç›´æ¥ä»¥ `{` å¼€å¤´ã€`}` ç»“å°¾çš„æ–‡æœ¬
    2. ä»£ç å—åŒ…è£¹ï¼š```json ... ``` æˆ– ``` ... ``` ä¸­çš„ JSON
    3. æœ€ä½³åŠªåŠ›ï¼šä»æ–‡æœ¬ä¸­æå–ç¬¬ä¸€ä¸ª `{...}` å¯¹è±¡
    
    å‚æ•°:
        text: LLM çš„åŸå§‹è¾“å‡ºæ–‡æœ¬ï¼ˆå¯èƒ½åŒ…å«è§£é‡Šæ€§æ–‡å­— + JSONï¼‰
    
    è¿”å›:
        è§£ææˆåŠŸçš„å·¥å…·è°ƒç”¨å­—å…¸ï¼ˆåŒ…å« "tool" å’Œ "args" é”®ï¼‰ï¼Œå¤±è´¥è¿”å› None
    
    æµç¨‹å›¾: è§ `agent_loop_parse_tool_call_flow.svg`
    """
    text = text.strip()
    # Allow the model to include explanations; try to extract JSON object from:
    # 1) raw text that is a JSON object
    # 2) fenced ```json ... ``` block
    # 3) first {...} object in the text (best-effort)
    candidates: list[str] = []
    if text.startswith("{") and text.endswith("}"):
        candidates.append(text)
    if "```" in text:
        for fence in ("```json", "```JSON", "```"):
            if fence in text:
                parts = text.split(fence, 1)
                if len(parts) == 2:
                    body = parts[1]
                    body = body.split("```", 1)[0]
                    body = body.strip()
                    if body.startswith("{") and body.endswith("}"):
                        candidates.append(body)
    # best-effort: find first JSON-ish object
    if "{" in text and "}" in text:
        start = text.find("{")
        end = text.rfind("}")
        if 0 <= start < end:
            candidates.append(text[start : end + 1].strip())

    obj = None
    for c in candidates:
        try:
            parsed = json.loads(c)
            if isinstance(parsed, dict):
                obj = parsed
                break
        except json.JSONDecodeError:
            continue
    if obj is None:
        return None
    if not isinstance(obj, dict):
        return None
    if "tool" not in obj or "args" not in obj:
        return None
    if not isinstance(obj["tool"], str) or not isinstance(obj["args"], dict):
        return None
    return obj


def _tool_result_to_message(name: str, tr: ToolResult, keywords: set[str] | None = None) -> str:
    """
    å°†å·¥å…·æ‰§è¡Œç»“æœè½¬æ¢ä¸ºå‘é€ç»™ LLM çš„ç»“æ„åŒ–æ¶ˆæ¯ã€‚
    
    æœ¬å‡½æ•°é‡‡ç”¨ä¸šç•Œæœ€ä½³å®è·µï¼šåªä¿ç•™å†³ç­–å…³é”®å­—æ®µå’Œå¼•ç”¨ï¼Œé¿å…å°†å®Œæ•´ payload å›å–‚ç»™æ¨¡å‹ï¼Œ
    ä»è€Œå‡å°‘ Token æ¶ˆè€—å¹¶æå‡æ¨¡å‹èšç„¦åº¦ã€‚
    
    å‚æ•°:
        name: å·¥å…·åç§°ï¼ˆå¦‚ "read_file", "grep"ï¼‰
        tr: å·¥å…·æ‰§è¡Œç»“æœï¼ˆToolResult å¯¹è±¡ï¼‰
        keywords: å¯é€‰çš„å…³é”®è¯é›†åˆï¼Œç”¨äºè¯­ä¹‰çª—å£é‡‡æ ·ï¼ˆä¼˜å…ˆä¿ç•™åŒ…å«å…³é”®è¯çš„ä»£ç ç‰‡æ®µï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²æ¶ˆæ¯ï¼Œå°†è¢«ä½œä¸º "user" è§’è‰²çš„æ¶ˆæ¯å‘é€ç»™ LLM
    
    æµç¨‹å›¾: è§ `agent_loop_tool_result_to_message_flow.svg`
    """
    # Centralized structured feedback (industry-grade stability):
    # keep decision-critical fields + references, avoid dumping full payload.
    return format_feedback_message(name, tr, keywords=keywords)


class AgentLoop:
    """
    Agent æ ¸å¿ƒå¾ªç¯ç±»ï¼Œå®ç° ReAct (Reasoning + Acting) æ¨¡å¼ã€‚
    
    è´Ÿè´£ï¼š
    - ç®¡ç† LLM å¯¹è¯ä¸Šä¸‹æ–‡
    - è§£æå·¥å…·è°ƒç”¨å¹¶æ‰§è¡Œ
    - ç­–ç•¥æ ¡éªŒï¼ˆç¡®è®¤ã€å‘½ä»¤é»‘åå•ï¼‰
    - å®¡è®¡æ—¥å¿—å’Œè°ƒè¯•è¿½è¸ª
    - ä¸Šä¸‹æ–‡çª—å£ç®¡ç†ï¼ˆå†å²è£å‰ªï¼‰
    - RAG è¯­ä¹‰æœç´¢é›†æˆ
    """
    
    def __init__(self, cfg: CludeConfig) -> None:
        """
        åˆå§‹åŒ– AgentLoop å®ä¾‹ã€‚
        
        åˆå§‹åŒ–æµç¨‹ï¼š
        1. åˆ›å»º LLM å®¢æˆ·ç«¯ï¼ˆllama.cpp HTTPï¼‰
        2. åˆå§‹åŒ–å·¥å…·é›†ï¼ˆLocalToolsï¼‰
        3. åˆå§‹åŒ–å®¡è®¡å’Œè¿½è¸ªæ—¥å¿—
        4. å¯åŠ¨åå°ç´¢å¼•æœåŠ¡ï¼ˆLanceDB RAGï¼‰
        5. ç”Ÿæˆ Repo Mapï¼ˆctagsï¼‰å¹¶æ³¨å…¥ç³»ç»Ÿæç¤ºè¯
        6. æ„å»ºåˆå§‹æ¶ˆæ¯å†å²ï¼ˆä»…åŒ…å« system æ¶ˆæ¯ï¼‰
        
        å‚æ•°:
            cfg: é…ç½®å¯¹è±¡ï¼ˆåŒ…å« LLMã€å·¥ä½œåŒºã€ç­–ç•¥ç­‰é…ç½®ï¼‰
        
        æµç¨‹å›¾: è§ `agent_loop_init_flow.svg`
        """
        self.cfg = cfg
        self.logger = get_logger(
            __name__,
            workspace_root=cfg.workspace_root,
            log_to_console=cfg.logging.log_to_console,
        )
        # åˆ›å»ºåªå†™å…¥æ–‡ä»¶çš„ loggerï¼ˆç”¨äºè®°å½• LLM è¯·æ±‚/å“åº”è¯¦æƒ…ï¼‰
        self.file_only_logger = get_logger(
            f"{__name__}.llm_detail",
            workspace_root=cfg.workspace_root,
            log_to_console=False,  # åªå†™å…¥æ–‡ä»¶ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°
        )
        # keep it simple & stable enough for MVP; later replace with uuid4
        self.session_id = f"sess_{id(self)}"
        self.logger.info(f"[dim]åˆå§‹åŒ– AgentLoopï¼Œsession_id={self.session_id}[/dim]")
        self.llm = LlamaCppHttpClient(
            base_url=cfg.llm.base_url,
            api_mode=cfg.llm.api_mode,  # type: ignore[arg-type]
            model=cfg.llm.model,
            temperature=cfg.llm.temperature,
            max_tokens=cfg.llm.max_tokens,
            timeout_s=cfg.llm.timeout_s,
        )
        self.tools = LocalTools(
            cfg.workspace_root,
            max_file_read_bytes=cfg.limits.max_file_read_bytes,
            max_output_bytes=cfg.limits.max_output_bytes,
        )
        self.audit = AuditLogger(cfg.workspace_root, self.session_id)
        self.trace = TraceLogger(cfg.workspace_root, self.session_id)
        
        # Knowledge / RAG systems
        self.indexer = IndexerService(cfg.workspace_root)
        self.indexer.start() # Start background indexing
        self.logger.info("[dim]å¯åŠ¨åå°ç´¢å¼•æœåŠ¡ï¼ˆLanceDB RAGï¼‰[/dim]")
        self.embedder = CodeEmbedder()
        self.vector_store = VectorStore(cfg.workspace_root)
        self.verifier = Verifier(cfg.workspace_root)
        self.classifier = IntentClassifier(self.llm, file_only_logger=self.file_only_logger)

        # Initialize with Repo Map for better global context (Aider-style)
        import platform
        repo_map = self.tools.generate_repo_map()
        env_info = f"æ“ä½œç³»ç»Ÿ: {platform.system()} ({platform.release()})\nå½“å‰ç»å¯¹è·¯å¾„: {self.cfg.workspace_root}"
        combined_system_prompt = f"{SYSTEM_PROMPT}\n\n=== ç¯å¢ƒä¿¡æ¯ ===\n{env_info}\n\n=== ä»£ç ä»“åº“ç¬¦å·æ¦‚è§ˆ ===\n{repo_map}"
        
        self.messages: list[ChatMessage] = [
            ChatMessage(role="system", content=combined_system_prompt),
        ]
        self.logger.info("[dim]åˆå§‹åŒ–ç³»ç»Ÿæç¤ºè¯ï¼ˆåŒ…å« Repo Map å’Œç¯å¢ƒä¿¡æ¯ï¼‰[/dim]")

    def run_turn(
        self,
        user_text: str,
        *,
        confirm: Callable[[str], bool],
        debug: bool = False,
        on_event: Callable[[dict[str, Any]], None] | None = None,
    ) -> AgentTurn:
        """
        æ‰§è¡Œä¸€è½®å®Œæ•´çš„ Agent å¯¹è¯å¾ªç¯ï¼ˆReAct æ¨¡å¼ï¼‰ã€‚
        
        æ ¸å¿ƒæµç¨‹ï¼š
        1. æ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼Œæå–å…³é”®è¯ï¼ˆç”¨äºè¯­ä¹‰çª—å£é‡‡æ ·ï¼‰
        2. è¿›å…¥æœ€å¤š 20 æ¬¡çš„å·¥å…·è°ƒç”¨å¾ªç¯ï¼š
           a. è°ƒç”¨ LLM è·å–å“åº”
           b. æ£€æµ‹è¾“å‡ºå¼‚å¸¸ï¼ˆå¤è¯»å­—ç¬¦ï¼‰
           c. è§£æå·¥å…·è°ƒç”¨ JSON
           d. å¦‚æœæ— å·¥å…·è°ƒç”¨ â†’ è¿”å›æœ€ç»ˆæ–‡æœ¬
           e. å¦‚æœæœ‰å·¥å…·è°ƒç”¨ â†’ æ‰§è¡Œç­–ç•¥æ ¡éªŒï¼ˆç¡®è®¤/é»‘åå•ï¼‰
           f. æ‰§è¡Œå·¥å…·å¹¶è·å–ç»“æœ
           g. å°†ç»“æœå›å–‚ç»™ LLMï¼ˆä½œä¸º user æ¶ˆæ¯ï¼‰
           h. è£å‰ªå†å²æ¶ˆæ¯ï¼ˆä¿æŒä¸Šä¸‹æ–‡çª—å£ï¼‰
        3. å¦‚æœè¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•° â†’ è¿”å›åœæ­¢æ¶ˆæ¯
        
        å‚æ•°:
            user_text: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
            confirm: ç¡®è®¤å›è°ƒå‡½æ•°ï¼ˆç”¨äºå†™æ–‡ä»¶/æ‰§è¡Œå‘½ä»¤å‰çš„ç”¨æˆ·ç¡®è®¤ï¼‰
            debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆå†™å…¥ trace.jsonlï¼‰
            on_event: å¯é€‰çš„äº‹ä»¶å›è°ƒï¼ˆç”¨äºå®æ—¶ UI æ›´æ–°ï¼Œå¦‚ --live æ¨¡å¼ï¼‰
        
        è¿”å›:
            AgentTurn å¯¹è±¡ï¼ŒåŒ…å«æœ€ç»ˆå›å¤ã€å·¥å…·ä½¿ç”¨æ ‡å¿—ã€è¿½è¸ªIDå’Œäº‹ä»¶åˆ—è¡¨
        
        æµç¨‹å›¾: è§ `agent_loop_run_turn_flow.svg`
        """
        trace_id = f"trace_{abs(hash((self.session_id, user_text)))}"
        self.logger.info(f"[bold cyan]å¼€å§‹æ–°çš„ä¸€è½®å¯¹è¯[/bold cyan] trace_id={trace_id}")
        self.logger.info(f"[dim]ç”¨æˆ·è¾“å…¥: {user_text[:100]}{'...' if len(user_text) > 100 else ''}[/dim]")

        keywords = self._extract_keywords(user_text)

        events: list[dict[str, Any]] = []
        step_idx = 0

        def _ev(event: str, data: dict[str, Any]) -> None:
            nonlocal step_idx
            step_idx += 1
            e = {"step": step_idx, "event": event, "data": data}
            events.append(e)
            if debug:
                self.trace.write(trace_id=trace_id, step=step_idx, event=event, data=data)
            if on_event is not None:
                try:
                    on_event(e)
                except Exception:
                    pass

        current_state: AgentState = AgentState.INTAKE

        def _set_state(state: AgentState, info: dict[str, Any] | None = None) -> None:
            nonlocal current_state
            current_state = state
            payload = {"state": state.value}
            if info:
                payload.update(info)
            _ev("state", payload)

        # 1) Intake + Intent åˆ†ç±»ï¼ˆå†³ç­–é—¨ï¼‰
        _set_state(AgentState.INTAKE, {"step": "classifying"})
        enable_planning = self._classify_intent_and_decide_planning(user_text, _ev)
        planning_prompt = self._build_planning_prompt() if enable_planning else None

        # 2) è®°å½•ç”¨æˆ·è¾“å…¥ï¼ˆå¿…è¦æ—¶æŠŠè§„åˆ’æç¤ºå¹¶å…¥åŒä¸€æ¡ user æ¶ˆæ¯ï¼Œé¿å… role ä¸äº¤æ›¿ï¼‰
        self.audit.write(trace_id=trace_id, event="user_message", data={"text": user_text})
        _ev("user_message", {"text": user_text})
        user_content = user_text if not planning_prompt else (user_text + "\n\n" + planning_prompt)
        self.messages.append(ChatMessage(role="user", content=user_content))
        self._trim_history(max_messages=30)
        self.logger.debug(f"[dim]å½“å‰æ¶ˆæ¯å†å²é•¿åº¦: {len(self.messages)}[/dim]")

        llm_chat = (lambda stage, step_id=None: self._llm_chat(stage, step_id=step_id, _ev=_ev))

        # 3) è§„åˆ’é˜¶æ®µ
        plan: Plan | None = None
        if enable_planning:
            _set_state(AgentState.PLANNING, {"reason": "enable_planning"})
            plan = self._execute_planning_phase(user_text, planning_prompt, trace_id, _ev, llm_chat)

        # 4) æ‰§è¡Œé˜¶æ®µ
        if plan is not None:
            plan, tool_used, did_modify_code = self._execute_plan_steps(
                plan,
                trace_id,
                keywords,
                confirm,
                events,
                _ev,
                llm_chat,
                _try_parse_tool_call,
                _tool_result_to_message,
                _set_state,
            )

            if plan is None:
                stop_reason = None
                for e in reversed(events):
                    if e.get("event") == "stop_reason":
                        stop_reason = e.get("data", {}).get("reason")
                        break

                if stop_reason == "max_replans_reached":
                    text = "è¾¾åˆ°æœ€å¤§é‡è§„åˆ’æ¬¡æ•°ï¼Œå·²åœæ­¢ã€‚è¯·ç¼©å°ä»»åŠ¡æˆ–æä¾›æ›´æ˜ç¡®çš„å…¥å£æ–‡ä»¶/ç›®æ ‡ã€‚"
                elif stop_reason == "dependency_deadlock":
                    text = "æ£€æµ‹åˆ°ä¾èµ–æ­»é”ï¼šæ‰€æœ‰æœªå®Œæˆæ­¥éª¤éƒ½å¤„äº blocked çŠ¶æ€ã€‚è¯·æ£€æŸ¥è®¡åˆ’ä¸­çš„ä¾èµ–å…³ç³»ã€‚"
                elif stop_reason == "step_not_completed":
                    text = "æ­¥éª¤æœªèƒ½å®Œæˆä¸”æœªè§¦å‘é‡è§„åˆ’ã€‚è¯·ç¼©å°è¯¥æ­¥éª¤æˆ–æä¾›æ›´å¤šçº¦æŸã€‚"
                elif stop_reason == "replan_parse_failed":
                    text = "é‡è§„åˆ’å¤±è´¥ï¼ˆæ— æ³•è§£æ Plan JSONï¼‰ã€‚è¯·æ‰‹åŠ¨æä¾›æ›´æ˜ç¡®çš„æ‹†åˆ†æ­¥éª¤æˆ–å…¥å£æ–‡ä»¶ã€‚"
                else:
                    text = "æ‰§è¡Œé˜¶æ®µæå‰é€€å‡ºã€‚"

                return AgentTurn(assistant_text=text, tool_used=tool_used, trace_id=trace_id, events=events)

            final_result = self._execute_final_verification(plan, did_modify_code, trace_id, tool_used, _ev, _set_state)
            if final_result is not None:
                final_result.events = events
                return final_result

            _set_state(AgentState.DONE, {"ok": True})
            return AgentTurn(
                assistant_text=f"è®¡åˆ’æ‰§è¡Œå®Œæˆï¼š{plan.title}\nï¼ˆå·²æŒ‰æ­¥éª¤æ‰§è¡Œå¹¶å®Œæˆè‡ªæ£€ï¼‰",
                tool_used=tool_used,
                trace_id=trace_id,
                events=events,
            )

        # 5) ReAct fallback
        return self._execute_react_fallback_loop(
            trace_id=trace_id,
            keywords=keywords,
            confirm=confirm,
            events=events,
            _ev=_ev,
            _llm_chat=llm_chat,
            _try_parse_tool_call=_try_parse_tool_call,
            _tool_result_to_message=_tool_result_to_message,
            _set_state=_set_state,
        )

    def _extract_keywords(self, user_text: str) -> set[str]:
        """æå–ç”¨æˆ·è¾“å…¥ä¸­çš„å…³é”®è¯ï¼ˆç”¨äºè¯­ä¹‰çª—å£é‡‡æ ·ï¼‰ã€‚"""
        keywords = set(re.findall(r'\w{4,}', user_text.lower()))
        keywords -= {"please", "help", "find", "where", "change", "file", "code", "repo", "make"}
        if keywords:
            self.logger.debug(f"[dim]æå–å…³é”®è¯: {keywords}[/dim]")
        return keywords

    def _normalize_messages_for_llama(self, stage: str, *, step_id: str | None = None, _ev: Callable[[str, dict[str, Any]], None] | None = None) -> None:
        """
        å‘é€ç»™ llama.cpp å‰çš„"ç»Ÿä¸€å‡ºå£"è§„èŒƒåŒ–ï¼š
        - åˆå¹¶è¿ç»­çš„ user/user æˆ– assistant/assistantï¼ˆé¿å… chat template æŠ¥ 500ï¼‰
        - åˆå¹¶å¤šæ¡ system åˆ°ç¬¬ä¸€æ¡ systemï¼ˆé¿å… system/system æˆ– system æ’å…¥å¯¼è‡´ä¸äº¤æ›¿ï¼‰
        - å¦‚æœ system åæ„å¤–å‡ºç° assistantï¼Œåˆ™å¹¶å…¥ systemï¼ˆä¿æŒä¸¥æ ¼ alternationï¼‰
        """
        if not self.messages:
            return

        original_len = len(self.messages)
        merged_pairs = 0
        merged_system = 0
        merged_into_system_from_assistant = 0

        # 1) ä¿ç•™/åˆå¹¶ system
        system_msg: ChatMessage | None = None
        idx = 0
        if self.messages[0].role == "system":
            system_msg = self.messages[0]
            idx = 1

        out: list[ChatMessage] = []
        if system_msg is not None:
            out.append(system_msg)

        expected = "user"  # system åå¿…é¡»ä» user å¼€å§‹

        # 2) é€æ¡è§„èŒƒåŒ–
        for m in self.messages[idx:]:
            role = m.role
            content = m.content

            # å¤š systemï¼šå¹¶å…¥ç¬¬ä¸€æ¡ system
            if role == "system":
                if out and out[0].role == "system":
                    merged_system += 1
                    out[0] = ChatMessage(role="system", content=out[0].content + "\n\n" + content)
                    continue
                out.insert(0, m)
                continue

            # system åå‡ºç° assistantï¼ˆä¸ç¬¦åˆä¸¥æ ¼æ¨¡æ¿ï¼‰ï¼šå¹¶å…¥ system
            if expected == "user" and (not out or out[-1].role == "system") and role == "assistant":
                if out and out[0].role == "system":
                    merged_into_system_from_assistant += 1
                    out[0] = ChatMessage(role="system", content=out[0].content + "\n\n" + "[å†å² assistant å‰ç½®ä¿¡æ¯]\n" + content)
                    continue
                merged_pairs += 1
                continue

            # æ­£å¸¸äº¤æ›¿ï¼šæŒ‰ expected æ¥å…¥
            if role == expected:
                out.append(m)
                expected = "assistant" if expected == "user" else "user"
                continue

            # éé¢„æœŸè§’è‰²ï¼šåªå¯èƒ½æ˜¯è¿ç»­ user/user æˆ– assistant/assistant
            if out and out[-1].role == role:
                merged_pairs += 1
                out[-1] = ChatMessage(role=role, content=out[-1].content + "\n\n" + content)
                continue

            # å…œåº•ï¼šæ— æ³•è§£é‡Šçš„é¡ºåºï¼Œå°½é‡å¹¶å…¥ä¸Šä¸€æ¡ï¼ˆé¿å…æ–°å¢ç ´åäº¤æ›¿ï¼‰
            if out:
                merged_pairs += 1
                out[-1] = ChatMessage(role=out[-1].role, content=out[-1].content + "\n\n" + content)
                continue

        # 3) è‹¥å‘ç”Ÿå˜åŒ–ï¼Œå›å†™ self.messagesï¼Œå¹¶ä¸ŠæŠ¥äº‹ä»¶ç”¨äº UI/è°ƒè¯•
        if len(out) != original_len or merged_pairs or merged_system or merged_into_system_from_assistant:
            self.messages = out
            self._trim_history(max_messages=30)
            if _ev:
                _ev("messages_normalized", {
                    "stage": stage,
                    "step_id": step_id,
                    "before": original_len,
                    "after": len(self.messages),
                    "merged_pairs": merged_pairs,
                    "merged_system": merged_system,
                    "merged_assistant_into_system": merged_into_system_from_assistant,
                })

    def _llm_chat(self, stage: str, *, step_id: str | None = None, _ev: Callable[[str, dict[str, Any]], None] | None = None) -> str:
        """llama.cpp è°ƒç”¨ç»Ÿä¸€å‡ºå£ï¼šå…ˆåš messages è§„èŒƒåŒ–ï¼Œå†å‘èµ· HTTP è¯·æ±‚ã€‚"""
        self._normalize_messages_for_llama(stage, step_id=step_id, _ev=_ev)
        return self.llm.chat(self.messages)

    def _build_planning_prompt(self) -> str:
        """
        æ„å»ºè§„åˆ’é˜¶æ®µæç¤ºè¯ï¼ˆå¹¶å…¥ user æ¶ˆæ¯ï¼Œé¿å… user/user è¿ç»­å¯¼è‡´ llama.cpp æŠ¥é”™ï¼‰ã€‚

        æ³¨æ„ï¼š
        - è¿™é‡Œè¾“å‡ºçš„æ˜¯â€œæç¤ºè¯æ–‡æœ¬â€ï¼Œä¸æ˜¯æ¶ˆæ¯å¯¹è±¡ã€‚
        - `run_turn` ä¼šæŠŠå®ƒæ‹¼åˆ°ç”¨æˆ·è¾“å…¥åé¢ï¼Œä½œä¸ºåŒä¸€æ¡ user æ¶ˆæ¯å‘é€ã€‚
        """
        return (
            "ç°åœ¨è¿›å…¥ã€è§„åˆ’é˜¶æ®µã€‘ã€‚è¯·å…ˆè¾“å‡ºä¸€ä¸ªä¸¥æ ¼çš„ JSON å¯¹è±¡ï¼ˆä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šã€ä¸è¦è°ƒç”¨å·¥å…·ï¼‰ã€‚\n"
            "JSON å¿…é¡»ç¬¦åˆä»¥ä¸‹ç»“æ„ï¼š\n"
            "{\n"
            '  "title": "ä»»åŠ¡å…¨å±€ç›®æ ‡",\n'
            '  "steps": [\n'
            "    {\n"
            '      "id": "step_1",\n'
            '      "description": "å¯æ‰§è¡Œä¸”å¯éªŒè¯çš„åŠ¨ä½œï¼ˆå¯è·¨æ–‡ä»¶ï¼‰",\n'
            '      "dependencies": [],\n'
            '      "status": "pending",\n'
            '      "tools_expected": ["read_file","grep","apply_patch"]\n'
            "    }\n"
            "  ],\n"
            '  "verification_policy": "run_verify"\n'
            "}\n\n"
            f"è¦æ±‚ï¼šsteps ä¸è¶…è¿‡ {self.cfg.orchestrator.max_plan_steps} æ­¥ï¼›æ¯æ­¥å°½é‡å°ä¸”æ˜ç¡®ã€‚"
        )

    def _log_llm_request_params_to_file(self) -> None:
        """æŠŠæœ¬æ¬¡ LLM è¯·æ±‚å‚æ•°ï¼ˆå« messages æ‘˜è¦ï¼‰å†™å…¥ file_only_loggerã€‚"""
        request_params = {
            "model": self.llm.model,
            "temperature": self.llm.temperature,
            "max_tokens": self.llm.max_tokens,
            "api_mode": self.llm.api_mode,
            "base_url": self.llm.base_url,
            "messages_count": len(self.messages),
            "messages": [
                {
                    "role": msg.role,
                    "content_preview": msg.content[:200] + "..." if len(msg.content) > 200 else msg.content,
                    "content_length": len(msg.content),
                }
                for msg in self.messages
            ],
        }
        self.file_only_logger.info(f"è¯·æ±‚å¤§æ¨¡å‹å‚æ•°: {json.dumps(request_params, ensure_ascii=False, indent=2)}")

    def _log_llm_response_data_to_file(self, assistant_text: str, tool_call: dict[str, Any] | None) -> None:
        """æŠŠæœ¬æ¬¡ LLM è¿”å›æ•°æ®æ‘˜è¦å†™å…¥ file_only_loggerã€‚"""
        response_data = {
            "text_length": len(assistant_text),
            "text_preview": assistant_text[:500] + "..." if len(assistant_text) > 500 else assistant_text,
            "truncated": len(assistant_text) > 500,
            "has_tool_call": tool_call is not None,
            "tool_call": tool_call if tool_call else None,
        }
        self.file_only_logger.info(f"å¤§æ¨¡å‹è¿”å›æ•°æ®: {json.dumps(response_data, ensure_ascii=False, indent=2)}")

    def _run_tool_lifecycle(
        self,
        name: str,
        args: dict[str, Any],
        trace_id: str,
        confirm: Callable[[str], bool],
        _ev: Callable[[str, dict[str, Any]], None],
    ) -> ToolResult:
        """
        ç»Ÿä¸€å·¥å…·æ‰§è¡Œç”Ÿå‘½å‘¨æœŸï¼šç­–ç•¥æ£€æŸ¥ -> ç¡®è®¤ -> å®¡è®¡ -> æ‰§è¡Œ -> éªŒè¯ã€‚
        """
        # 1. ç¡®è®¤ç­–ç•¥ (MVP: å†™/æ‰§è¡Œ ç¡®è®¤)
        if name in {"write_file", "apply_patch", "undo_patch"} and self.cfg.policy.confirm_write:
            self.logger.info(f"[yellow]âš  éœ€è¦ç”¨æˆ·ç¡®è®¤å†™æ–‡ä»¶æ“ä½œ: {name}[/yellow]")
            if not confirm(f"ç¡®è®¤å†™æ–‡ä»¶ï¼Ÿtool={name} args={args}"):
                self.logger.warning(f"[red]âœ— ç”¨æˆ·æ‹’ç»å†™æ–‡ä»¶æ“ä½œ: {name}[/red]")
                self.audit.write(trace_id=trace_id, event="confirm_deny", data={"tool": name, "args": args})
                _ev("denied_by_user", {"tool": name})
                return ToolResult(ok=False, error={"code": "E_DENIED", "message": "User denied write access"})
            else:
                self.logger.info(f"[green]âœ“ ç”¨æˆ·ç¡®è®¤å†™æ–‡ä»¶æ“ä½œ: {name}[/green]")

        if name == "run_cmd":
            cmd = str(args.get("command", ""))
            # å†…éƒ¨å®‰å…¨è¯„ä¼°ï¼ˆé»‘åå•ï¼‰
            decision = evaluate_command(cmd, allow_network=self.cfg.policy.allow_network)
            if not decision.ok:
                self.logger.warning(f"[red]âœ— ç­–ç•¥æ‹’ç»å‘½ä»¤: {cmd} (åŸå› : {decision.reason})[/red]")
                self.audit.write(trace_id=trace_id, event="policy_deny_cmd", data={"command": cmd, "reason": decision.reason})
                _ev("policy_deny_cmd", {"command": cmd, "reason": decision.reason})
                return ToolResult(ok=False, error={"code": "E_POLICY", "message": decision.reason})
            # ç”¨æˆ·äº¤äº’ç¡®è®¤
            if self.cfg.policy.confirm_exec:
                self.logger.info(f"[yellow]âš  éœ€è¦ç”¨æˆ·ç¡®è®¤æ‰§è¡Œå‘½ä»¤: {cmd}[/yellow]")
                if not confirm(f"ç¡®è®¤æ‰§è¡Œå‘½ä»¤ï¼Ÿ{cmd}"):
                    self.logger.warning(f"[red]âœ— ç”¨æˆ·æ‹’ç»æ‰§è¡Œå‘½ä»¤: {cmd}[/red]")
                    self.audit.write(trace_id=trace_id, event="confirm_deny", data={"tool": name, "command": cmd})
                    _ev("denied_by_user", {"tool": name})
                    return ToolResult(ok=False, error={"code": "E_DENIED", "message": "User denied command execution"})
                else:
                    self.logger.info(f"[green]âœ“ ç”¨æˆ·ç¡®è®¤æ‰§è¡Œå‘½ä»¤[/green]")

        # 2. æ ¸å¿ƒæ‰§è¡Œ
        self.logger.info(f"[bold cyan]â–¶ æ‰§è¡Œå·¥å…·: {name}[/bold cyan]")
        result = self._dispatch_tool(name, args)

        # è¯¦ç»†æ—¥å¿—è¾“å‡º
        result_summary = self._format_result_summary(name, result)
        if result.ok:
            self.logger.info(f"[green]âœ“ å·¥å…·æ‰§è¡ŒæˆåŠŸ: {name}[/green] [ç»“æœ] {result_summary}")
        else:
            error_msg = result.error.get("message", str(result.error)) if isinstance(result.error, dict) else str(result.error)
            self.logger.error(f"[red]âœ— å·¥å…·æ‰§è¡Œå¤±è´¥: {name}[/red] [é”™è¯¯] {error_msg} [ç»“æœ] {result_summary}")

        # 3. è®°å½•å®¡è®¡
        audit_data: dict[str, Any] = {"tool": name, "args": args, "ok": result.ok, "error": result.error}
        if name in {"apply_patch", "undo_patch"} and result.ok and result.payload:
            audit_data["payload"] = result.payload  # è®°å½• hash/undo_id
        self.audit.write(trace_id=trace_id, event="tool_call", data=audit_data)
        
        # 4. è®°å½•è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶
        self.file_only_logger.info(
            f"å·¥å…·æ‰§è¡Œç»“æœ [tool={name}] [ok={result.ok}] "
            f"[error={json.dumps(result.error, ensure_ascii=False) if result.error else None}] "
            f"[payload_keys={list(result.payload.keys()) if result.payload else []}]"
        )

        # 5. è‡ªåŠ¨åŒ–éªŒè¯é—­ç¯ (è‡ªæ„ˆ)
        if result.ok and name in {"write_file", "apply_patch", "undo_patch", "run_cmd"}:
            self.logger.info("[bold magenta]ğŸ” è‡ªåŠ¨è§¦å‘éªŒè¯é—­ç¯...[/bold magenta]")
            v_res = self.verifier.run_verify()
            _ev("autofix_check", {"ok": v_res.ok, "type": v_res.type, "summary": v_res.summary})
            
            if v_res.ok:
                self.logger.info(f"[green]âœ“ éªŒè¯é€šè¿‡[/green] [æ‘˜è¦] {v_res.summary}")
            else:
                error_details = "; ".join([f"{err.file}:{err.line} {err.message}" for err in (v_res.errors or [])[:3]])
                self.logger.warning(f"[yellow]âš  éªŒè¯å¤±è´¥[/yellow] [æ‘˜è¦] {v_res.summary} [é”™è¯¯] {error_details}")
                self.file_only_logger.warning(
                    f"éªŒè¯å¤±è´¥è¯¦æƒ… [tool={name}] [errors={json.dumps([{'file': err.file, 'line': err.line, 'message': err.message} for err in (v_res.errors or [])], ensure_ascii=False)}]"
                )
                # æ³¨å…¥éªŒè¯å¤±è´¥ä¿¡æ¯åˆ°ç»“æœ payload
                v_msg = f"\n\n[éªŒè¯å¤±è´¥ - è‡ªåŠ¨è‡ªæ£€ç»“æœ]\nçŠ¶æ€: {v_res.summary}\n"
                if v_res.errors:
                    v_msg += "å…·ä½“é”™è¯¯:\n"
                    for err in v_res.errors[:3]:
                        v_msg += f"- {err.file}:{err.line} {err.message}\n"
                if result.payload is None:
                    result = ToolResult(ok=True, payload={"verification_error": v_msg})
                else:
                    result.payload["verification_error"] = v_msg

        return result

    def _classify_intent_and_decide_planning(self, user_text: str, _ev: Callable[[str, dict[str, Any]], None]) -> bool:
        """æ„å›¾åˆ†ç±»å’Œå†³ç­–é—¨ï¼šæ ¹æ®ç”¨æˆ·æ„å›¾å†³å®šæ˜¯å¦å¯ç”¨è§„åˆ’ã€‚"""
        classification = self.classifier.classify(user_text)
        self.logger.info(f"[bold cyan]æ„å›¾è¯†åˆ«ç»“æœ: {classification.category.value}[/bold cyan] (ç½®ä¿¡åº¦: {classification.confidence})")
        _ev("intent_classified", classification.model_dump())

        enable_planning = self.cfg.orchestrator.enable_planning
        if classification.category in (IntentCategory.CAPABILITY_QUERY, IntentCategory.GENERAL_CHAT):
            if enable_planning:
                self.logger.info("[dim]æ£€æµ‹åˆ°èƒ½åŠ›è¯¢é—®æˆ–é€šç”¨å¯¹è¯ï¼Œè·³è¿‡æ˜¾å¼è§„åˆ’é˜¶æ®µã€‚[/dim]")
                enable_planning = False
        return enable_planning

    def _execute_planning_phase(self, user_text: str, planning_prompt: str | None, trace_id: str, _ev: Callable[[str, dict[str, Any]], None], _llm_chat: Callable[[str, str | None], str]) -> Plan | None:
        """æ‰§è¡Œè§„åˆ’é˜¶æ®µï¼šç”Ÿæˆæ˜¾å¼ Planã€‚"""
        if not planning_prompt:
            return None

        _ev("state", {"state": AgentState.PLANNING.value, "reason": "enable_planning"})
        self.logger.info("[bold magenta]ğŸ§© è¿›å…¥è§„åˆ’é˜¶æ®µï¼šç”Ÿæˆæ˜¾å¼ Plan[/bold magenta]")

        plan_attempts = 0
        while plan_attempts <= self.cfg.orchestrator.planning_retry:
            plan_attempts += 1
            _ev("planning_llm_request", {"attempt": plan_attempts})
            assistant_plan = _llm_chat("planning", None)
            _ev("planning_llm_response", {"text": assistant_plan[:4000], "truncated": len(assistant_plan) > 4000})

            self.messages.append(ChatMessage(role="assistant", content=assistant_plan))
            self._trim_history(max_messages=30)
            try:
                parsed = parse_plan_from_text(assistant_plan)
                if len(parsed.steps) > self.cfg.orchestrator.max_plan_steps:
                    parsed.steps = parsed.steps[: self.cfg.orchestrator.max_plan_steps]
                plan = parsed
                # å®Œå–„ï¼šå¼ºåˆ¶æ‰§è¡Œ ID å”¯ä¸€æ€§æ ¡éªŒï¼Œé˜²æ­¢ LLM ç”Ÿæˆé‡å¤æ­¥éª¤å¯¼è‡´é€»è¾‘æ··ä¹±
                try:
                    plan.validate_unique_ids()
                except ValueError as ve:
                    # è‡ªåŠ¨å°è¯•ä¿®å¤ï¼šå¦‚æœå‘ç°é‡å¤ IDï¼Œåˆ™é‡æ–°ç”Ÿæˆæˆ–æŠ›å‡ºå¼‚å¸¸è§¦å‘é‡è¯•
                    self.logger.warning(f"[yellow]ğŸ§© è®¡åˆ’æ­¥éª¤ ID é‡å¤ï¼Œå°è¯•è¿›å…¥é‡è¯•é€»è¾‘: {ve}[/yellow]")
                    raise ve

                self.audit.write(trace_id=trace_id, event="plan_generated", data={"title": plan.title, "steps": [s.model_dump() for s in plan.steps]})
                _ev("plan_generated", {"title": plan.title, "steps": len(plan.steps)})
                self.logger.info("[green]âœ“ è®¡åˆ’ç”ŸæˆæˆåŠŸ[/green]")
                plan_summary = render_plan_markdown(plan)
                self.logger.info(f"[dim]è®¡åˆ’æ‘˜è¦:\n{plan_summary}[/dim]")
                self.file_only_logger.info("ç”Ÿæˆè®¡åˆ’:\n" + plan_summary)
                return plan
            except Exception as e:
                self.logger.warning(f"[yellow]âš  è®¡åˆ’è§£æå¤±è´¥ï¼ˆattempt={plan_attempts}ï¼‰: {e}[/yellow]")
                self.audit.write(trace_id=trace_id, event="plan_parse_failed", data={"attempt": plan_attempts, "error": str(e)})
                _ev("plan_parse_failed", {"attempt": plan_attempts, "error": str(e)})
                self.messages.append(ChatMessage(role="user", content="ä¸Šé¢çš„è¾“å‡ºæ— æ³•è§£æä¸º Plan JSONã€‚è¯·åªè¾“å‡ºä¸€ä¸ªä¸¥æ ¼ JSON å¯¹è±¡ï¼ˆä¸è¦è§£é‡Šï¼Œä¸è¦ä»£ç å—ï¼‰ã€‚"))
                self._trim_history(max_messages=30)
        return None

    def _check_step_dependencies(self, step, plan: Plan, trace_id: str, _ev: Callable[[str, dict[str, Any]], None]) -> list[str]:
        """æ£€æŸ¥æ­¥éª¤ä¾èµ–æ˜¯å¦æ»¡è¶³ï¼Œå¦‚æœä¸æ»¡è¶³åˆ™æ ‡è®°ä¸º blockedã€‚"""
        completed_ids = {s.id for s in plan.steps if s.status == "done"}
        unmet_deps = [dep for dep in step.dependencies if dep not in completed_ids]
        if unmet_deps:
            self.logger.warning(f"[yellow]âš  æ­¥éª¤ {step.id} æœ‰æœªæ»¡è¶³çš„ä¾èµ–: {unmet_deps}ï¼Œè·³è¿‡å¹¶æ ‡è®°ä¸º blocked[/yellow]")
            step.status = "blocked"
            self.audit.write(trace_id=trace_id, event="plan_step_blocked", data={"step_id": step.id, "unmet_deps": unmet_deps})
            _ev("plan_step_blocked", {"step_id": step.id, "unmet_deps": unmet_deps})
        return unmet_deps

    def _handle_tool_call_in_step(
        self,
        name: str,
        args: dict[str, Any],
        step,
        trace_id: str,
        keywords: set[str],
        confirm: Callable[[str], bool],
        _ev: Callable[[str, dict[str, Any]], None],
        _tool_result_to_message: Callable[[str, ToolResult, set[str] | None], str],
    ) -> tuple[ToolResult, bool]:
        """
        å¤„ç†æ­¥éª¤ä¸­çš„å·¥å…·è°ƒç”¨ï¼šç¡®è®¤ã€ç­–ç•¥æ£€æŸ¥ã€æ‰§è¡Œã€éªŒè¯ã€‚
        è¿”å›: (result, did_modify_code)
        """
        # è°ƒç”¨ç»Ÿä¸€ç”Ÿå‘½å‘¨æœŸ
        result = self._run_tool_lifecycle(name, args, trace_id, confirm, _ev)

        # åˆ¤æ–­æ˜¯å¦ä¿®æ”¹äº†ä»£ç 
        did_modify_code = (name in {"write_file", "apply_patch", "undo_patch"} and result.ok)

        # è®°å½•æ­¥éª¤å…³è”çš„ç»“æœ
        _ev("tool_result", {"tool": name, "ok": result.ok, "error": result.error, "payload": result.payload, "step_id": step.id})
        
        # å›é¦ˆç»“æœ
        result_msg = _tool_result_to_message(name, result, keywords=keywords)
        self.messages.append(ChatMessage(role="user", content=result_msg))
        self.logger.debug(f"[dim]å·¥å…·ç»“æœå·²å›å–‚[/dim] [å·¥å…·] {name} [æ­¥éª¤] {step.id}")
        self.file_only_logger.debug(f"å·¥å…·ç»“æœå›å–‚ [step={step.id}] [tool={name}] [len={len(result_msg)}]")
        _ev("tool_result_fed_back", {"tool": name})
        self._trim_history(max_messages=30)
        
        return result, did_modify_code

    def _execute_single_step_iteration(
        self,
        step,
        step_cursor: int,
        plan: Plan,
        iteration: int,
        trace_id: str,
        keywords: set[str],
        confirm: Callable[[str], bool],
        _ev: Callable[[str, dict[str, Any]], None],
        _llm_chat: Callable[[str, str | None], str],
        _try_parse_tool_call: Callable[[str], dict[str, Any] | None],
        _tool_result_to_message: Callable[[str, ToolResult, set[str] | None], str],
    ) -> tuple[str | None, bool, bool]:
        """
        æ‰§è¡Œå•ä¸ªè®¡åˆ’æ­¥éª¤çš„ä¸€æ¬¡ LLM äº¤äº’è½®æ¬¡ã€‚
        è¿”å›: (control_signal, did_modify_code, did_use_tool)
        """
        tools_hint = ", ".join(step.tools_expected) if step.tools_expected else "ï¼ˆæœªæŒ‡å®šï¼Œæ¨¡å‹è‡ªé€‰ï¼‰"
        self.logger.info(
            f"[bold yellow]â†’ æ‰§è¡Œæ­¥éª¤ {step_cursor + 1}/{len(plan.steps)}: {step.id}ï¼ˆè½®æ¬¡ {iteration + 1}/{self.cfg.orchestrator.max_step_tool_calls}ï¼‰[/bold yellow] "
            f"[æè¿°] {step.description} [å»ºè®®å·¥å…·] {tools_hint}"
        )
        _ev("llm_request", {"messages": len(self.messages), "step_id": step.id, "iteration": iteration + 1})

        # è®°å½•è¯·æ±‚å‚æ•°åˆ°æ–‡ä»¶
        self._log_llm_request_params_to_file()

        step_prompt = (
            f"ç°åœ¨æ‰§è¡Œè®¡åˆ’æ­¥éª¤ï¼š{step.id}\n"
            f"æ­¥éª¤æè¿°ï¼š{step.description}\n"
            f"å»ºè®®å·¥å…·ï¼š{', '.join(step.tools_expected) if step.tools_expected else 'ï¼ˆè‡ªè¡Œé€‰æ‹©ï¼‰'}\n\n"
            "è§„åˆ™ï¼š\n"
            "1) å¦‚æœéœ€è¦å·¥å…·ï¼šåªè¾“å‡ºä¸€ä¸ªå·¥å…·è°ƒç”¨ JSONï¼ˆä¸ç³»ç»Ÿè¦æ±‚ä¸€è‡´ï¼‰ã€‚\n"
            "2) å¦‚æœæœ¬æ­¥éª¤å·²å®Œæˆä¸”ä¸éœ€è¦å·¥å…·ï¼šåªè¾“å‡ºå­—ç¬¦ä¸²ã€STEP_DONEã€‘ã€‚\n"
            "3) å¦‚æœæœ¬æ­¥éª¤å¤±è´¥ä¸”éœ€è¦é‡è§„åˆ’ï¼šåªè¾“å‡ºå­—ç¬¦ä¸²ã€REPLANã€‘ã€‚\n"
        )
        self.messages.append(ChatMessage(role="user", content=step_prompt))
        self._trim_history(max_messages=30)

        assistant = _llm_chat("execute_step", step.id)
        _ev("llm_response", {"text": assistant[:4000], "truncated": len(assistant) > 4000, "step_id": step.id})

        # stuttering é˜²æŠ¤
        if assistant.count("[") > 50 or assistant.count("{") > 50:
            self.logger.warning("[red]æ£€æµ‹åˆ°æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼ˆå¤è¯»å­—ç¬¦ï¼‰ï¼Œå·²å¼ºåˆ¶æˆªæ–­[/red]")
            assistant = "æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼šæ£€æµ‹åˆ°è¿‡å¤šçš„é‡å¤å­—ç¬¦ï¼Œå·²å¼ºåˆ¶æˆªæ–­ã€‚"
            _ev("stuttering_detected", {"length": len(assistant), "step_id": step.id})

        # æ£€æŸ¥æ§åˆ¶æ ‡è®°
        a_strip = assistant.strip()
        if "STEP_DONE" in a_strip or "ã€STEP_DONEã€‘" in a_strip or a_strip.upper().startswith("STEP_DONE"):
            self.messages.append(ChatMessage(role="assistant", content=assistant))
            self._trim_history(max_messages=30)
            step.status = "done"
            self.audit.write(trace_id=trace_id, event="plan_step_done", data={"step_id": step.id})
            _ev("plan_step_done", {"step_id": step.id})
            self.logger.info(f"[green]âœ“ æ­¥éª¤å®Œæˆ[/green] [æ­¥éª¤] {step.id} [æè¿°] {step.description} [è½®æ¬¡] {iteration + 1}/{self.cfg.orchestrator.max_step_tool_calls}")
            self.file_only_logger.info(f"æ­¥éª¤å®Œæˆè¯¦æƒ… [step_id={step.id}] [description={step.description}] [iteration={iteration + 1}]")
            return "STEP_DONE", False, False

        if "REPLAN" in a_strip or "ã€REPLANã€‘" in a_strip or a_strip.upper().startswith("REPLAN"):
            self.messages.append(ChatMessage(role="assistant", content=assistant))
            self._trim_history(max_messages=30)
            step.status = "failed"
            self.audit.write(trace_id=trace_id, event="plan_step_replan_requested", data={"step_id": step.id})
            _ev("plan_step_replan_requested", {"step_id": step.id})
            self.logger.warning(f"[yellow]âš  æ­¥éª¤è¯·æ±‚é‡è§„åˆ’[/yellow] [æ­¥éª¤] {step.id} [æè¿°] {step.description} [è½®æ¬¡] {iteration + 1}/{self.cfg.orchestrator.max_step_tool_calls} [åŸå› ] æ¨¡å‹è¾“å‡ºã€REPLANã€‘æ ‡è®°")
            self.file_only_logger.info(f"æ­¥éª¤è¯·æ±‚é‡è§„åˆ’è¯¦æƒ… [step_id={step.id}] [description={step.description}] [iteration={iteration + 1}]")
            return "REPLAN", False, False

        # å°è¯•è§£æå·¥å…·è°ƒç”¨
        tool_call = _try_parse_tool_call(assistant)
        
        # è®°å½•å“åº”æ•°æ®åˆ°æ–‡ä»¶
        self._log_llm_response_data_to_file(assistant, tool_call)

        if tool_call is None:
            self.messages.append(ChatMessage(role="assistant", content=assistant))
            self._trim_history(max_messages=30)
            self.messages.append(ChatMessage(role="user", content="ä½ çš„è¾“å‡ºæ—¢ä¸æ˜¯å·¥å…·è°ƒç”¨ JSONï¼Œä¹Ÿä¸æ˜¯ã€STEP_DONEã€‘/ã€REPLANã€‘ã€‚è¯·ä¸¥æ ¼æŒ‰è§„åˆ™è¾“å‡ºã€‚"))
            self._trim_history(max_messages=30)
            return None, False, False

        name = tool_call["tool"]
        args = tool_call["args"]
        _ev("tool_call_parsed", {"tool": name, "args": args, "step_id": step.id})
        
        args_summary = self._format_args_summary(name, args)
        self.logger.info(f"[bold blue]ğŸ”§ è§£æåˆ°å·¥å…·è°ƒç”¨: {name}[/bold blue] [æ­¥éª¤] {step.id} [å‚æ•°] {args_summary}")
        self.file_only_logger.info(f"å·¥å…·è°ƒç”¨è¯¦æƒ… [step_id={step.id}] [tool={name}] [args={json.dumps(args, ensure_ascii=False)}]")

        clean_assistant = json.dumps(tool_call, ensure_ascii=False)
        self.messages.append(ChatMessage(role="assistant", content=clean_assistant))
        self._trim_history(max_messages=30)

        # å¤„ç†å·¥å…·è°ƒç”¨
        result, did_modify_code = self._handle_tool_call_in_step(name, args, step, trace_id, keywords, confirm, _ev, _tool_result_to_message)
        if result is None:
            # ç”¨æˆ·æ‹’ç»æˆ–ç­–ç•¥æ‹¦æˆªï¼Œæ­¤æ—¶è™½ç„¶å°è¯•äº†è°ƒç”¨ï¼Œä½†å®é™…æœªæ‰§è¡ŒæˆåŠŸï¼Œè®°å½•ä¸ºå·²ä½¿ç”¨è¿‡å·¥å…·ï¼ˆè½®æ¬¡æ¶ˆè€—ï¼‰
            return None, False, True

        return None, did_modify_code, True

    def _handle_replanning(
        self,
        step,
        plan: Plan,
        replans_used: int,
        trace_id: str,
        tool_used: bool,
        _ev: Callable[[str, dict[str, Any]], None],
        _llm_chat: Callable[[str, str | None], str],
        _set_state: Callable[[AgentState, dict[str, Any] | None], None],
    ) -> tuple[Plan | None, int]:
        """å¤„ç†é‡è§„åˆ’é€»è¾‘ã€‚è¿”å›: (new_plan, new_replans_used)"""
        if replans_used >= self.cfg.orchestrator.max_replans:
            self.logger.warning(f"[red]âš  è¾¾åˆ°æœ€å¤§é‡è§„åˆ’æ¬¡æ•°ï¼Œåœæ­¢[/red] [å½“å‰æ­¥éª¤] {step.id} [æè¿°] {step.description} [å·²ç”¨é‡è§„åˆ’] {replans_used}/{self.cfg.orchestrator.max_replans}")
            self.file_only_logger.warning(f"è¾¾åˆ°æœ€å¤§é‡è§„åˆ’æ¬¡æ•° [step_id={step.id}] [replans_used={replans_used}] [max_replans={self.cfg.orchestrator.max_replans}]")
            _ev("stop_reason", {"reason": "max_replans_reached", "limit": self.cfg.orchestrator.max_replans})
            return None, replans_used

        replans_used += 1
        _set_state(AgentState.RECOVERING, {"reason": "step_failed", "step_id": step.id, "replans_used": replans_used})
        _set_state(AgentState.PLANNING, {"reason": "replan", "replans_used": replans_used})
        completed_count = len([s for s in plan.steps if s.status == "done"])
        self.logger.info(f"[bold magenta]ğŸ” è§¦å‘é‡è§„åˆ’ï¼ˆç¬¬ {replans_used} æ¬¡ï¼‰[/bold magenta] [å¤±è´¥æ­¥éª¤] {step.id} [æè¿°] {step.description} [å·²å®Œæˆæ­¥éª¤] {completed_count}/{len(plan.steps)}")
        self.file_only_logger.info(f"è§¦å‘é‡è§„åˆ’ [replans_used={replans_used}] [failed_step_id={step.id}] [description={step.description}] [completed_steps={completed_count}/{len(plan.steps)}]")

        replan_prompt = (
            "å‡ºç°é˜»å¡/å¤±è´¥ï¼Œéœ€è¦é‡è§„åˆ’ã€‚è¯·è¾“å‡ºæ–°çš„ Plan JSONï¼ˆä¸¥æ ¼ JSONï¼Œä¸è¦è§£é‡Šï¼Œä¸è¦è°ƒç”¨å·¥å…·ï¼‰ã€‚\n"
            f"é™åˆ¶ï¼šsteps ä¸è¶…è¿‡ {self.cfg.orchestrator.max_plan_steps}ã€‚\n"
            "è¯·ç»“åˆå½“å‰å¯¹è¯ä¸­çš„é”™è¯¯ä¸å·¥å…·åé¦ˆï¼Œç”Ÿæˆæ›´å¯æ‰§è¡Œçš„æ­¥éª¤ã€‚"
        )
        self.messages.append(ChatMessage(role="user", content=replan_prompt))
        self._trim_history(max_messages=30)
        assistant_plan = _llm_chat("replan", step.id)
        self.messages.append(ChatMessage(role="assistant", content=assistant_plan))
        self._trim_history(max_messages=30)
        
        try:
            new_plan = parse_plan_from_text(assistant_plan)
            if len(new_plan.steps) > self.cfg.orchestrator.max_plan_steps:
                new_plan.steps = new_plan.steps[: self.cfg.orchestrator.max_plan_steps]
            self.audit.write(trace_id=trace_id, event="plan_replanned", data={"title": new_plan.title, "steps": [s.model_dump() for s in new_plan.steps], "replans_used": replans_used})
            _ev("plan_replanned", {"title": new_plan.title, "steps": len(new_plan.steps), "replans_used": replans_used})
            plan_summary = render_plan_markdown(new_plan)
            self.logger.info(f"[green]âœ“ é‡è§„åˆ’æˆåŠŸ[/green] [æ ‡é¢˜] {new_plan.title} [æ­¥éª¤æ•°] {len(new_plan.steps)} [é‡è§„åˆ’æ¬¡æ•°] {replans_used}/{self.cfg.orchestrator.max_replans}")
            self.file_only_logger.info(f"é‡è§„åˆ’æˆåŠŸ [title={new_plan.title}] [steps={len(new_plan.steps)}] [replans_used={replans_used}] [plan_summary={plan_summary[:500]}]")
            _set_state(AgentState.EXECUTING, {"steps": len(new_plan.steps)})
            return new_plan, replans_used
        except Exception as e:
            self.logger.warning(f"[yellow]âš  é‡è§„åˆ’è§£æå¤±è´¥[/yellow] [é”™è¯¯] {str(e)} [é‡è§„åˆ’æ¬¡æ•°] {replans_used}/{self.cfg.orchestrator.max_replans}")
            self.file_only_logger.exception(f"é‡è§„åˆ’è§£æå¤±è´¥ [replans_used={replans_used}] [error={str(e)}]", exc_info=True)
            self.audit.write(trace_id=trace_id, event="plan_replan_parse_failed", data={"error": str(e)})
            _ev("plan_replan_parse_failed", {"error": str(e)})
            _ev("stop_reason", {"reason": "replan_parse_failed", "error": str(e)})
            return None, replans_used

    def _execute_final_verification(self, plan: Plan, did_modify_code: bool, trace_id: str, tool_used: bool, _ev: Callable[[str, dict[str, Any]], None], _set_state: Callable[[AgentState, dict[str, Any] | None], None]) -> AgentTurn | None:
        """æ‰§è¡Œæœ€ç»ˆéªŒè¯é˜¶æ®µã€‚å¦‚æœéªŒè¯å¤±è´¥ï¼Œè¿”å› AgentTurnï¼›å¦åˆ™è¿”å› Noneã€‚"""
        _set_state(AgentState.VERIFYING, {"did_modify_code": did_modify_code})
        if not did_modify_code:
            return None

        self.logger.info(f"[bold magenta]ğŸ” è¿›å…¥æœ€ç»ˆéªŒè¯é˜¶æ®µ[/bold magenta] [å·²å®Œæˆæ­¥éª¤] {len([s for s in plan.steps if s.status == 'done'])}/{len(plan.steps)}")
        v_res = self.verifier.run_verify()
        _ev("final_verify", {"ok": v_res.ok, "type": v_res.type, "summary": v_res.summary})
        
        if v_res.ok:
            self.logger.info(f"[green]âœ“ æœ€ç»ˆéªŒè¯é€šè¿‡[/green] [ç±»å‹] {v_res.type} [æ‘˜è¦] {v_res.summary}")
        else:
            error_details = "; ".join([f"{err.file}:{err.line} {err.message}" for err in (v_res.errors or [])[:5]])
            self.logger.warning(f"[yellow]âš  æœ€ç»ˆéªŒè¯å¤±è´¥[/yellow] [ç±»å‹] {v_res.type} [æ‘˜è¦] {v_res.summary} [é”™è¯¯] {error_details}")
            self.file_only_logger.warning(f"æœ€ç»ˆéªŒè¯å¤±è´¥ [type={v_res.type}] [summary={v_res.summary}] [errors={json.dumps([{'file': err.file, 'line': err.line, 'message': err.message} for err in (v_res.errors or [])], ensure_ascii=False)}]")
        
        if not v_res.ok:
            text = f"æœ€ç»ˆéªŒè¯å¤±è´¥ï¼š{v_res.summary}\n"
            if v_res.errors:
                for err in v_res.errors[:10]:
                    text += f"- {err.file}:{err.line} {err.message}\n"
            _set_state(AgentState.DONE, {"ok": False})
            return AgentTurn(assistant_text=text, tool_used=tool_used, trace_id=trace_id, events=[])
        return None

    def _execute_react_fallback_loop(
        self,
        trace_id: str,
        keywords: set[str],
        confirm: Callable[[str], bool],
        events: list[dict[str, Any]],
        _ev: Callable[[str, dict[str, Any]], None],
        _llm_chat: Callable[[str, str | None], str],
        _try_parse_tool_call: Callable[[str], dict[str, Any] | None],
        _tool_result_to_message: Callable[[str, ToolResult, set[str] | None], str],
        _set_state: Callable[[AgentState, dict[str, Any] | None], None],
    ) -> AgentTurn:
        """æ‰§è¡Œ ReAct fallback å¾ªç¯ï¼ˆå•çº§å¾ªç¯ï¼Œæ— è§„åˆ’ï¼‰ã€‚"""
        _set_state(AgentState.EXECUTING, {"mode": "react_fallback"})
        tool_used = False
        
        for iteration in range(20):  # hard stop to avoid infinite loops
            self.logger.info(f"[bold yellow]â†’ ç¬¬ {iteration + 1} è½®ï¼šè¯·æ±‚ LLMï¼ˆæ¶ˆæ¯æ•°={len(self.messages)}ï¼‰[/bold yellow]")
            _ev("llm_request", {"messages": len(self.messages)})
            
            # è®°å½•è¯·æ±‚å‚æ•°åˆ°æ–‡ä»¶ï¼ˆä¸è¾“å‡ºåˆ°å±å¹•ï¼‰
            self._log_llm_request_params_to_file()
            
            assistant = _llm_chat("react_fallback", None)
            
            # Robustness: Detect repetitive/broken outputs (stuttering)
            if assistant.count("[") > 50 or assistant.count("{") > 50:
                self.logger.warning("[red]æ£€æµ‹åˆ°æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼ˆå¤è¯»å­—ç¬¦ï¼‰ï¼Œå·²å¼ºåˆ¶æˆªæ–­[/red]")
                assistant = "æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼šæ£€æµ‹åˆ°è¿‡å¤šçš„é‡å¤å­—ç¬¦ï¼Œå·²å¼ºåˆ¶æˆªæ–­ã€‚è¯·é‡æ–°æè¿°ä½ çš„éœ€æ±‚æˆ–å°è¯•ç¼©å°ä»»åŠ¡èŒƒå›´ã€‚"
                _ev("stuttering_detected", {"length": len(assistant)})

            _ev("llm_response", {"text": assistant[:4000], "truncated": len(assistant) > 4000})
            self.logger.debug(f"[dim]LLM å“åº”é•¿åº¦: {len(assistant)} å­—ç¬¦[/dim]")
            
            # è§£æå·¥å…·è°ƒç”¨ï¼ˆåªè§£æä¸€æ¬¡ï¼‰
            tool_call = _try_parse_tool_call(assistant)
            
            # è®°å½•å“åº”æ•°æ®åˆ°æ–‡ä»¶ï¼ˆä¸è¾“å‡ºåˆ°å±å¹•ï¼‰
            self._log_llm_response_data_to_file(assistant, tool_call)
            if tool_call is None:
                self.logger.info(
                    "[bold green]âœ“ LLM è¿”å›æœ€ç»ˆå›å¤ï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰[/bold green] "
                    f"[è½®æ¬¡] {iteration + 1}/20 [å“åº”é•¿åº¦] {len(assistant)} å­—ç¬¦"
                )
                self.messages.append(ChatMessage(role="assistant", content=assistant))
                self.audit.write(trace_id=trace_id, event="assistant_text", data={"text": assistant})
                _ev("final_text", {"text": assistant[:4000], "truncated": len(assistant) > 4000})
                self._trim_history(max_messages=30)
                return AgentTurn(assistant_text=assistant, tool_used=tool_used, trace_id=trace_id, events=events)

            name = tool_call["tool"]
            args = tool_call["args"]
            args_summary = self._format_args_summary(name, args)
            self.logger.info(
                f"[bold blue]ğŸ”§ è§£æåˆ°å·¥å…·è°ƒç”¨: {name}[/bold blue] "
                f"[è½®æ¬¡] {iteration + 1}/20 [å‚æ•°] {args_summary}"
            )
            self.file_only_logger.info(
                f"å·¥å…·è°ƒç”¨è¯¦æƒ… [iteration={iteration + 1}] [tool={name}] [args={json.dumps(args, ensure_ascii=False)}]"
            )
            _ev("tool_call_parsed", {"tool": name, "args": args})

            clean_assistant = json.dumps(tool_call, ensure_ascii=False)
            self.messages.append(ChatMessage(role="assistant", content=clean_assistant))
            _ev("assistant_tool_call_recorded", {"tool": name})
            self._trim_history(max_messages=30)

            # è°ƒç”¨ç»Ÿä¸€ç”Ÿå‘½å‘¨æœŸ
            result = self._run_tool_lifecycle(name, args, trace_id, confirm, _ev)
            tool_used = True

            _ev("tool_result", {"tool": name, "ok": result.ok, "error": result.error, "payload": result.payload})
            
            # å›å–‚ç»“æœ
            result_msg = _tool_result_to_message(name, result, keywords=keywords)
            self.messages.append(ChatMessage(role="user", content=result_msg))
            self.logger.debug(f"[dim]å·¥å…·ç»“æœå·²å›å–‚[/dim] [å·¥å…·] {name}")
            self.file_only_logger.debug(f"å·¥å…·ç»“æœå›å–‚ [tool={name}] [len={len(result_msg)}]")
            _ev("tool_result_fed_back", {"tool": name})
            self._trim_history(max_messages=30)

        self.logger.warning("[red]âš  è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆ20ï¼‰ï¼Œåœæ­¢ä»¥é¿å…æ­»å¾ªç¯[/red]")
        _ev("stop_reason", {"reason": "max_tool_calls_reached", "limit": 20})
        return AgentTurn(
            assistant_text="è¾¾åˆ°æœ¬è½®æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆ20ï¼‰ï¼Œå·²åœæ­¢ä»¥é¿å…æ­»å¾ªç¯ã€‚è¯·ç¼©å°ä»»åŠ¡æˆ–æä¾›æ›´å¤šçº¦æŸ/å…¥å£æ–‡ä»¶ã€‚",
            tool_used=tool_used,
            trace_id=trace_id,
            events=events,
        )

    def _execute_plan_steps(
        self,
        plan: Plan,
        trace_id: str,
        keywords: set[str],
        confirm: Callable[[str], bool],
        events: list[dict[str, Any]],
        _ev: Callable[[str, dict[str, Any]], None],
        _llm_chat: Callable[[str, str | None], str],
        _try_parse_tool_call: Callable[[str], dict[str, Any] | None],
        _tool_result_to_message: Callable[[str, ToolResult, set[str] | None], str],
        _set_state: Callable[[AgentState, dict[str, Any] | None], None],
    ) -> tuple[Plan | None, bool, bool]:
        """
        æ‰§è¡Œè®¡åˆ’çš„æ‰€æœ‰æ­¥éª¤ï¼ˆä¸»å¾ªç¯ï¼‰ã€‚
        è¿”å›: (plan, tool_used, did_modify_code)
        """
        _set_state(AgentState.EXECUTING, {"steps": len(plan.steps)})
        self.logger.info("[bold magenta]â–¶ è¿›å…¥æ‰§è¡Œé˜¶æ®µï¼šæŒ‰ Plan æ­¥éª¤ç¼–æ’[/bold magenta]")

        replans_used = 0
        step_cursor = 0
        tool_used = False
        did_modify_code = False

        while True:
            if plan is None:
                break
            if step_cursor >= len(plan.steps):
                break

            step = plan.steps[step_cursor]

            # ä¾èµ–æ£€æŸ¥
            unmet_deps = self._check_step_dependencies(step, plan, trace_id, _ev)
            if unmet_deps:
                step_cursor += 1
                continue

            step.status = "in_progress"
            self.audit.write(trace_id=trace_id, event="plan_step_start", data={"step_id": step.id, "description": step.description})
            _ev("plan_step_start", {"step_id": step.id, "idx": step_cursor + 1, "total": len(plan.steps)})

            # æ¯ä¸ªæ­¥éª¤å†…éƒ¨ï¼Œå…è®¸è‹¥å¹²æ¬¡å·¥å…·è°ƒç”¨
            for iteration in range(self.cfg.orchestrator.max_step_tool_calls):
                control_signal, iter_did_modify, iter_did_use_tool = self._execute_single_step_iteration(
                    step, step_cursor, plan, iteration, trace_id, keywords, confirm,
                    _ev, _llm_chat, _try_parse_tool_call, _tool_result_to_message
                )
                
                if iter_did_modify:
                    did_modify_code = True
                if iter_did_use_tool:
                    tool_used = True
                
                if control_signal == "STEP_DONE":
                    break
                elif control_signal == "REPLAN":
                    break

            # æ­¥éª¤è¿­ä»£å¾ªç¯ç»“æŸåå¼ºåˆ¶ç†”æ–­
            if step.status == "in_progress":
                self.logger.warning(
                    f"[yellow]âš  æ­¥éª¤è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ä½†æœªå®Œæˆï¼Œå¼ºåˆ¶æ ‡è®°ä¸º failed[/yellow] "
                    f"[æ­¥éª¤] {step.id} [æè¿°] {step.description} "
                    f"[æœ€å¤§è¿­ä»£] {self.cfg.orchestrator.max_step_tool_calls} [å·¥å…·ä½¿ç”¨] {tool_used}"
                )
                self.file_only_logger.warning(
                    f"æ­¥éª¤è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° [step_id={step.id}] [description={step.description}] "
                    f"[max_iter={self.cfg.orchestrator.max_step_tool_calls}] [tools_used={tool_used}]"
                )
                step.status = "failed"
                self.audit.write(trace_id=trace_id, event="plan_step_max_iter", data={"step_id": step.id, "max_iter": self.cfg.orchestrator.max_step_tool_calls})
                _ev("plan_step_max_iter", {"step_id": step.id, "max_iter": self.cfg.orchestrator.max_step_tool_calls})

            # æ­¥éª¤ç»“æŸåï¼Œæ ¹æ®çŠ¶æ€æ¨è¿›
            if step.status == "done":
                step_cursor += 1
                continue

            # å¦‚æœæ­¥éª¤è¦æ±‚é‡è§„åˆ’
            if step.status == "failed":
                new_plan, new_replans_used = self._handle_replanning(step, plan, replans_used, trace_id, tool_used, _ev, _llm_chat, _set_state)
                if new_plan is None:
                    if replans_used >= self.cfg.orchestrator.max_replans:
                        return None, tool_used, did_modify_code
                    return None, tool_used, did_modify_code
                plan = new_plan
                replans_used = new_replans_used
                step_cursor = 0
                continue

            # å¤„ç† blocked æ­¥éª¤ï¼šæ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ­¥éª¤éƒ½è¢« blockedï¼ˆæ­»é”æ£€æµ‹ï¼‰
            if step.status == "blocked":
                all_blocked_or_done = all(s.status in ("blocked", "done") for s in plan.steps)
                if all_blocked_or_done and any(s.status == "blocked" for s in plan.steps):
                    self.logger.error("[red]âœ— æ£€æµ‹åˆ°ä¾èµ–æ­»é”ï¼šæ‰€æœ‰æœªå®Œæˆæ­¥éª¤éƒ½å¤„äº blocked çŠ¶æ€[/red]")
                    _ev("stop_reason", {"reason": "dependency_deadlock"})
                    return None, tool_used, did_modify_code
                step_cursor += 1
                continue

            # å…¶ä»–çŠ¶æ€ï¼ˆå¡ä½/æœªå®Œæˆï¼‰ï¼šç†”æ–­
            _ev("stop_reason", {"reason": "step_not_completed", "step_id": step.id})
            return None, tool_used, did_modify_code

        return plan, tool_used, did_modify_code

    def _trim_history(self, *, max_messages: int) -> None:
        """
        è£å‰ªå¯¹è¯å†å²ï¼Œä¿æŒä¸Šä¸‹æ–‡çª—å£åœ¨åˆç†èŒƒå›´å†…ã€‚
        
        è£å‰ªç­–ç•¥ï¼š
        1. å§‹ç»ˆä¿ç•™ç¬¬ä¸€æ¡ system æ¶ˆæ¯ï¼ˆåŒ…å«æ ¸å¿ƒæŒ‡ä»¤å’Œ Repo Mapï¼‰
        2. ä»å°¾éƒ¨å‘å‰è£å‰ªï¼Œä½†ç¡®ä¿è£å‰ªåçš„ç¬¬ä¸€æ¡æ¶ˆæ¯æ˜¯ 'user' è§’è‰²
           ï¼ˆæ»¡è¶³ llama.cpp ç­‰ä¸¥æ ¼ chat template çš„ user/assistant äº¤æ›¿è¦æ±‚ï¼‰
        3. å¦‚æœå½“å‰æ¶ˆæ¯æ•° <= max_messagesï¼Œåˆ™ä¸è¿›è¡Œè£å‰ª
        
        å‚æ•°:
            max_messages: æœ€å¤§ä¿ç•™æ¶ˆæ¯æ•°ï¼ˆåŒ…æ‹¬ system æ¶ˆæ¯ï¼‰
        
        æµç¨‹å›¾: è§ `agent_loop_trim_history_flow.svg`
        """
        old_len = len(self.messages)
        if old_len <= max_messages:
            return
        
        system = self.messages[0]
        # We need an odd number of messages in the tail if the last one is 'user'
        # or just ensure the first message of the tail is 'user'.
        tail_start_idx = len(self.messages) - (max_messages - 1)
        
        # Move forward until we find a 'user' message to keep parity
        while tail_start_idx < len(self.messages) and self.messages[tail_start_idx].role != "user":
            tail_start_idx += 1
            
        tail = self.messages[tail_start_idx:]
        self.messages = [system, *tail]
        self.logger.debug(f"[dim]å†å²è£å‰ª: {old_len} â†’ {len(self.messages)} æ¡æ¶ˆæ¯[/dim]")

    def _format_args_summary(self, tool_name: str, args: dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–å·¥å…·å‚æ•°æ‘˜è¦ï¼ˆç”¨äºæ—¥å¿—è¾“å‡ºï¼‰ã€‚
        
        æ ¹æ®å·¥å…·ç±»å‹æå–å…³é”®å‚æ•°ï¼Œé¿å…è¾“å‡ºè¿‡é•¿ã€‚
        """
        if tool_name == "read_file":
            path = args.get("path", "")
            offset = args.get("offset")
            limit = args.get("limit")
            parts = [f"path={path}"]
            if offset is not None:
                parts.append(f"offset={offset}")
            if limit is not None:
                parts.append(f"limit={limit}")
            return " ".join(parts)
        elif tool_name == "grep":
            pattern = args.get("pattern", "")[:60]
            path = args.get("path", ".")
            return f"pattern={pattern!r} path={path}"
        elif tool_name == "apply_patch":
            path = args.get("path", "")
            expected = args.get("expected_replacements", 1)
            fuzzy = args.get("fuzzy", False)
            return f"path={path} expected={expected} fuzzy={fuzzy}"
        elif tool_name == "write_file":
            path = args.get("path", "")
            text_len = len(args.get("text", ""))
            return f"path={path} text_len={text_len}"
        elif tool_name == "run_cmd":
            cmd = args.get("command", "")[:100]
            cwd = args.get("cwd", ".")
            return f"cmd={cmd!r} cwd={cwd}"
        elif tool_name == "list_dir":
            path = args.get("path", ".")
            return f"path={path}"
        elif tool_name == "glob_file_search":
            pattern = args.get("glob_pattern", "")
            target = args.get("target_directory", ".")
            return f"pattern={pattern} target={target}"
        else:
            # é€šç”¨ï¼šåªæ˜¾ç¤ºå‰ 3 ä¸ªå‚æ•°ï¼Œé¿å…è¿‡é•¿
            items = list(args.items())[:3]
            parts = [f"{k}={str(v)[:50]}" for k, v in items]
            if len(args) > 3:
                parts.append("...")
            return " ".join(parts)

    def _format_result_summary(self, tool_name: str, result: ToolResult) -> str:
        """
        æ ¼å¼åŒ–å·¥å…·æ‰§è¡Œç»“æœæ‘˜è¦ï¼ˆç”¨äºæ—¥å¿—è¾“å‡ºï¼‰ã€‚
        
        æ ¹æ®å·¥å…·ç±»å‹å’Œç»“æœæå–å…³é”®ä¿¡æ¯ï¼Œé¿å…è¾“å‡ºè¿‡é•¿ã€‚
        """
        if not result.ok:
            error_msg = result.error.get("message", str(result.error)) if isinstance(result.error, dict) else str(result.error)
            return f"å¤±è´¥: {error_msg[:100]}"
        
        if not result.payload:
            return "æˆåŠŸï¼ˆæ—  payloadï¼‰"
        
        payload = result.payload
        
        if tool_name == "read_file":
            text_len = len(payload.get("text", ""))
            return f"æˆåŠŸ: è¯»å– {text_len} å­—ç¬¦"
        elif tool_name == "grep":
            hits = payload.get("hits", [])
            count = len(hits)
            truncated = payload.get("truncated", False)
            return f"æˆåŠŸ: æ‰¾åˆ° {count} ä¸ªåŒ¹é…{'ï¼ˆå·²æˆªæ–­ï¼‰' if truncated else ''}"
        elif tool_name == "apply_patch":
            replacements = payload.get("replacements", 0)
            undo_id = payload.get("undo_id", "")
            return f"æˆåŠŸ: {replacements} å¤„æ›¿æ¢ undo_id={undo_id[:20]}"
        elif tool_name == "write_file":
            return "æˆåŠŸ: æ–‡ä»¶å·²å†™å…¥"
        elif tool_name == "run_cmd":
            exit_code = payload.get("exit_code", -1)
            stdout_len = len(payload.get("stdout", ""))
            stderr_len = len(payload.get("stderr", ""))
            return f"æˆåŠŸ: exit_code={exit_code} stdout={stdout_len}å­—ç¬¦ stderr={stderr_len}å­—ç¬¦"
        elif tool_name == "list_dir":
            items = payload.get("items", [])
            count = len(items)
            return f"æˆåŠŸ: {count} é¡¹"
        elif tool_name == "glob_file_search":
            matches = payload.get("matches", [])
            count = len(matches)
            return f"æˆåŠŸ: æ‰¾åˆ° {count} ä¸ªæ–‡ä»¶"
        elif tool_name == "search_semantic":
            hits = payload.get("hits", [])
            count = len(hits)
            return f"æˆåŠŸ: {count} ä¸ªè¯­ä¹‰åŒ¹é…"
        else:
            # é€šç”¨ï¼šæ˜¾ç¤º payload çš„é”®
            keys = list(payload.keys())[:3]
            return f"æˆåŠŸ: {', '.join(keys)}{'...' if len(payload) > 3 else ''}"

    def _dispatch_tool(self, name: str, args: dict[str, Any]) -> ToolResult:
        """
        æ ¹æ®å·¥å…·åç§°åˆ†å‘åˆ°å¯¹åº”çš„å·¥å…·æ‰§è¡Œå‡½æ•°ã€‚
        
        æ”¯æŒçš„å·¥å…·ï¼š
        - list_dir: åˆ—å‡ºç›®å½•å†…å®¹
        - read_file: è¯»å–æ–‡ä»¶ï¼ˆæ”¯æŒ offset/limitï¼‰
        - glob_file_search: æŒ‰æ¨¡å¼æœç´¢æ–‡ä»¶
        - grep: æ–‡æœ¬æœç´¢ï¼ˆä¼˜å…ˆ ripgrepï¼Œé™çº§ Pythonï¼‰
        - apply_patch: åº”ç”¨ä»£ç è¡¥ä¸ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰
        - undo_patch: å›æ»šè¡¥ä¸ï¼ˆåŸºäº undo_idï¼‰
        - write_file: å†™å…¥æ–‡ä»¶
        - run_cmd: æ‰§è¡Œå‘½ä»¤
        - search_semantic: è¯­ä¹‰æœç´¢ï¼ˆå‘é‡ RAGï¼‰
        
        å‚æ•°:
            name: å·¥å…·åç§°
            args: å·¥å…·å‚æ•°å­—å…¸
        
        è¿”å›:
            ToolResult å¯¹è±¡ï¼ˆåŒ…å« ok/error/payloadï¼‰
        
        å¼‚å¸¸å¤„ç†:
            - KeyError: ç¼ºå°‘å¿…éœ€å‚æ•° â†’ è¿”å› E_INVALID_ARGS
            - å…¶ä»–å¼‚å¸¸: å·¥å…·æ‰§è¡Œå¤±è´¥ â†’ è¿”å› E_TOOL
        
        æµç¨‹å›¾: è§ `agent_loop_dispatch_tool_flow.svg`
        """
        try:
            if name == "list_dir":
                return self.tools.list_dir(path=args.get("path", "."))
            if name == "read_file":
                return self.tools.read_file(path=args["path"], offset=args.get("offset"), limit=args.get("limit"))
            if name == "glob_file_search":
                return self.tools.glob_file_search(glob_pattern=args["glob_pattern"], target_directory=args.get("target_directory", "."))
            if name == "grep":
                return self.tools.grep(
                    pattern=args["pattern"],
                    path=args.get("path", "."),
                    ignore_case=bool(args.get("ignore_case", False)),
                    max_hits=int(args.get("max_hits", 200)),
                )
            if name == "apply_patch":
                return self.tools.apply_patch(
                    path=args["path"],
                    old=args["old"],
                    new=args["new"],
                    expected_replacements=int(args.get("expected_replacements", 1)),
                    fuzzy=bool(args.get("fuzzy", False)),
                    min_similarity=float(args.get("min_similarity", 0.92)),
                )
            if name == "undo_patch":
                return self.tools.undo_patch(
                    undo_id=args["undo_id"],
                    force=bool(args.get("force", False)),
                )
            if name == "write_file":
                return self.tools.write_file(path=args["path"], text=args.get("text", ""))
            if name == "run_cmd":
                return self.tools.run_cmd(command=args["command"], cwd=args.get("cwd", "."))
            if name == "search_semantic":
                return self._semantic_search(query=args["query"])
            return ToolResult(False, error={"code": "E_NO_TOOL", "message": f"unknown tool: {name}"})
        except KeyError as e:
            return ToolResult(False, error={"code": "E_INVALID_ARGS", "message": f"missing arg: {e}"})
        except Exception as e:
            return ToolResult(False, error={"code": "E_TOOL", "message": str(e)})

    def _semantic_search(self, query: str) -> ToolResult:
        """
        æ‰§è¡Œè¯­ä¹‰æœç´¢ï¼ˆå‘é‡ RAGï¼‰ã€‚
        
        æµç¨‹ï¼š
        1. ä½¿ç”¨ CodeEmbedder å°†æŸ¥è¯¢æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
        2. åœ¨ VectorStoreï¼ˆLanceDBï¼‰ä¸­æœç´¢æœ€ç›¸ä¼¼çš„ä»£ç å—ï¼ˆtop 5ï¼‰
        3. å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸º ToolResult
        
        å‚æ•°:
            query: æœç´¢æŸ¥è¯¢æ–‡æœ¬ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
        
        è¿”å›:
            ToolResult å¯¹è±¡ï¼Œpayload åŒ…å«ï¼š
            - query: åŸå§‹æŸ¥è¯¢
            - hits: æœç´¢ç»“æœåˆ—è¡¨ï¼ˆæ¯ä¸ªåŒ…å« path/start_line/end_line/textï¼‰
        
        å¼‚å¸¸å¤„ç†:
            ä»»ä½•å¼‚å¸¸éƒ½ä¼šè¿”å› E_SEMANTIC_SEARCH é”™è¯¯
        
        æµç¨‹å›¾: è§ `agent_loop_semantic_search_flow.svg`
        """
        try:
            self.logger.debug(f"[dim]æ‰§è¡Œè¯­ä¹‰æœç´¢: {query[:50]}...[/dim]")
            q_vector = self.embedder.embed_query(query)
            hits = self.vector_store.search(q_vector, limit=5)
            self.logger.info(f"[green]âœ“ è¯­ä¹‰æœç´¢æ‰¾åˆ° {len(hits)} ä¸ªç»“æœ[/green]")
            
            payload_hits = []
            for h in hits:
                payload_hits.append({
                    "path": h.get("path"),
                    "start_line": h.get("start_line"),
                    "end_line": h.get("end_line"),
                    "text": h.get("text")
                })
            
            return ToolResult(True, payload={"query": query, "hits": payload_hits})
        except Exception as e:
            self.logger.error(f"[red]âœ— è¯­ä¹‰æœç´¢å¤±è´¥: {e}[/red]")
            return ToolResult(False, error={"code": "E_SEMANTIC_SEARCH", "message": str(e)})


