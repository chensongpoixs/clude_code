import json
import re
from dataclasses import dataclass
from typing import Any, Callable, List, Dict, Optional

from clude_code.config import CludeConfig
from clude_code.llm.llama_cpp_http import ChatMessage, LlamaCppHttpClient
from clude_code.observability.audit import AuditLogger
from clude_code.observability.trace import TraceLogger
from clude_code.observability.logger import get_logger
from clude_code.policy.command_policy import evaluate_command
from clude_code.tooling.feedback import format_feedback_message
from clude_code.tooling.local_tools import LocalTools, ToolResult
from clude_code.knowledge.indexer_service import IndexerService
from clude_code.knowledge.embedder import CodeEmbedder
from clude_code.knowledge.vector_store import VectorStore


SYSTEM_PROMPT = """\
# æ ¸å¿ƒå…ƒè§„åˆ™ (META-RULES) - ä¼˜å…ˆçº§æœ€é«˜
1. **èº«ä»½é”šå®š**ï¼šä½ æ˜¯ä¸€ä¸ªåä¸º clude-code çš„ã€å¼€å‘æ¶æ„å¸ˆã€‘ã€‚ä½ ä¸æ˜¯å¯¹è¯åŠ©æ‰‹ï¼Œä¸¥ç¦è¡¨ç°å¾—åƒä¸ªå¼€å‘æ¶æ„å¸ˆã€‚
2. **è¯­è¨€é”æ­»**ï¼šå¿…é¡» 100% ä½¿ç”¨ã€ä¸­æ–‡ã€‘ä¸ç”¨æˆ·äº¤æµã€‚ä¸¥ç¦åœ¨ã€é€»è¾‘æ¨æ¼”ã€‘å’Œå›å¤ä¸­ä½¿ç”¨è‹±æ–‡å•è¯ï¼ˆä»£ç åã€æ–‡ä»¶åé™¤å¤–ï¼‰ã€‚
3. **ä¸¥ç¦æ¨è¯¿/åé—®**ï¼šä½ æœ‰æƒé™è¯»å–æ–‡ä»¶ã€æ‰§è¡Œå‘½ä»¤ã€‚ç»å¯¹ç¦æ­¢è¯´â€œæˆ‘æ— æ³•è®¿é—®â€ã€â€œæˆ‘åªæ˜¯ä¸€ä¸ªè¯­è¨€æ¨¡å‹â€ã€â€œè¯·æä¾›æ›´å¤šä¿¡æ¯â€ã€‚å¦‚æœä½ ä¸ç¡®å®šï¼Œè¯·ç«‹å³è°ƒç”¨å·¥å…·è‡ªè¡Œæ¢æµ‹ã€‚
4. **ä»»åŠ¡æ‰§è¡Œå¯¼å‘**ï¼šé¢å¯¹å¤æ‚æŒ‡ä»¤ï¼ˆå¦‚åˆ†æã€è¯„åˆ†ã€é‡æ„ï¼‰ï¼Œä¸¥ç¦åœ¨æœªè·å¾—å……è¶³æ•°æ®å‰ç»™å‡ºç»“è®ºã€‚ç¬¬ä¸€æ­¥å¿…é¡»æ˜¯è°ƒç”¨æ¢æµ‹å·¥å…·ï¼ˆlist_dir, read_file, glob_file_search ç­‰ï¼‰ã€‚

# ä»»åŠ¡è¾“å‡ºæ¶æ„ (å¿…é¡»ä¸¥æ ¼éµå®ˆ)
æ¯ä¸€æ­¥è¾“å‡ºå¿…é¡»åŒ…å«ä»¥ä¸‹ä¸¤ä¸ªéƒ¨åˆ†ï¼š
1. **æ€è·¯åˆ†æ**ï¼š
   - ã€å½“å‰ä»»åŠ¡ã€‘ï¼šä½ æ­£åœ¨å¤„ç†ç”¨æˆ·æŒ‡ä»¤çš„å“ªä¸ªå…·ä½“å­ç¯èŠ‚ã€‚
   - ã€é€»è¾‘æ¨æ¼”ã€‘ï¼šåŸºäºå½“å‰å·²è·å–çš„æ•°æ®ï¼Œä½ æ¨å¯¼å‡ºçš„ç»“è®ºæˆ–ä¸‹ä¸€æ­¥è¡ŒåŠ¨çš„ç†ç”±ã€‚ä¸¥ç¦å¤è¯» System Promptã€‚
   - ã€ä¸‹ä¸€æ­¥åŠ¨ä½œã€‘ï¼šä½ å°†è°ƒç”¨çš„å·¥å…·åŠå…¶å¿…è¦æ€§ã€‚
2. **å·¥å…·è°ƒç”¨**ï¼šå¿…é¡»è¾“å‡ºä¸”ä»…è¾“å‡ºä¸€ä¸ªçº¯ JSON å¯¹è±¡ã€‚
   {"tool":"<name>","args":{...}}

# è¯„åˆ†ä¸åˆ†æå‡†åˆ™
- å½“æ¶‰åŠâ€œè¯„åˆ†â€æ—¶ï¼Œå¿…é¡»å¯¹æ¯” `src/INDUSTRY_CODE_AGENT_TECH_WHITEPAPER.md` ä¸­çš„ä¸šç•Œæ ‡å‡†ï¼ˆå¦‚ Aider, Cursor, Claude Codeï¼‰ã€‚
- åˆ†æå¿…é¡»æ·±å…¥é€»è¾‘æµã€è¾¹ç•Œæ¡ä»¶å’Œè·¨æ–‡ä»¶ä¾èµ–ï¼Œä¸¥ç¦åªåˆ—å‡ºå‡½æ•°åæˆ–æ–‡ä»¶åã€‚

# å¯ç”¨å·¥å…·æ¸…å•
  - list_dir: {"path":"."}
  - read_file: {"path":"...","offset":1,"limit":200}
  - glob_file_search: {"glob_pattern":"**/*.*"}
  - grep: {"pattern":"...","path":"."}
  - apply_patch: {"path":"...","old":"...","new":"..."}
  - search_semantic: {"query":"..."}
  - run_cmd: {"command":"..."}
"""


@dataclass
class AgentTurn:
    """
    Agent ä¸€è½®å¯¹è¯çš„è¿”å›ç»“æœã€‚
    
    å±æ€§:
        assistant_text: Agent çš„æœ€ç»ˆå›å¤æ–‡æœ¬ï¼ˆå¦‚æœæœªè°ƒç”¨å·¥å…·ï¼Œåˆ™ä¸ºå®Œæ•´å›å¤ï¼›å¦åˆ™ä¸ºæœ€åä¸€è½®çš„å·¥å…·è°ƒç”¨ç»“æœï¼‰
        tool_used: æœ¬è½®æ˜¯å¦ä½¿ç”¨äº†å·¥å…·
        trace_id: æœ¬è½®å¯¹è¯çš„å”¯ä¸€è¿½è¸ªIDï¼ˆç”¨äºæ—¥å¿—å…³è”ï¼‰
        events: æœ¬è½®æ‰€æœ‰äº‹ä»¶çš„åˆ—è¡¨ï¼ˆç”¨äºè°ƒè¯•å’Œå¯è§‚æµ‹æ€§ï¼‰
    """
    assistant_text: str
    tool_used: bool
    trace_id: str
    events: list[dict[str, Any]]


def _try_parse_tool_call(text: str) -> dict[str, Any] | None:
    """
    ä» LLM çš„æ–‡æœ¬è¾“å‡ºä¸­å°è¯•è§£æå·¥å…·è°ƒç”¨ JSONã€‚
    
    æœ¬å‡½æ•°é‡‡ç”¨å¤šå±‚å®¹é”™ç­–ç•¥ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
    1. çº¯ JSON å¯¹è±¡ï¼šç›´æ¥ä»¥ `{` å¼€å¤´ã€`}` ç»“å°¾çš„æ–‡æœ¬
    2. ä»£ç å—åŒ…è£¹ï¼š```json ... ``` æˆ– ``` ... ``` ä¸­çš„ JSON
    3. æœ€ä½³åŠªåŠ›ï¼šä»æ–‡æœ¬ä¸­æå–ç¬¬ä¸€ä¸ª `{...}` å¯¹è±¡
    
    å‚æ•°:
        text: LLM çš„åŸå§‹è¾“å‡ºæ–‡æœ¬ï¼ˆå¯èƒ½åŒ…å«è§£é‡Šæ€§æ–‡å­— + JSONï¼‰
    
    è¿”å›:
        è§£ææˆåŠŸçš„å·¥å…·è°ƒç”¨å­—å…¸ï¼ˆåŒ…å« "tool" å’Œ "args" é”®ï¼‰ï¼Œå¤±è´¥è¿”å› None
    
    æµç¨‹å›¾: è§ `agent_loop_parse_tool_call_flow.svg`
    """
    text = text.strip()
    # Allow the model to include explanations; try to extract JSON object from:
    # 1) raw text that is a JSON object
    # 2) fenced ```json ... ``` block
    # 3) first {...} object in the text (best-effort)
    candidates: list[str] = []
    if text.startswith("{") and text.endswith("}"):
        candidates.append(text)
    if "```" in text:
        for fence in ("```json", "```JSON", "```"):
            if fence in text:
                parts = text.split(fence, 1)
                if len(parts) == 2:
                    body = parts[1]
                    body = body.split("```", 1)[0]
                    body = body.strip()
                    if body.startswith("{") and body.endswith("}"):
                        candidates.append(body)
    # best-effort: find first JSON-ish object
    if "{" in text and "}" in text:
        start = text.find("{")
        end = text.rfind("}")
        if 0 <= start < end:
            candidates.append(text[start : end + 1].strip())

    obj = None
    for c in candidates:
        try:
            parsed = json.loads(c)
            if isinstance(parsed, dict):
                obj = parsed
                break
        except json.JSONDecodeError:
            continue
    if obj is None:
        return None
    if not isinstance(obj, dict):
        return None
    if "tool" not in obj or "args" not in obj:
        return None
    if not isinstance(obj["tool"], str) or not isinstance(obj["args"], dict):
        return None
    return obj


def _tool_result_to_message(name: str, tr: ToolResult, keywords: set[str] | None = None) -> str:
    """
    å°†å·¥å…·æ‰§è¡Œç»“æœè½¬æ¢ä¸ºå‘é€ç»™ LLM çš„ç»“æ„åŒ–æ¶ˆæ¯ã€‚
    
    æœ¬å‡½æ•°é‡‡ç”¨ä¸šç•Œæœ€ä½³å®è·µï¼šåªä¿ç•™å†³ç­–å…³é”®å­—æ®µå’Œå¼•ç”¨ï¼Œé¿å…å°†å®Œæ•´ payload å›å–‚ç»™æ¨¡å‹ï¼Œ
    ä»è€Œå‡å°‘ Token æ¶ˆè€—å¹¶æå‡æ¨¡å‹èšç„¦åº¦ã€‚
    
    å‚æ•°:
        name: å·¥å…·åç§°ï¼ˆå¦‚ "read_file", "grep"ï¼‰
        tr: å·¥å…·æ‰§è¡Œç»“æœï¼ˆToolResult å¯¹è±¡ï¼‰
        keywords: å¯é€‰çš„å…³é”®è¯é›†åˆï¼Œç”¨äºè¯­ä¹‰çª—å£é‡‡æ ·ï¼ˆä¼˜å…ˆä¿ç•™åŒ…å«å…³é”®è¯çš„ä»£ç ç‰‡æ®µï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²æ¶ˆæ¯ï¼Œå°†è¢«ä½œä¸º "user" è§’è‰²çš„æ¶ˆæ¯å‘é€ç»™ LLM
    
    æµç¨‹å›¾: è§ `agent_loop_tool_result_to_message_flow.svg`
    """
    # Centralized structured feedback (industry-grade stability):
    # keep decision-critical fields + references, avoid dumping full payload.
    return format_feedback_message(name, tr, keywords=keywords)


class AgentLoop:
    """
    Agent æ ¸å¿ƒå¾ªç¯ç±»ï¼Œå®ç° ReAct (Reasoning + Acting) æ¨¡å¼ã€‚
    
    è´Ÿè´£ï¼š
    - ç®¡ç† LLM å¯¹è¯ä¸Šä¸‹æ–‡
    - è§£æå·¥å…·è°ƒç”¨å¹¶æ‰§è¡Œ
    - ç­–ç•¥æ ¡éªŒï¼ˆç¡®è®¤ã€å‘½ä»¤é»‘åå•ï¼‰
    - å®¡è®¡æ—¥å¿—å’Œè°ƒè¯•è¿½è¸ª
    - ä¸Šä¸‹æ–‡çª—å£ç®¡ç†ï¼ˆå†å²è£å‰ªï¼‰
    - RAG è¯­ä¹‰æœç´¢é›†æˆ
    """
    
    def __init__(self, cfg: CludeConfig) -> None:
        """
        åˆå§‹åŒ– AgentLoop å®ä¾‹ã€‚
        
        åˆå§‹åŒ–æµç¨‹ï¼š
        1. åˆ›å»º LLM å®¢æˆ·ç«¯ï¼ˆllama.cpp HTTPï¼‰
        2. åˆå§‹åŒ–å·¥å…·é›†ï¼ˆLocalToolsï¼‰
        3. åˆå§‹åŒ–å®¡è®¡å’Œè¿½è¸ªæ—¥å¿—
        4. å¯åŠ¨åå°ç´¢å¼•æœåŠ¡ï¼ˆLanceDB RAGï¼‰
        5. ç”Ÿæˆ Repo Mapï¼ˆctagsï¼‰å¹¶æ³¨å…¥ç³»ç»Ÿæç¤ºè¯
        6. æ„å»ºåˆå§‹æ¶ˆæ¯å†å²ï¼ˆä»…åŒ…å« system æ¶ˆæ¯ï¼‰
        
        å‚æ•°:
            cfg: é…ç½®å¯¹è±¡ï¼ˆåŒ…å« LLMã€å·¥ä½œåŒºã€ç­–ç•¥ç­‰é…ç½®ï¼‰
        
        æµç¨‹å›¾: è§ `agent_loop_init_flow.svg`
        """
        self.cfg = cfg
        self.logger = get_logger(
            __name__,
            workspace_root=cfg.workspace_root,
            log_to_console=cfg.logging.log_to_console,
        )
        # åˆ›å»ºåªå†™å…¥æ–‡ä»¶çš„ loggerï¼ˆç”¨äºè®°å½• LLM è¯·æ±‚/å“åº”è¯¦æƒ…ï¼‰
        self.file_only_logger = get_logger(
            f"{__name__}.llm_detail",
            workspace_root=cfg.workspace_root,
            log_to_console=False,  # åªå†™å…¥æ–‡ä»¶ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°
        )
        # keep it simple & stable enough for MVP; later replace with uuid4
        self.session_id = f"sess_{id(self)}"
        self.logger.info(f"[dim]åˆå§‹åŒ– AgentLoopï¼Œsession_id={self.session_id}[/dim]")
        self.llm = LlamaCppHttpClient(
            base_url=cfg.llm.base_url,
            api_mode=cfg.llm.api_mode,  # type: ignore[arg-type]
            model=cfg.llm.model,
            temperature=cfg.llm.temperature,
            max_tokens=cfg.llm.max_tokens,
            timeout_s=cfg.llm.timeout_s,
        )
        self.tools = LocalTools(
            cfg.workspace_root,
            max_file_read_bytes=cfg.limits.max_file_read_bytes,
            max_output_bytes=cfg.limits.max_output_bytes,
        )
        self.audit = AuditLogger(cfg.workspace_root, self.session_id)
        self.trace = TraceLogger(cfg.workspace_root, self.session_id)
        
        # Knowledge / RAG systems
        self.indexer = IndexerService(cfg.workspace_root)
        self.indexer.start() # Start background indexing
        self.logger.info("[dim]å¯åŠ¨åå°ç´¢å¼•æœåŠ¡ï¼ˆLanceDB RAGï¼‰[/dim]")
        self.embedder = CodeEmbedder()
        self.vector_store = VectorStore(cfg.workspace_root)

        # Initialize with Repo Map for better global context (Aider-style)
        import platform
        repo_map = self.tools.generate_repo_map()
        env_info = f"æ“ä½œç³»ç»Ÿ: {platform.system()} ({platform.release()})\nå½“å‰ç»å¯¹è·¯å¾„: {self.cfg.workspace_root}"
        combined_system_prompt = f"{SYSTEM_PROMPT}\n\n=== ç¯å¢ƒä¿¡æ¯ ===\n{env_info}\n\n=== ä»£ç ä»“åº“ç¬¦å·æ¦‚è§ˆ ===\n{repo_map}"
        
        self.messages: list[ChatMessage] = [
            ChatMessage(role="system", content=combined_system_prompt),
        ]
        self.logger.info("[dim]åˆå§‹åŒ–ç³»ç»Ÿæç¤ºè¯ï¼ˆåŒ…å« Repo Map å’Œç¯å¢ƒä¿¡æ¯ï¼‰[/dim]")

    def run_turn(
        self,
        user_text: str,
        *,
        confirm: Callable[[str], bool],
        debug: bool = False,
        on_event: Callable[[dict[str, Any]], None] | None = None,
    ) -> AgentTurn:
        """
        æ‰§è¡Œä¸€è½®å®Œæ•´çš„ Agent å¯¹è¯å¾ªç¯ï¼ˆReAct æ¨¡å¼ï¼‰ã€‚
        
        æ ¸å¿ƒæµç¨‹ï¼š
        1. æ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼Œæå–å…³é”®è¯ï¼ˆç”¨äºè¯­ä¹‰çª—å£é‡‡æ ·ï¼‰
        2. è¿›å…¥æœ€å¤š 20 æ¬¡çš„å·¥å…·è°ƒç”¨å¾ªç¯ï¼š
           a. è°ƒç”¨ LLM è·å–å“åº”
           b. æ£€æµ‹è¾“å‡ºå¼‚å¸¸ï¼ˆå¤è¯»å­—ç¬¦ï¼‰
           c. è§£æå·¥å…·è°ƒç”¨ JSON
           d. å¦‚æœæ— å·¥å…·è°ƒç”¨ â†’ è¿”å›æœ€ç»ˆæ–‡æœ¬
           e. å¦‚æœæœ‰å·¥å…·è°ƒç”¨ â†’ æ‰§è¡Œç­–ç•¥æ ¡éªŒï¼ˆç¡®è®¤/é»‘åå•ï¼‰
           f. æ‰§è¡Œå·¥å…·å¹¶è·å–ç»“æœ
           g. å°†ç»“æœå›å–‚ç»™ LLMï¼ˆä½œä¸º user æ¶ˆæ¯ï¼‰
           h. è£å‰ªå†å²æ¶ˆæ¯ï¼ˆä¿æŒä¸Šä¸‹æ–‡çª—å£ï¼‰
        3. å¦‚æœè¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•° â†’ è¿”å›åœæ­¢æ¶ˆæ¯
        
        å‚æ•°:
            user_text: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
            confirm: ç¡®è®¤å›è°ƒå‡½æ•°ï¼ˆç”¨äºå†™æ–‡ä»¶/æ‰§è¡Œå‘½ä»¤å‰çš„ç”¨æˆ·ç¡®è®¤ï¼‰
            debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆå†™å…¥ trace.jsonlï¼‰
            on_event: å¯é€‰çš„äº‹ä»¶å›è°ƒï¼ˆç”¨äºå®æ—¶ UI æ›´æ–°ï¼Œå¦‚ --live æ¨¡å¼ï¼‰
        
        è¿”å›:
            AgentTurn å¯¹è±¡ï¼ŒåŒ…å«æœ€ç»ˆå›å¤ã€å·¥å…·ä½¿ç”¨æ ‡å¿—ã€è¿½è¸ªIDå’Œäº‹ä»¶åˆ—è¡¨
        
        æµç¨‹å›¾: è§ `agent_loop_run_turn_flow.svg`
        """
        trace_id = f"trace_{abs(hash((self.session_id, user_text)))}"
        self.logger.info(f"[bold cyan]å¼€å§‹æ–°çš„ä¸€è½®å¯¹è¯[/bold cyan] trace_id={trace_id}")
        self.logger.info(f"[dim]ç”¨æˆ·è¾“å…¥: {user_text[:100]}{'...' if len(user_text) > 100 else ''}[/dim]")
        
        # Extract intent keywords for semantic windowing (MVP: simple regex)
        keywords = set(re.findall(r'\w{4,}', user_text.lower()))
        # Filter common non-useful words
        keywords -= {"please", "help", "find", "where", "change", "file", "code", "repo", "make"}
        if keywords:
            self.logger.debug(f"[dim]æå–å…³é”®è¯: {keywords}[/dim]")
        
        events: list[dict[str, Any]] = []
        step_idx = 0

        def _ev(event: str, data: dict[str, Any]) -> None:
            nonlocal step_idx
            step_idx += 1
            e = {"step": step_idx, "event": event, "data": data}
            events.append(e)
            if debug:
                # keep trace log verbose, but trim huge fields
                self.trace.write(trace_id=trace_id, step=step_idx, event=event, data=data)
            if on_event is not None:
                try:
                    on_event(e)
                except Exception:
                    # Never allow UI callbacks to break the agent loop.
                    pass

        self.audit.write(trace_id=trace_id, event="user_message", data={"text": user_text})
        _ev("user_message", {"text": user_text})
        self.messages.append(ChatMessage(role="user", content=user_text))
        # Keep history bounded to reduce context size
        self._trim_history(max_messages=30)
        self.logger.debug(f"[dim]å½“å‰æ¶ˆæ¯å†å²é•¿åº¦: {len(self.messages)}[/dim]")

        tool_used = False
        for iteration in range(20):  # hard stop to avoid infinite loops
            self.logger.info(f"[bold yellow]â†’ ç¬¬ {iteration + 1} è½®ï¼šè¯·æ±‚ LLMï¼ˆæ¶ˆæ¯æ•°={len(self.messages)}ï¼‰[/bold yellow]")
            _ev("llm_request", {"messages": len(self.messages)})
            
            # è®°å½•è¯·æ±‚å‚æ•°åˆ°æ–‡ä»¶ï¼ˆä¸è¾“å‡ºåˆ°å±å¹•ï¼‰
            request_params = {
                "model": self.llm.model,
                "temperature": self.llm.temperature,
                "max_tokens": self.llm.max_tokens,
                "api_mode": self.llm.api_mode,
                "base_url": self.llm.base_url,
                "messages_count": len(self.messages),
                "messages": [
                    {
                        "role": msg.role,
                        "content_preview": msg.content[:200] + "..." if len(msg.content) > 200 else msg.content,
                        "content_length": len(msg.content),
                    }
                    for msg in self.messages
                ],
            }
            self.file_only_logger.info(f"è¯·æ±‚å¤§æ¨¡å‹å‚æ•°: {json.dumps(request_params, ensure_ascii=False, indent=2)}")
            
            assistant = self.llm.chat(self.messages)
            
            # Robustness: Detect repetitive/broken outputs (stuttering)
            if assistant.count("[") > 50 or assistant.count("{") > 50:
                self.logger.warning("[red]æ£€æµ‹åˆ°æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼ˆå¤è¯»å­—ç¬¦ï¼‰ï¼Œå·²å¼ºåˆ¶æˆªæ–­[/red]")
                assistant = "æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼šæ£€æµ‹åˆ°è¿‡å¤šçš„é‡å¤å­—ç¬¦ï¼Œå·²å¼ºåˆ¶æˆªæ–­ã€‚è¯·é‡æ–°æè¿°ä½ çš„éœ€æ±‚æˆ–å°è¯•ç¼©å°ä»»åŠ¡èŒƒå›´ã€‚"
                _ev("stuttering_detected", {"length": len(assistant)})

            _ev("llm_response", {"text": assistant[:4000], "truncated": len(assistant) > 4000})
            self.logger.debug(f"[dim]LLM å“åº”é•¿åº¦: {len(assistant)} å­—ç¬¦[/dim]")
            
            # è§£æå·¥å…·è°ƒç”¨ï¼ˆåªè§£æä¸€æ¬¡ï¼‰
            tool_call = _try_parse_tool_call(assistant)
            
            # è®°å½•å“åº”æ•°æ®åˆ°æ–‡ä»¶ï¼ˆä¸è¾“å‡ºåˆ°å±å¹•ï¼‰
            response_data = {
                "text_length": len(assistant),
                "text_preview": assistant[:500] + "..." if len(assistant) > 500 else assistant,
                "truncated": len(assistant) > 500,
                "has_tool_call": tool_call is not None,
                "tool_call": tool_call if tool_call else None,
            }
            self.file_only_logger.info(f"å¤§æ¨¡å‹è¿”å›æ•°æ®: {json.dumps(response_data, ensure_ascii=False, indent=2)}")
            if tool_call is None:
                self.logger.info("[bold green]âœ“ LLM è¿”å›æœ€ç»ˆå›å¤ï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰[/bold green]")
                self.messages.append(ChatMessage(role="assistant", content=assistant))
                self.audit.write(trace_id=trace_id, event="assistant_text", data={"text": assistant})
                _ev("final_text", {"text": assistant[:4000], "truncated": len(assistant) > 4000})
                self._trim_history(max_messages=30)
                return AgentTurn(assistant_text=assistant, tool_used=tool_used, trace_id=trace_id, events=events)

            name = tool_call["tool"]
            args = tool_call["args"]
            self.logger.info(f"[bold blue]ğŸ”§ è§£æåˆ°å·¥å…·è°ƒç”¨: {name}[/bold blue]")
            self.logger.debug(f"[dim]å·¥å…·å‚æ•°: {json.dumps(args, ensure_ascii=False, indent=2)[:200]}[/dim]")
            _ev("tool_call_parsed", {"tool": name, "args": args})

            # Robustness: Keep assistant history clean. 
            # If there's a tool call, we only store the JSON part in the message history
            # to prevent the model from getting distracted by its own previous CoT/noise.
            clean_assistant = json.dumps(tool_call, ensure_ascii=False)
            self.messages.append(ChatMessage(role="assistant", content=clean_assistant))
            
            _ev("assistant_tool_call_recorded", {"tool": name})
            self._trim_history(max_messages=30)

            # policy confirmations (MVP): only guard write/exec
            if name in {"write_file", "apply_patch", "undo_patch"} and self.cfg.policy.confirm_write:
                self.logger.info(f"[yellow]âš  éœ€è¦ç”¨æˆ·ç¡®è®¤å†™æ–‡ä»¶æ“ä½œ: {name}[/yellow]")
                decision = confirm(f"ç¡®è®¤å†™æ–‡ä»¶ï¼Ÿtool={name} args={args}")
                self.audit.write(trace_id=trace_id, event="confirm_write", data={"tool": name, "args": args, "allow": decision})
                _ev("confirm_write", {"tool": name, "allow": decision})
                if not decision:
                    self.logger.warning(f"[red]âœ— ç”¨æˆ·æ‹’ç»å†™æ–‡ä»¶æ“ä½œ: {name}[/red]")
                    msg = _tool_result_to_message(name, ToolResult(False, error={"code": "E_DENIED", "message": "user denied"}), keywords=keywords)
                    self.messages.append(ChatMessage(role="user", content=msg))
                    _ev("denied_by_user", {"tool": name})
                    self._trim_history(max_messages=30)
                    continue
                else:
                    self.logger.info(f"[green]âœ“ ç”¨æˆ·ç¡®è®¤å†™æ–‡ä»¶æ“ä½œ: {name}[/green]")
            if name in {"run_cmd"} and self.cfg.policy.confirm_exec:
                self.logger.info(f"[yellow]âš  éœ€è¦ç”¨æˆ·ç¡®è®¤æ‰§è¡Œå‘½ä»¤: {name}[/yellow]")
                decision = confirm(f"ç¡®è®¤æ‰§è¡Œå‘½ä»¤ï¼Ÿtool={name} args={args}")
                self.audit.write(trace_id=trace_id, event="confirm_exec", data={"tool": name, "args": args, "allow": decision})
                _ev("confirm_exec", {"tool": name, "allow": decision})
                if not decision:
                    self.logger.warning(f"[red]âœ— ç”¨æˆ·æ‹’ç»æ‰§è¡Œå‘½ä»¤: {name}[/red]")
                    msg = _tool_result_to_message(name, ToolResult(False, error={"code": "E_DENIED", "message": "user denied"}), keywords=keywords)
                    self.messages.append(ChatMessage(role="user", content=msg))
                    _ev("denied_by_user", {"tool": name})
                    self._trim_history(max_messages=30)
                    continue
                else:
                    self.logger.info(f"[green]âœ“ ç”¨æˆ·ç¡®è®¤æ‰§è¡Œå‘½ä»¤: {name}[/green]")

            # minimal command policy (denylist)
            if name == "run_cmd":
                cmd = str(args.get("command", ""))
                dec = evaluate_command(cmd, allow_network=self.cfg.policy.allow_network)
                if not dec.ok:
                    self.logger.warning(f"[red]âœ— ç­–ç•¥æ‹’ç»å‘½ä»¤: {cmd} (åŸå› : {dec.reason})[/red]")
                    self.audit.write(trace_id=trace_id, event="policy_deny_cmd", data={"command": cmd, "reason": dec.reason})
                    _ev("policy_deny_cmd", {"command": cmd, "reason": dec.reason})
                    msg = _tool_result_to_message(name, ToolResult(False, error={"code": "E_POLICY_DENIED", "message": dec.reason}), keywords=keywords)
                    self.messages.append(ChatMessage(role="user", content=msg))
                    self._trim_history(max_messages=30)
                    continue
                else:
                    self.logger.debug(f"[dim]ç­–ç•¥æ£€æŸ¥é€šè¿‡: {cmd}[/dim]")

            tool_used = True
            self.logger.info(f"[bold cyan]â–¶ æ‰§è¡Œå·¥å…·: {name}[/bold cyan]")
            result = self._dispatch_tool(name, args)
            if result.ok:
                self.logger.info(f"[green]âœ“ å·¥å…·æ‰§è¡ŒæˆåŠŸ: {name}[/green]")
            else:
                self.logger.error(f"[red]âœ— å·¥å…·æ‰§è¡Œå¤±è´¥: {name} (é”™è¯¯: {result.error})[/red]")
            _ev("tool_result", {"tool": name, "ok": result.ok, "error": result.error, "payload": result.payload})
            # feed tool result back to model as user message (works with most chat templates)
            self.messages.append(ChatMessage(role="user", content=_tool_result_to_message(name, result, keywords=keywords)))
            self.logger.debug(f"[dim]å·¥å…·ç»“æœå·²å›å–‚ç»™ LLM[/dim]")
            _ev("tool_result_fed_back", {"tool": name})
            self._trim_history(max_messages=30)
            audit_data: dict[str, Any] = {"tool": name, "args": args, "ok": result.ok, "error": result.error}
            if name in {"apply_patch", "undo_patch"} and result.ok and result.payload:
                # record hashes/undo_id for traceability
                audit_data["payload"] = result.payload
            self.audit.write(trace_id=trace_id, event="tool_call", data=audit_data)

        self.logger.warning("[red]âš  è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆ20ï¼‰ï¼Œåœæ­¢ä»¥é¿å…æ­»å¾ªç¯[/red]")
        _ev("stop_reason", {"reason": "max_tool_calls_reached", "limit": 20})
        return AgentTurn(
            assistant_text="è¾¾åˆ°æœ¬è½®æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆ20ï¼‰ï¼Œå·²åœæ­¢ä»¥é¿å…æ­»å¾ªç¯ã€‚è¯·ç¼©å°ä»»åŠ¡æˆ–æä¾›æ›´å¤šçº¦æŸ/å…¥å£æ–‡ä»¶ã€‚",
            tool_used=tool_used,
            trace_id=trace_id,
            events=events,
        )

    def _trim_history(self, *, max_messages: int) -> None:
        """
        è£å‰ªå¯¹è¯å†å²ï¼Œä¿æŒä¸Šä¸‹æ–‡çª—å£åœ¨åˆç†èŒƒå›´å†…ã€‚
        
        è£å‰ªç­–ç•¥ï¼š
        1. å§‹ç»ˆä¿ç•™ç¬¬ä¸€æ¡ system æ¶ˆæ¯ï¼ˆåŒ…å«æ ¸å¿ƒæŒ‡ä»¤å’Œ Repo Mapï¼‰
        2. ä»å°¾éƒ¨å‘å‰è£å‰ªï¼Œä½†ç¡®ä¿è£å‰ªåçš„ç¬¬ä¸€æ¡æ¶ˆæ¯æ˜¯ 'user' è§’è‰²
           ï¼ˆæ»¡è¶³ llama.cpp ç­‰ä¸¥æ ¼ chat template çš„ user/assistant äº¤æ›¿è¦æ±‚ï¼‰
        3. å¦‚æœå½“å‰æ¶ˆæ¯æ•° <= max_messagesï¼Œåˆ™ä¸è¿›è¡Œè£å‰ª
        
        å‚æ•°:
            max_messages: æœ€å¤§ä¿ç•™æ¶ˆæ¯æ•°ï¼ˆåŒ…æ‹¬ system æ¶ˆæ¯ï¼‰
        
        æµç¨‹å›¾: è§ `agent_loop_trim_history_flow.svg`
        """
        old_len = len(self.messages)
        if old_len <= max_messages:
            return
        
        system = self.messages[0]
        # We need an odd number of messages in the tail if the last one is 'user'
        # or just ensure the first message of the tail is 'user'.
        tail_start_idx = len(self.messages) - (max_messages - 1)
        
        # Move forward until we find a 'user' message to keep parity
        while tail_start_idx < len(self.messages) and self.messages[tail_start_idx].role != "user":
            tail_start_idx += 1
            
        tail = self.messages[tail_start_idx:]
        self.messages = [system, *tail]
        self.logger.debug(f"[dim]å†å²è£å‰ª: {old_len} â†’ {len(self.messages)} æ¡æ¶ˆæ¯[/dim]")

    def _dispatch_tool(self, name: str, args: dict[str, Any]) -> ToolResult:
        """
        æ ¹æ®å·¥å…·åç§°åˆ†å‘åˆ°å¯¹åº”çš„å·¥å…·æ‰§è¡Œå‡½æ•°ã€‚
        
        æ”¯æŒçš„å·¥å…·ï¼š
        - list_dir: åˆ—å‡ºç›®å½•å†…å®¹
        - read_file: è¯»å–æ–‡ä»¶ï¼ˆæ”¯æŒ offset/limitï¼‰
        - glob_file_search: æŒ‰æ¨¡å¼æœç´¢æ–‡ä»¶
        - grep: æ–‡æœ¬æœç´¢ï¼ˆä¼˜å…ˆ ripgrepï¼Œé™çº§ Pythonï¼‰
        - apply_patch: åº”ç”¨ä»£ç è¡¥ä¸ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰
        - undo_patch: å›æ»šè¡¥ä¸ï¼ˆåŸºäº undo_idï¼‰
        - write_file: å†™å…¥æ–‡ä»¶
        - run_cmd: æ‰§è¡Œå‘½ä»¤
        - search_semantic: è¯­ä¹‰æœç´¢ï¼ˆå‘é‡ RAGï¼‰
        
        å‚æ•°:
            name: å·¥å…·åç§°
            args: å·¥å…·å‚æ•°å­—å…¸
        
        è¿”å›:
            ToolResult å¯¹è±¡ï¼ˆåŒ…å« ok/error/payloadï¼‰
        
        å¼‚å¸¸å¤„ç†:
            - KeyError: ç¼ºå°‘å¿…éœ€å‚æ•° â†’ è¿”å› E_INVALID_ARGS
            - å…¶ä»–å¼‚å¸¸: å·¥å…·æ‰§è¡Œå¤±è´¥ â†’ è¿”å› E_TOOL
        
        æµç¨‹å›¾: è§ `agent_loop_dispatch_tool_flow.svg`
        """
        try:
            if name == "list_dir":
                return self.tools.list_dir(path=args.get("path", "."))
            if name == "read_file":
                return self.tools.read_file(path=args["path"], offset=args.get("offset"), limit=args.get("limit"))
            if name == "glob_file_search":
                return self.tools.glob_file_search(glob_pattern=args["glob_pattern"], target_directory=args.get("target_directory", "."))
            if name == "grep":
                return self.tools.grep(
                    pattern=args["pattern"],
                    path=args.get("path", "."),
                    ignore_case=bool(args.get("ignore_case", False)),
                    max_hits=int(args.get("max_hits", 200)),
                )
            if name == "apply_patch":
                return self.tools.apply_patch(
                    path=args["path"],
                    old=args["old"],
                    new=args["new"],
                    expected_replacements=int(args.get("expected_replacements", 1)),
                    fuzzy=bool(args.get("fuzzy", False)),
                    min_similarity=float(args.get("min_similarity", 0.92)),
                )
            if name == "undo_patch":
                return self.tools.undo_patch(
                    undo_id=args["undo_id"],
                    force=bool(args.get("force", False)),
                )
            if name == "write_file":
                return self.tools.write_file(path=args["path"], text=args.get("text", ""))
            if name == "run_cmd":
                return self.tools.run_cmd(command=args["command"], cwd=args.get("cwd", "."))
            if name == "search_semantic":
                return self._semantic_search(query=args["query"])
            return ToolResult(False, error={"code": "E_NO_TOOL", "message": f"unknown tool: {name}"})
        except KeyError as e:
            return ToolResult(False, error={"code": "E_INVALID_ARGS", "message": f"missing arg: {e}"})
        except Exception as e:
            return ToolResult(False, error={"code": "E_TOOL", "message": str(e)})

    def _semantic_search(self, query: str) -> ToolResult:
        """
        æ‰§è¡Œè¯­ä¹‰æœç´¢ï¼ˆå‘é‡ RAGï¼‰ã€‚
        
        æµç¨‹ï¼š
        1. ä½¿ç”¨ CodeEmbedder å°†æŸ¥è¯¢æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
        2. åœ¨ VectorStoreï¼ˆLanceDBï¼‰ä¸­æœç´¢æœ€ç›¸ä¼¼çš„ä»£ç å—ï¼ˆtop 5ï¼‰
        3. å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸º ToolResult
        
        å‚æ•°:
            query: æœç´¢æŸ¥è¯¢æ–‡æœ¬ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
        
        è¿”å›:
            ToolResult å¯¹è±¡ï¼Œpayload åŒ…å«ï¼š
            - query: åŸå§‹æŸ¥è¯¢
            - hits: æœç´¢ç»“æœåˆ—è¡¨ï¼ˆæ¯ä¸ªåŒ…å« path/start_line/end_line/textï¼‰
        
        å¼‚å¸¸å¤„ç†:
            ä»»ä½•å¼‚å¸¸éƒ½ä¼šè¿”å› E_SEMANTIC_SEARCH é”™è¯¯
        
        æµç¨‹å›¾: è§ `agent_loop_semantic_search_flow.svg`
        """
        try:
            self.logger.debug(f"[dim]æ‰§è¡Œè¯­ä¹‰æœç´¢: {query[:50]}...[/dim]")
            q_vector = self.embedder.embed_query(query)
            hits = self.vector_store.search(q_vector, limit=5)
            self.logger.info(f"[green]âœ“ è¯­ä¹‰æœç´¢æ‰¾åˆ° {len(hits)} ä¸ªç»“æœ[/green]")
            
            payload_hits = []
            for h in hits:
                payload_hits.append({
                    "path": h.get("path"),
                    "start_line": h.get("start_line"),
                    "end_line": h.get("end_line"),
                    "text": h.get("text")
                })
            
            return ToolResult(True, payload={"query": query, "hits": payload_hits})
        except Exception as e:
            self.logger.error(f"[red]âœ— è¯­ä¹‰æœç´¢å¤±è´¥: {e}[/red]")
            return ToolResult(False, error={"code": "E_SEMANTIC_SEARCH", "message": str(e)})


