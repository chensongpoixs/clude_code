from __future__ import annotations

import json
from typing import Any, Callable, TYPE_CHECKING

from clude_code.llm.http_client import ChatMessage
from clude_code.orchestrator.planner import parse_plan_from_text, render_plan_markdown, Plan, PlanStep
from clude_code.orchestrator.state_m import AgentState
from clude_code.prompts import read_prompt

if TYPE_CHECKING:
    from .agent_loop import AgentLoop


def _try_convert_tool_call_to_plan(text: str, loop: "AgentLoop") -> Plan | None:
    """
    å°è¯•å°†å·¥å…·è°ƒç”¨ JSON è½¬æ¢ä¸º Planã€‚
    
    å½“ LLM è¯¯è¾“å‡ºå·¥å…·è°ƒç”¨æ ¼å¼æ—¶ï¼Œè‡ªåŠ¨è½¬æ¢ä¸ºå•æ­¥ Planã€‚
    
    æ£€æµ‹æ¨¡å¼:
    - {"tool": "xxx", "args": {...}}
    - {"tool": "xxx", "params": {...}}
    
    Args:
        text: LLM è¾“å‡ºçš„æ–‡æœ¬
        loop: AgentLoop å®ä¾‹
    
    Returns:
        Plan å¯¹è±¡æˆ– Noneï¼ˆæ— æ³•è½¬æ¢ï¼‰
    """
    try:
        # å°è¯•è§£æ JSON
        data = json.loads(text.strip())
        
        # å¿…é¡»æ˜¯å­—å…¸
        if not isinstance(data, dict):
            return None
        
        # å¿…é¡»æœ‰ tool å­—æ®µ
        tool_name = data.get("tool")
        if not tool_name or not isinstance(tool_name, str):
            return None
        
        # å¿…é¡»æœ‰ args æˆ– params å­—æ®µï¼ˆå·¥å…·è°ƒç”¨ç‰¹å¾ï¼‰
        if "args" not in data and "params" not in data:
            return None
        
        # ä¸èƒ½æœ‰ type å­—æ®µï¼ˆé¿å…è¯¯åˆ¤ Planï¼‰
        if "type" in data:
            return None
        
        # æ„å»ºå•æ­¥ Plan
        step = PlanStep(
            id="step_1",
            description=f"ä½¿ç”¨ {tool_name} å·¥å…·æ‰§è¡Œä»»åŠ¡",
            dependencies=[],
            tools_expected=[tool_name],
            status="pending"
        )
        
        plan = Plan(
            type="FullPlan",
            title=f"æ‰§è¡Œ {tool_name}",
            steps=[step]
        )
        
        loop.logger.info(
            f"[yellow]âš  æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨è¾“å‡ºï¼Œå·²è‡ªåŠ¨è½¬æ¢ä¸º Plan[/yellow]: "
            f"tool={tool_name}"
        )
        
        return plan
    except (json.JSONDecodeError, ValueError, KeyError, AttributeError):
        # æ— æ³•è§£ææˆ–è½¬æ¢ï¼Œè¿”å› None
        return None


def execute_planning_phase(
    loop: "AgentLoop",
    user_text: str,
    planning_prompt: str | None,
    trace_id: str,
    _ev: Callable[[str, dict[str, Any]], None],
    _llm_chat: Callable[[str, str | None], str],
) -> Plan | None:
    """æ‰§è¡Œè§„åˆ’é˜¶æ®µï¼šç”Ÿæˆæ˜¾å¼ Planã€‚"""
    if not planning_prompt:
        return None

    _ev("state", {"state": AgentState.PLANNING.value, "reason": "enable_planning"})
    loop.logger.info("[bold magenta]ğŸ§© è¿›å…¥è§„åˆ’é˜¶æ®µï¼šç”Ÿæˆæ˜¾å¼ Plan[/bold magenta]")

    plan_attempts = 0
    while plan_attempts <= loop.cfg.orchestrator.planning_retry:
        plan_attempts += 1
        _ev("planning_llm_request", {"attempt": plan_attempts})

        # è®°å½•è°ƒç”¨_llm_chatä¹‹å‰çš„æ¶ˆæ¯é•¿åº¦ï¼Œç”¨äºåç»­æ¸…ç†
        messages_before_llm = len(loop.messages)

        assistant_plan = _llm_chat("planning", None)
        _ev("planning_llm_response", {"text": assistant_plan[:4000], "truncated": len(assistant_plan) > 4000})

        try:
            parsed = parse_plan_from_text(assistant_plan)
            if len(parsed.steps) > loop.cfg.orchestrator.max_plan_steps:
                parsed.steps = parsed.steps[: loop.cfg.orchestrator.max_plan_steps]
            plan = parsed

            # å¼ºåˆ¶æ ¡éªŒæ­¥éª¤ ID å”¯ä¸€æ€§ï¼ˆparse_plan_from_text å·²æ ¡éªŒï¼Œè¿™é‡ŒåšåŒä¿é™©ï¼‰
            plan.validate_unique_ids()

            # åªæœ‰åœ¨æˆåŠŸæ—¶æ‰æ·»åŠ assistantæ¶ˆæ¯åˆ°å†å²
            loop.messages.append(ChatMessage(role="assistant", content=assistant_plan))
            loop._trim_history(max_messages=30)

            loop.audit.write(trace_id=trace_id, event="plan_generated", data={"title": plan.title, "steps": [s.model_dump() for s in plan.steps]})
            # ä¸º live UI / TUI æä¾›å¯è¯»çš„è®¡åˆ’é¢„è§ˆï¼ˆé¿å…åªç»™ä¸€ä¸ª steps æ•°å­—ï¼‰
            steps_preview: list[str] = []
            for s in plan.steps[: min(8, len(plan.steps))]:
                sid = str(getattr(s, "id", "") or "").strip()
                desc = str(getattr(s, "description", "") or "").strip()
                line = f"{sid}: {desc}" if sid else desc
                if len(line) > 140:
                    line = line[:139] + "â€¦"
                if line:
                    steps_preview.append(line)
            _ev(
                "plan_generated",
                {
                    "type": "FullPlan",  # åˆå§‹è§„åˆ’ç±»å‹
                    "title": plan.title,
                    "steps_count": len(plan.steps),
                    "steps": [s.model_dump() for s in plan.steps],
                    "verification_policy": plan.verification_policy,
                },
            )
            loop.logger.info("[green]âœ“ è®¡åˆ’ç”ŸæˆæˆåŠŸ[/green]")
            plan_summary = render_plan_markdown(plan)
            loop.logger.info(f"[dim]è®¡åˆ’æ‘˜è¦:\n{plan_summary}[/dim]")
            return plan
        except ValueError as e:
            # å°è¯•å®¹é”™ï¼šæ£€æµ‹æ˜¯å¦ä¸ºå·¥å…·è°ƒç”¨è¾“å‡º
            tool_call_plan = _try_convert_tool_call_to_plan(assistant_plan, loop)
            if tool_call_plan:
                # æˆåŠŸè½¬æ¢ï¼Œä½¿ç”¨è½¬æ¢åçš„ Plan
                plan = tool_call_plan
                
                # æ·»åŠ åˆ°å†å²
                loop.messages.append(ChatMessage(role="assistant", content=assistant_plan))
                loop._trim_history(max_messages=30)
                
                loop.audit.write(
                    trace_id=trace_id,
                    event="plan_generated_from_tool_call",
                    data={
                        "title": plan.title,
                        "steps": [s.model_dump() for s in plan.steps],
                        "warning": "LLM è¾“å‡ºå·¥å…·è°ƒç”¨è€Œé Planï¼Œå·²è‡ªåŠ¨è½¬æ¢"
                    }
                )
                
                _ev(
                    "plan_generated",
                    {
                        "type": "FullPlan",
                        "title": plan.title,
                        "steps_count": len(plan.steps),
                        "steps": [s.model_dump() for s in plan.steps],
                        "from_tool_call": True,
                    },
                )
                
                loop.logger.info("[green]âœ“ è®¡åˆ’ç”ŸæˆæˆåŠŸï¼ˆä»å·¥å…·è°ƒç”¨è½¬æ¢ï¼‰[/green]")
                plan_summary = render_plan_markdown(plan)
                loop.logger.info(f"[dim]è®¡åˆ’æ‘˜è¦:\n{plan_summary}[/dim]")
                return plan
            
            # æ— æ³•å®¹é”™ï¼Œè®°å½•é”™è¯¯å¹¶é‡è¯•
            loop.logger.error(f"[red]âœ— è®¡åˆ’è§£æå¤±è´¥ (å°è¯• {plan_attempts}/{loop.cfg.orchestrator.planning_retry + 1}): {e}[/red]", exc_info=True)
            loop.audit.write(trace_id=trace_id, event="plan_parse_failed", data={"attempt": plan_attempts, "error": str(e)})
            _ev("plan_parse_failed", {"attempt": plan_attempts, "error": str(e)})
            loop.messages.append(ChatMessage(role="user", content=read_prompt("user/stage/plan_parse_retry.md").strip()))
            loop._trim_history(max_messages=30)
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸ï¼Œç›´æ¥è®°å½•å¹¶é‡è¯•
            loop.logger.error(f"[red]âœ— è®¡åˆ’è§£æå¤±è´¥ (å°è¯• {plan_attempts}/{loop.cfg.orchestrator.planning_retry + 1}): {e}[/red]", exc_info=True)
            loop.audit.write(trace_id=trace_id, event="plan_parse_failed", data={"attempt": plan_attempts, "error": str(e)})
            _ev("plan_parse_failed", {"attempt": plan_attempts, "error": str(e)})
            loop.messages.append(ChatMessage(role="user", content=read_prompt("user/stage/plan_parse_retry.md").strip()))
            loop._trim_history(max_messages=30)

    return None


