from __future__ import annotations

from typing import Any, Callable, TYPE_CHECKING

from clude_code.llm.llama_cpp_http import ChatMessage
from clude_code.orchestrator.planner import parse_plan_from_text, render_plan_markdown, Plan
from clude_code.orchestrator.state_m import AgentState
from clude_code.prompts import read_prompt

if TYPE_CHECKING:
    from .agent_loop import AgentLoop


def execute_planning_phase(
    loop: "AgentLoop",
    user_text: str,
    planning_prompt: str | None,
    trace_id: str,
    _ev: Callable[[str, dict[str, Any]], None],
    _llm_chat: Callable[[str, str | None], str],
) -> Plan | None:
    """æ‰§è¡Œè§„åˆ’é˜¶æ®µï¼šç”Ÿæˆæ˜¾å¼ Planã€‚"""
    if not planning_prompt:
        return None

    _ev("state", {"state": AgentState.PLANNING.value, "reason": "enable_planning"})
    loop.logger.info("[bold magenta]ğŸ§© è¿›å…¥è§„åˆ’é˜¶æ®µï¼šç”Ÿæˆæ˜¾å¼ Plan[/bold magenta]")

    plan_attempts = 0
    while plan_attempts <= loop.cfg.orchestrator.planning_retry:
        plan_attempts += 1
        _ev("planning_llm_request", {"attempt": plan_attempts})

        # è®°å½•è°ƒç”¨_llm_chatä¹‹å‰çš„æ¶ˆæ¯é•¿åº¦ï¼Œç”¨äºåç»­æ¸…ç†
        messages_before_llm = len(loop.messages)

        assistant_plan = _llm_chat("planning", None)
        _ev("planning_llm_response", {"text": assistant_plan[:4000], "truncated": len(assistant_plan) > 4000})

        try:
            parsed = parse_plan_from_text(assistant_plan)
            if len(parsed.steps) > loop.cfg.orchestrator.max_plan_steps:
                parsed.steps = parsed.steps[: loop.cfg.orchestrator.max_plan_steps]
            plan = parsed

            # å¼ºåˆ¶æ ¡éªŒæ­¥éª¤ ID å”¯ä¸€æ€§ï¼ˆparse_plan_from_text å·²æ ¡éªŒï¼Œè¿™é‡ŒåšåŒä¿é™©ï¼‰
            plan.validate_unique_ids()

            # åªæœ‰åœ¨æˆåŠŸæ—¶æ‰æ·»åŠ assistantæ¶ˆæ¯åˆ°å†å²
            loop.messages.append(ChatMessage(role="assistant", content=assistant_plan))
            loop._trim_history(max_messages=30)

            loop.audit.write(trace_id=trace_id, event="plan_generated", data={"title": plan.title, "steps": [s.model_dump() for s in plan.steps]})
            # ä¸º live UI / TUI æä¾›å¯è¯»çš„è®¡åˆ’é¢„è§ˆï¼ˆé¿å…åªç»™ä¸€ä¸ª steps æ•°å­—ï¼‰
            steps_preview: list[str] = []
            for s in plan.steps[: min(8, len(plan.steps))]:
                sid = str(getattr(s, "id", "") or "").strip()
                desc = str(getattr(s, "description", "") or "").strip()
                line = f"{sid}: {desc}" if sid else desc
                if len(line) > 140:
                    line = line[:139] + "â€¦"
                if line:
                    steps_preview.append(line)
            _ev(
                "plan_generated",
                {
                    "type": "FullPlan",  # åˆå§‹è§„åˆ’ç±»å‹
                    "title": plan.title,
                    "steps_count": len(plan.steps),
                    "steps": [s.model_dump() for s in plan.steps],
                    "verification_policy": plan.verification_policy,
                },
            )
            loop.logger.info("[green]âœ“ è®¡åˆ’ç”ŸæˆæˆåŠŸ[/green]")
            plan_summary = render_plan_markdown(plan)
            loop.logger.info(f"[dim]è®¡åˆ’æ‘˜è¦:\n{plan_summary}[/dim]")
            return plan
        except Exception as e:
            loop.logger.error(f"[red]âœ— è®¡åˆ’è§£æå¤±è´¥ (å°è¯• {plan_attempts}/{loop.cfg.orchestrator.planning_retry + 1}): {e}[/red]", exc_info=True)
            loop.audit.write(trace_id=trace_id, event="plan_parse_failed", data={"attempt": plan_attempts, "error": str(e)})
            _ev("plan_parse_failed", {"attempt": plan_attempts, "error": str(e)})
            loop.messages.append(ChatMessage(role="user", content=read_prompt("agent_loop/plan_parse_retry.md").strip()))
            loop._trim_history(max_messages=30)

    return None


