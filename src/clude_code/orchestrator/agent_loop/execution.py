from __future__ import annotations

import json
from typing import Any, Callable, TYPE_CHECKING

from clude_code.llm.llama_cpp_http import ChatMessage
from clude_code.tooling.local_tools import ToolResult
from clude_code.orchestrator.state_m import AgentState
from clude_code.orchestrator.planner import Plan

if TYPE_CHECKING:
    from .agent_loop import AgentLoop
    from .models import AgentTurn


def check_step_dependencies(
    loop: "AgentLoop",
    step,
    plan: Plan,
    trace_id: str,
    _ev: Callable[[str, dict[str, Any]], None],
) -> list[str]:
    """æ£€æŸ¥æ­¥éª¤ä¾èµ–æ˜¯å¦æ»¡è¶³ï¼Œå¦‚æœä¸æ»¡è¶³åˆ™æ ‡è®°ä¸º blockedã€‚"""
    completed_ids = {s.id for s in plan.steps if s.status == "done"}
    unmet_deps = [dep for dep in step.dependencies if dep not in completed_ids]
    if unmet_deps:
        loop.logger.warning(f"[yellow]âš  æ­¥éª¤ {step.id} æœ‰æœªæ»¡è¶³çš„ä¾èµ–: {unmet_deps}ï¼Œè·³è¿‡å¹¶æ ‡è®°ä¸º blocked[/yellow]")
        step.status = "blocked"
        loop.audit.write(trace_id=trace_id, event="plan_step_blocked", data={"step_id": step.id, "unmet_deps": unmet_deps})
        _ev("plan_step_blocked", {"step_id": step.id, "unmet_deps": unmet_deps})
    return unmet_deps


def handle_tool_call_in_step(
    loop: "AgentLoop",
    name: str,
    args: dict[str, Any],
    step,
    trace_id: str,
    keywords: set[str],
    confirm: Callable[[str], bool],
    _ev: Callable[[str, dict[str, Any]], None],
    _tool_result_to_message: Callable[[str, ToolResult, set[str] | None], str],
) -> tuple[ToolResult, bool]:
    """
    å¤„ç†æ­¥éª¤ä¸­çš„å·¥å…·è°ƒç”¨ï¼šç»Ÿä¸€ç”Ÿå‘½å‘¨æœŸ + å›å–‚ã€‚
    è¿”å›: (result, did_modify_code)
    """
    result = loop._run_tool_lifecycle(name, args, trace_id, confirm, _ev)
    did_modify_code = (name in {"write_file", "apply_patch", "undo_patch"} and result.ok)

    _ev("tool_result", {"tool": name, "ok": result.ok, "error": result.error, "payload": result.payload, "step_id": step.id})

    result_msg = _tool_result_to_message(name, result, keywords=keywords)
    loop.messages.append(ChatMessage(role="user", content=result_msg))
    loop.logger.debug(f"[dim]å·¥å…·ç»“æœå·²å›å–‚[/dim] [å·¥å…·] {name} [æ­¥éª¤] {step.id}")
    loop.file_only_logger.debug(f"å·¥å…·ç»“æœå›å–‚ [step={step.id}] [tool={name}] [len={len(result_msg)}]")
    _ev("tool_result_fed_back", {"tool": name, "step_id": step.id})
    loop._trim_history(max_messages=30)

    return result, did_modify_code


def execute_single_step_iteration(
    loop: "AgentLoop",
    step,
    step_cursor: int,
    plan: Plan,
    iteration: int,
    trace_id: str,
    keywords: set[str],
    confirm: Callable[[str], bool],
    _ev: Callable[[str, dict[str, Any]], None],
    _llm_chat: Callable[[str, str | None], str],
    _try_parse_tool_call: Callable[[str], dict[str, Any] | None],
    _tool_result_to_message: Callable[[str, ToolResult, set[str] | None], str],
) -> tuple[str | None, bool, bool]:
    """
    æ‰§è¡Œå•ä¸ªè®¡åˆ’æ­¥éª¤çš„ä¸€æ¬¡ LLM äº¤äº’è½®æ¬¡ã€‚
    è¿”å›: (control_signal, did_modify_code, did_use_tool)
    """
    tools_hint = ", ".join(step.tools_expected) if step.tools_expected else "ï¼ˆæœªæŒ‡å®šï¼Œæ¨¡å‹è‡ªé€‰ï¼‰"
    loop.logger.info(
        f"[bold yellow]â†’ æ‰§è¡Œæ­¥éª¤ {step_cursor + 1}/{len(plan.steps)}: {step.id}ï¼ˆè½®æ¬¡ {iteration + 1}/{loop.cfg.orchestrator.max_step_tool_calls}ï¼‰[/bold yellow] "
        f"[æè¿°] {step.description} [å»ºè®®å·¥å…·] {tools_hint}"
    )
    _ev("llm_request", {"messages": len(loop.messages), "step_id": step.id, "iteration": iteration + 1})

    loop._log_llm_request_params_to_file()

    step_prompt = (
        f"ç°åœ¨æ‰§è¡Œè®¡åˆ’æ­¥éª¤ï¼š{step.id}\n"
        f"æ­¥éª¤æè¿°ï¼š{step.description}\n"
        f"å»ºè®®å·¥å…·ï¼š{', '.join(step.tools_expected) if step.tools_expected else 'ï¼ˆè‡ªè¡Œé€‰æ‹©ï¼‰'}\n\n"
        "è§„åˆ™ï¼š\n"
        "1) å¦‚æœéœ€è¦å·¥å…·ï¼šåªè¾“å‡ºä¸€ä¸ªå·¥å…·è°ƒç”¨ JSONï¼ˆä¸ç³»ç»Ÿè¦æ±‚ä¸€è‡´ï¼‰ã€‚\n"
        "2) å¦‚æœæœ¬æ­¥éª¤å·²å®Œæˆä¸”ä¸éœ€è¦å·¥å…·ï¼šåªè¾“å‡ºå­—ç¬¦ä¸²ã€STEP_DONEã€‘ã€‚\n"
        "3) å¦‚æœæœ¬æ­¥éª¤å¤±è´¥ä¸”éœ€è¦é‡è§„åˆ’ï¼šåªè¾“å‡ºå­—ç¬¦ä¸²ã€REPLANã€‘ã€‚\n"
    )
    loop.messages.append(ChatMessage(role="user", content=step_prompt))
    loop._trim_history(max_messages=30)

    assistant = _llm_chat("execute_step", step.id)
    _ev("llm_response", {"text": assistant[:4000], "truncated": len(assistant) > 4000, "step_id": step.id})

    if assistant.count("[") > 50 or assistant.count("{") > 50:
        loop.logger.warning("[red]æ£€æµ‹åˆ°æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼ˆå¤è¯»å­—ç¬¦ï¼‰ï¼Œå·²å¼ºåˆ¶æˆªæ–­[/red]")
        assistant = "æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼šæ£€æµ‹åˆ°è¿‡å¤šçš„é‡å¤å­—ç¬¦ï¼Œå·²å¼ºåˆ¶æˆªæ–­ã€‚"
        _ev("stuttering_detected", {"length": len(assistant), "step_id": step.id})

    a_strip = assistant.strip()
    if "STEP_DONE" in a_strip or "ã€STEP_DONEã€‘" in a_strip or a_strip.upper().startswith("STEP_DONE"):
        loop.messages.append(ChatMessage(role="assistant", content=assistant))
        loop._trim_history(max_messages=30)
        step.status = "done"
        loop.audit.write(trace_id=trace_id, event="plan_step_done", data={"step_id": step.id})
        _ev("plan_step_done", {"step_id": step.id})
        loop.logger.info(f"[green]âœ“ æ­¥éª¤å®Œæˆ[/green] [æ­¥éª¤] {step.id} [æè¿°] {step.description}")
        return "STEP_DONE", False, False

    if "REPLAN" in a_strip or "ã€REPLANã€‘" in a_strip or a_strip.upper().startswith("REPLAN"):
        loop.messages.append(ChatMessage(role="assistant", content=assistant))
        loop._trim_history(max_messages=30)
        step.status = "failed"
        loop.audit.write(trace_id=trace_id, event="plan_step_replan_requested", data={"step_id": step.id})
        _ev("plan_step_replan_requested", {"step_id": step.id})
        loop.logger.warning(f"[yellow]âš  æ­¥éª¤è¯·æ±‚é‡è§„åˆ’[/yellow] [æ­¥éª¤] {step.id} [æè¿°] {step.description}")
        return "REPLAN", False, False

    tool_call = _try_parse_tool_call(assistant)
    loop._log_llm_response_data_to_file(assistant, tool_call)
    if tool_call is None:
        loop.messages.append(ChatMessage(role="assistant", content=assistant))
        loop._trim_history(max_messages=30)
        loop.messages.append(ChatMessage(role="user", content="ä½ çš„è¾“å‡ºæ—¢ä¸æ˜¯å·¥å…·è°ƒç”¨ JSONï¼Œä¹Ÿä¸æ˜¯ã€STEP_DONEã€‘/ã€REPLANã€‘ã€‚è¯·ä¸¥æ ¼æŒ‰è§„åˆ™è¾“å‡ºã€‚"))
        loop._trim_history(max_messages=30)
        return None, False, False

    name = tool_call["tool"]
    args = tool_call["args"]
    _ev("tool_call_parsed", {"tool": name, "args": args, "step_id": step.id})

    args_summary = loop._format_args_summary(name, args)
    loop.logger.info(f"[bold blue]ğŸ”§ è§£æåˆ°å·¥å…·è°ƒç”¨: {name}[/bold blue] [æ­¥éª¤] {step.id} [å‚æ•°] {args_summary}")
    loop.file_only_logger.info(f"å·¥å…·è°ƒç”¨è¯¦æƒ… [step_id={step.id}] [tool={name}] [args={json.dumps(args, ensure_ascii=False)}]")

    clean_assistant = json.dumps(tool_call, ensure_ascii=False)
    loop.messages.append(ChatMessage(role="assistant", content=clean_assistant))
    loop._trim_history(max_messages=30)

    result, did_modify_code = handle_tool_call_in_step(loop, name, args, step, trace_id, keywords, confirm, _ev, _tool_result_to_message)
    if result is None:
        return None, False, True
    return None, did_modify_code, True


def handle_replanning(
    loop: "AgentLoop",
    step,
    plan: Plan,
    replans_used: int,
    trace_id: str,
    tool_used: bool,
    _ev: Callable[[str, dict[str, Any]], None],
    _llm_chat: Callable[[str, str | None], str],
    _set_state: Callable[[AgentState, dict[str, Any] | None], None],
) -> tuple[Plan | None, int]:
    """å¤„ç†é‡è§„åˆ’é€»è¾‘ã€‚è¿”å›: (new_plan, new_replans_used)"""
    if replans_used >= loop.cfg.orchestrator.max_replans:
        loop.logger.warning(f"[red]âš  è¾¾åˆ°æœ€å¤§é‡è§„åˆ’æ¬¡æ•°ï¼Œåœæ­¢[/red] [å½“å‰æ­¥éª¤] {step.id} [å·²ç”¨é‡è§„åˆ’] {replans_used}/{loop.cfg.orchestrator.max_replans}")
        _ev("stop_reason", {"reason": "max_replans_reached", "limit": loop.cfg.orchestrator.max_replans})
        return None, replans_used

    replans_used += 1
    _set_state(AgentState.RECOVERING, {"reason": "step_failed", "step_id": step.id, "replans_used": replans_used})
    _set_state(AgentState.PLANNING, {"reason": "replan", "replans_used": replans_used})

    replan_prompt = (
        "å‡ºç°é˜»å¡/å¤±è´¥ï¼Œéœ€è¦é‡è§„åˆ’ã€‚è¯·è¾“å‡ºæ–°çš„ Plan JSONï¼ˆä¸¥æ ¼ JSONï¼Œä¸è¦è§£é‡Šï¼Œä¸è¦è°ƒç”¨å·¥å…·ï¼‰ã€‚\n"
        f"é™åˆ¶ï¼šsteps ä¸è¶…è¿‡ {loop.cfg.orchestrator.max_plan_steps}ã€‚\n"
        "è¯·ç»“åˆå½“å‰å¯¹è¯ä¸­çš„é”™è¯¯ä¸å·¥å…·åé¦ˆï¼Œç”Ÿæˆæ›´å¯æ‰§è¡Œçš„æ­¥éª¤ã€‚"
    )
    loop.messages.append(ChatMessage(role="user", content=replan_prompt))
    loop._trim_history(max_messages=30)
    assistant_plan = _llm_chat("replan", step.id)
    _ev("planning_llm_response", {"text": assistant_plan[:4000], "truncated": len(assistant_plan) > 4000})
    loop.messages.append(ChatMessage(role="assistant", content=assistant_plan))
    loop._trim_history(max_messages=30)

    try:
        from clude_code.orchestrator.planner import parse_plan_from_text, render_plan_markdown

        new_plan = parse_plan_from_text(assistant_plan)
        if len(new_plan.steps) > loop.cfg.orchestrator.max_plan_steps:
            new_plan.steps = new_plan.steps[: loop.cfg.orchestrator.max_plan_steps]
        loop.audit.write(trace_id=trace_id, event="replan_generated", data={"title": new_plan.title, "steps": [s.model_dump() for s in new_plan.steps]})
        _ev("replan_generated", {"title": new_plan.title, "steps": len(new_plan.steps), "replans_used": replans_used})
        loop.file_only_logger.info("é‡è§„åˆ’è®¡åˆ’:\n" + render_plan_markdown(new_plan))
        return new_plan, replans_used
    except Exception as e:
        loop.logger.error(f"[red]âœ— é‡è§„åˆ’è®¡åˆ’è§£æå¤±è´¥: {e}[/red]", exc_info=True)
        _ev("stop_reason", {"reason": "replan_parse_failed"})
        return None, replans_used


def execute_final_verification(
    loop: "AgentLoop",
    plan: Plan,
    did_modify_code: bool,
    trace_id: str,
    tool_used: bool,
    _ev: Callable[[str, dict[str, Any]], None],
    _set_state: Callable[[AgentState, dict[str, Any] | None], None],
) -> "AgentTurn | None":
    """æœ€ç»ˆéªŒè¯é˜¶æ®µï¼ˆä»…åœ¨ä¿®æ”¹è¿‡ä»£ç æ—¶è§¦å‘ï¼‰ã€‚"""
    if not did_modify_code:
        return None

    _set_state(AgentState.VERIFYING, {"reason": "did_modify_code"})
    loop.logger.info("[bold magenta]ğŸ” æœ€ç»ˆéªŒè¯é˜¶æ®µï¼šè¿è¡Œè‡ªæ£€[/bold magenta]")
    v_res = loop.verifier.run_verify()
    _ev("final_verify", {"ok": v_res.ok, "type": v_res.type, "summary": v_res.summary})

    if not v_res.ok:
        text = f"æœ€ç»ˆéªŒè¯å¤±è´¥ï¼š{v_res.summary}\n"
        if v_res.errors:
            for err in v_res.errors[:10]:
                text += f"- {err.file}:{err.line} {err.message}\n"
        _set_state(AgentState.DONE, {"ok": False})
        from .models import AgentTurn

        return AgentTurn(assistant_text=text, tool_used=tool_used, trace_id=trace_id, events=[])
    return None


def execute_plan_steps(
    loop: "AgentLoop",
    plan: Plan,
    trace_id: str,
    keywords: set[str],
    confirm: Callable[[str], bool],
    events: list[dict[str, Any]],
    _ev: Callable[[str, dict[str, Any]], None],
    _llm_chat: Callable[[str, str | None], str],
    _try_parse_tool_call: Callable[[str], dict[str, Any] | None],
    _tool_result_to_message: Callable[[str, ToolResult, set[str] | None], str],
    _set_state: Callable[[AgentState, dict[str, Any] | None], None],
) -> tuple[Plan | None, bool, bool]:
    """
    æ‰§è¡Œè®¡åˆ’çš„æ‰€æœ‰æ­¥éª¤ï¼ˆä¸»å¾ªç¯ï¼‰ã€‚
    è¿”å›: (plan, tool_used, did_modify_code)
    """
    _set_state(AgentState.EXECUTING, {"steps": len(plan.steps)})
    loop.logger.info("[bold magenta]â–¶ è¿›å…¥æ‰§è¡Œé˜¶æ®µï¼šæŒ‰ Plan æ­¥éª¤ç¼–æ’[/bold magenta]")

    replans_used = 0
    step_cursor = 0
    tool_used = False
    did_modify_code = False

    while True:
        if step_cursor >= len(plan.steps):
            break

        step = plan.steps[step_cursor]
        unmet_deps = check_step_dependencies(loop, step, plan, trace_id, _ev)
        if unmet_deps:
            step_cursor += 1
            continue

        step.status = "in_progress"
        loop.audit.write(trace_id=trace_id, event="plan_step_start", data={"step_id": step.id, "description": step.description})
        _ev("plan_step_start", {"step_id": step.id, "idx": step_cursor + 1, "total": len(plan.steps)})

        for iteration in range(loop.cfg.orchestrator.max_step_tool_calls):
            control_signal, iter_did_modify, iter_did_use_tool = execute_single_step_iteration(
                loop,
                step,
                step_cursor,
                plan,
                iteration,
                trace_id,
                keywords,
                confirm,
                _ev,
                _llm_chat,
                _try_parse_tool_call,
                _tool_result_to_message,
            )

            if iter_did_modify:
                did_modify_code = True
            if iter_did_use_tool:
                tool_used = True

            if control_signal in ("STEP_DONE", "REPLAN"):
                break

        if step.status == "done":
            step_cursor += 1
            continue

        if step.status in ("failed", "in_progress"):
            step.status = "failed"
            new_plan, replans_used = handle_replanning(loop, step, plan, replans_used, trace_id, tool_used, _ev, _llm_chat, _set_state)
            if new_plan is None:
                return None, tool_used, did_modify_code
            plan = new_plan
            step_cursor = 0
            continue

        if step.status == "blocked":
            all_blocked_or_done = all(s.status in ("blocked", "done") for s in plan.steps)
            if all_blocked_or_done and any(s.status == "blocked" for s in plan.steps):
                loop.logger.error("[red]âœ— æ£€æµ‹åˆ°ä¾èµ–æ­»é”ï¼šæ‰€æœ‰æœªå®Œæˆæ­¥éª¤éƒ½å¤„äº blocked çŠ¶æ€[/red]")
                _ev("stop_reason", {"reason": "dependency_deadlock"})
                return None, tool_used, did_modify_code
            step_cursor += 1
            continue

        _ev("stop_reason", {"reason": "step_not_completed", "step_id": step.id})
        return None, tool_used, did_modify_code

    return plan, tool_used, did_modify_code


