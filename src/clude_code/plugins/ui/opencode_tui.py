"""
Textual-based TUIï¼ˆå¯¹æ ‡ OpenCodeï¼‰ï¼š
- å¤šçª—æ ¼å¸ƒå±€ï¼ˆå·¦ä¾§è¾“å‡º/å³ä¾§çŠ¶æ€ä¸Žæ“ä½œ/åº•éƒ¨äº‹ä»¶ï¼‰
- æ¯ä¸ªçª—æ ¼å¯æ»šåŠ¨ï¼ˆæ”¯æŒé¼ æ ‡æ»šè½®æŸ¥çœ‹åŽ†å²ï¼‰
- ä¸ä¾èµ– rich.Live çš„æ•´å±åˆ·æ–°

æ³¨æ„ï¼šè¯¥æ¨¡å—ä¾èµ–å¯é€‰ä¾èµ– `textual`ï¼ˆè§ pyproject.toml çš„ [project.optional-dependencies].uiï¼‰ã€‚
æœªå®‰è£…æ—¶åº”ç”±è°ƒç”¨æ–¹ä¼˜é›…é™çº§ã€‚
"""

from __future__ import annotations

from queue import Empty, Queue
from threading import Thread
from typing import Any, Callable
import json
import time
from rich.text import Text
from rich.table import Table
from rich.syntax import Syntax
from collections import deque


def run_opencode_tui(
    *,
    cfg: Any,
    run_turn: Callable[[str, Callable[[str], bool], Callable[[dict[str, Any]], None]], None],
) -> None:
    """
    è¿è¡Œ OpenCode é£Žæ ¼ Textual TUIï¼ˆåœ¨ä¸»çº¿ç¨‹é˜»å¡žè¿è¡Œï¼‰ã€‚

    ä¸ºä»€ä¹ˆè¿™æ ·åšï¼š
    - Textual/TUI æ¡†æž¶é€šå¸¸éœ€è¦åœ¨ä¸»çº¿ç¨‹è¿è¡Œï¼ˆæ‰èƒ½æ­£ç¡®å¤„ç†è¾“å…¥/é¼ æ ‡/ç»ˆç«¯èƒ½åŠ›ï¼‰
    - AgentLoop åœ¨åŽå°çº¿ç¨‹æ‰§è¡Œï¼Œé€šè¿‡é˜Ÿåˆ—æŠŠäº‹ä»¶æŽ¨é€å›ž UI çº¿ç¨‹æ¸²æŸ“
    """

    # å»¶è¿Ÿå¯¼å…¥ï¼šé¿å…çº¯ CLI/doctor/tools ä¹Ÿè¢«è¿«å®‰è£… textual
    # å¯é€‰ä¾èµ–ï¼šTextualï¼ˆè¿è¡Œæ—¶å­˜åœ¨å³å¯ï¼›é™æ€æ£€æŸ¥å…è®¸ç¼ºå¤±ï¼‰
    from textual.app import App, ComposeResult  # type: ignore[import-not-found]
    from textual.containers import Horizontal, Vertical  # type: ignore[import-not-found]
    from textual.widgets import Footer, Header, Input, RichLog  # type: ignore[import-not-found]

    q: Queue[dict[str, Any]] = Queue(maxsize=50_000)

    class _Log(RichLog):
        """RichLog é»˜è®¤å¯æ»šåŠ¨ï¼Œæ”¯æŒé¼ æ ‡æ»šè½®æŸ¥çœ‹åŽ†å²ã€‚"""

        def __init__(self, *args: Any, **kwargs: Any) -> None:
            kwargs.setdefault("wrap", True)
            super().__init__(*args, **kwargs)
            # é»˜è®¤è·Ÿéšå°¾éƒ¨ï¼ˆæ›´åƒ OpenCodeï¼‰ï¼›ç”¨æˆ·å¯æŒ‰ f åˆ‡æ¢â€œæµè§ˆåŽ†å²/è·Ÿéšè¾“å‡ºâ€
            self.auto_scroll = True

    class OpencodeTUI(App):
        TITLE = "clude chat"
        SUB_TITLE = "opencode"
        CSS = """
        Screen { layout: vertical; }
        #main { height: 1fr; }
        /* é¡¶éƒ¨ clude chat é¢æ¿ï¼šæŒ‰å†…å®¹è‡ªé€‚åº”ï¼Œé¿å…å¤šä½™ç©ºç™½ */
        #header_panel { height: auto; min-height: 3; }
        #left { width: 3fr; }
        #right { width: 2fr; }
        /* è¾“å…¥æ¡†ï¼šéœ€è¦ç»™è¾¹æ¡†/æç¤ºç•™ç©ºé—´ï¼Œå¦åˆ™ä¼šå¯¼è‡´æ— æ³•è¾“å…¥æˆ–ä¸å¯è§ */
        #input_row { height: 3; min-height: 3; }
        /* äº‹ä»¶åŒºï¼šç¨å¾®æ”¶ç´§ï¼Œç»™ä¸»å†…å®¹æ›´å¤šç©ºé—´ */
        #events { height: 8; }
        _Log { border: solid $primary; }
        /* æ‰€æœ‰å°çª—å£æ ‡é¢˜å±…ä¸­ï¼ˆå¯¹é½ä½ çš„è¦æ±‚ï¼‰ */
        #header_panel, #conversation, #status, #ops, #events, #input { border-title-align: center; }
        /* å³ä¾§ï¼šçŠ¶æ€æŒ‰å†…å®¹è‡ªé€‚åº”ï¼Œæ“ä½œé¢æ¿åƒæŽ‰å‰©ä½™é«˜åº¦ */
        #status { height: auto; }
        #ops { height: 1fr; min-height: 8; }
        """

        BINDINGS = [
            ("q", "quit", "Quit"),
            ("ctrl+c", "quit", "Quit"),
            ("f", "toggle_follow", "Follow/Scroll"),
            ("end", "jump_bottom", "Bottom"),
        ]

        def __init__(self) -> None:
            super().__init__()
            self._busy = False
            self._follow = True
            self._model = str(getattr(getattr(cfg, "llm", None), "model", "") or "auto")
            self._base_url = str(getattr(getattr(cfg, "llm", None), "base_url", "") or "")

            # å¯¹é½ enhanced çš„â€œçŠ¶æ€/æ“ä½œâ€å­—æ®µ
            self._state = "IDLE"
            self._operation = "ç­‰å¾…ä¸­"
            self._last_step: int | str = "-"
            self._last_event: str = "waiting"
            self._last_llm_messages: int | None = None
            self._last_tool: str | None = None
            self._last_tool_args: str | None = None
            self._last_tool_result: str | None = None
            self._active_tasks: int = 0
            self._recent_completed: deque[str] = deque(maxlen=5)
            self._project_memory_shown: bool = False

            self._max_tokens = int(getattr(getattr(cfg, "llm", None), "max_tokens", 0) or 0)
            self._llm_prompt = 0
            self._llm_completion = 0
            self._tps = 0.0
            self._verbosity: str = "compact"  # compact|verbose|debugï¼ˆä»…å½±å“â€œå¯¹è¯/è¾“å‡ºâ€çš„å—å†…å®¹ï¼‰

        def _now_hhmmss(self) -> str:
            try:
                return time.strftime("%H:%M:%S", time.localtime())
            except Exception:
                return ""

        def _short_trace(self, trace_id: str | None) -> str:
            t = (trace_id or "").strip()
            return t[:8] if t else "-"

        def _level_style(self, level: str) -> str:
            lv = (level or "").strip().lower()
            return {
                "info": "cyan",
                "progress": "blue",
                "warning": "yellow",
                "warn": "yellow",
                "error": "red",
                "success": "green",
            }.get(lv, "cyan")

        def _push_structured_block(
            self,
            *,
            title: str,
            level: str = "info",
            step: int | str | None = None,
            ev: str | None = None,
            trace_id: str | None = None,
            summary: str | None = None,
            decision: str | None = None,
            evidence: list[str] | None = None,
            hint: str | None = None,
            force_show_decision: bool = False,
        ) -> None:
            """
            åœ¨â€œå¯¹è¯/è¾“å‡ºâ€çª—æ ¼è¾“å‡ºç»“æž„åŒ–å—ï¼š
            - å¤´éƒ¨ï¼štime/LEVEL/step/ev/trace
            - æ­£æ–‡ï¼šSummary / Why / Evidenceï¼ˆæ‘˜è¦ä¼˜å…ˆï¼‰
            """
            conversation = self.query_one("#conversation", _Log)
            ttl = (title or "").strip()
            if not ttl:
                return
            lv = (level or "info").strip().upper()
            t = self._now_hhmmss()
            st = "-" if step is None else str(step)
            et = (ev or "").strip() or "-"
            tr = self._short_trace(trace_id)
            head = f"[{t}] [{lv}] step={st} ev={et} trace={tr}  {ttl}".strip()

            color = self._level_style(level)
            conversation.write(Text(f"â”Œâ”€ {head}", style=color))

            def _w(prefix: str, txt: str | None) -> None:
                s = (txt or "").strip()
                if not s:
                    return
                # é˜²æ­¢çˆ†å±ï¼šå¯¹è¯åŒºæ¯è¡Œå°½é‡çŸ­ä¸€äº›
                if len(s) > 500 and self._verbosity != "debug":
                    s = s[:499] + "â€¦"
                conversation.write(Text(f"â”‚ {prefix}{s}", style=color))

            _w("Summary: ", summary)
            if force_show_decision or self._verbosity in {"verbose", "debug"}:
                _w("Why: ", decision)
            if evidence:
                if self._verbosity == "compact":
                    ev_lines = evidence[:6]
                else:
                    ev_lines = evidence[:12]
                for ln in ev_lines:
                    ln = (ln or "").strip()
                    if not ln:
                        continue
                    if len(ln) > 520 and self._verbosity != "debug":
                        ln = ln[:519] + "â€¦"
                    conversation.write(Text(f"â”‚ Evidence: {ln}", style=color))
                if len(evidence) > len(ev_lines):
                    conversation.write(Text("â”‚ Evidence: â€¦(æ›´å¤šè¯æ®è§â€œäº‹ä»¶/æ“ä½œé¢æ¿â€)", style=color))
            if hint:
                _w("Hint: ", hint)
            conversation.write(Text("â””â”€", style=color))
            if self._follow:
                try:
                    conversation.scroll_end(animate=False)
                except Exception:
                    pass

        def _summarize_tool_args(self, tool: str, args: dict[str, Any]) -> list[str]:
            """ä»Ž args ä¸­æç‚¼â€œå¯¹è¯åŒºå¯è¯»è¯æ®â€ï¼Œé¿å… dump å…¨é‡ JSONã€‚"""
            tool = (tool or "").strip()
            args = args or {}
            evs: list[str] = []
            if tool == "read_file":
                evs.append(f"path={args.get('target_file')}")
                if args.get("offset") is not None:
                    evs.append(f"offset={args.get('offset')}")
                if args.get("limit") is not None:
                    evs.append(f"limit={args.get('limit')}")
            elif tool == "grep":
                evs.append(f"pattern={args.get('pattern')}")
                if args.get("path"):
                    evs.append(f"path={args.get('path')}")
                if args.get("glob"):
                    evs.append(f"glob={args.get('glob')}")
            elif tool == "apply_patch":
                # patch å†…å®¹å¯èƒ½å¾ˆé•¿ï¼šåªæç¤ºâ€œå·²æäº¤ patchâ€ï¼Œè¯¦æƒ…çœ‹äº‹ä»¶çª—æ ¼
                evs.append("patch=*** Begin Patch â€¦")
            elif tool in {"run_terminal_cmd", "run_cmd"}:
                cmd = args.get("command") or args.get("cmd")
                evs.append(f"command={cmd}")
                if args.get("is_background") is not None:
                    evs.append(f"is_background={args.get('is_background')}")
            elif tool in {"web_search", "webfetch"}:
                q = args.get("search_term") or args.get("url")
                evs.append(f"q={q}")
            else:
                # é»˜è®¤æç‚¼å°‘é‡å…³é”®å­—æ®µ
                for k in ("target_file", "target_directory", "glob_pattern", "query", "explanation", "name"):
                    if k in args and args.get(k) is not None:
                        evs.append(f"{k}={args.get(k)}")
            return [str(x) for x in evs if x not in ("None", "")]

        def compose(self) -> ComposeResult:
            yield Header(show_clock=True)
            yield _Log(id="header_panel")
            with Horizontal(id="main"):
                with Vertical(id="left"):
                    yield _Log(id="conversation")
                with Vertical(id="right"):
                    yield _Log(id="status")
                    yield _Log(id="ops")
            with Horizontal(id="input_row"):
                yield Input(placeholder="è¾“å…¥å†…å®¹ï¼Œå›žè½¦å‘é€ï¼ˆq é€€å‡ºï¼‰", id="input")
            yield _Log(id="events")
            yield Footer()

        def on_mount(self) -> None:
            # ä¸ºæ¯ä¸ªâ€œçª—å£â€è®¾ç½®è¾¹æ¡†æ ‡é¢˜ï¼ˆå¯¹é½ enhanced çš„åˆ†åŒºå‘½åï¼‰
            header_panel = self.query_one("#header_panel", _Log)
            conversation = self.query_one("#conversation", _Log)
            status_panel = self.query_one("#status", _Log)
            ops_panel = self.query_one("#ops", _Log)
            events_panel = self.query_one("#events", _Log)
            input_box = self.query_one("#input", Input)

            header_panel.border_title = "clude chat"
            conversation.border_title = "å¯¹è¯/è¾“å‡º"
            status_panel.border_title = "çŠ¶æ€"
            ops_panel.border_title = "æ“ä½œé¢æ¿"
            events_panel.border_title = "äº‹ä»¶"
            input_box.border_title = "you"

            # æ ‡é¢˜å±…ä¸­ï¼ˆTextual æ”¯æŒ border_title_alignï¼‰
            for w in (header_panel, conversation, status_panel, ops_panel, events_panel, input_box):
                try:
                    w.border_title_align = "center"  # type: ignore[attr-defined]
                except Exception:
                    pass

            # ç¡®ä¿è¾“å…¥æ¡†å¯ç”¨ä¸”é»˜è®¤èŽ·å¾—ç„¦ç‚¹
            try:
                input_box.focus()
            except Exception:
                pass

            # åˆå§‹çŠ¶æ€ï¼šè¿›å…¥ç•Œé¢å³â€œç­‰å¾…è¾“å…¥â€ï¼Œä¸è¦æ²¿ç”¨ä¸Šæ¬¡çš„ DONE/æ‰§è¡Œæ€
            self._state = "IDLE"
            self._operation = "ç­‰å¾…ä¸­"
            self._last_step = "-"
            self._last_event = "ready"
            self._active_tasks = 0
            self._recent_completed.clear()

            # è¿›å…¥ç•Œé¢å³è¾“å‡ºé¡¹ç›®è®°å¿†åŠ è½½å—ï¼ˆå¯¹é½ enhancedï¼šæ— éœ€ç­‰åˆ°ç¬¬ä¸€è½® run_turnï¼‰
            try:
                from clude_code.orchestrator.agent_loop.prompts import load_project_memory

                _txt, meta = load_project_memory(getattr(cfg, "workspace_root", "."))
                loaded = bool(meta.get("loaded"))
                path = str(meta.get("path", ""))
                truncated = bool(meta.get("truncated", False))
                length = meta.get("length")
                legacy = bool(meta.get("legacy_name", False))
                if loaded:
                    conversation.write(Text("â”Œâ”€ é¡¹ç›®è®°å¿†å·²åŠ è½½ï¼ˆCLUDE.mdï¼‰", style="cyan"))
                    conversation.write(Text(f"â”‚ path={path}", style="cyan"))
                    conversation.write(Text(f"â”‚ length={length}", style="cyan"))
                    conversation.write(Text(f"â”‚ truncated={truncated}", style="cyan"))
                    conversation.write(Text(f"â”‚ legacy_name={legacy}", style="cyan"))
                    conversation.write(Text("â””â”€", style="cyan"))
                else:
                    conversation.write(Text("â”Œâ”€ æœªåŠ è½½é¡¹ç›®è®°å¿†ï¼ˆCLUDE.mdï¼‰", style="cyan"))
                    conversation.write(Text(f"â”‚ path={path}", style="cyan"))
                    conversation.write(Text("â”‚ åŽŸå› ï¼šæ–‡ä»¶ä¸å­˜åœ¨/ä¸ºç©º/è¯»å–å¤±è´¥", style="cyan"))
                    conversation.write(Text("â””â”€", style="cyan"))
                self._project_memory_shown = True
            except Exception:
                # å¤±è´¥ä¸é˜»å¡ž UI
                pass

            self._refresh_header_panel()
            self._refresh_status()
            self._refresh_ops()

            self.query_one("#events", _Log).write(
                "[dim]æç¤ºï¼šæ»šè½®å¯æ»šåŠ¨åŽ†å²ï¼›æŒ‰ f åˆ‡æ¢è·Ÿéšè¾“å‡ºï¼›æŒ‰ End å›žåˆ°åº•éƒ¨ã€‚[/dim]"
            )
            self.set_interval(0.05, self._drain_events)

        def _refresh_header_panel(self) -> None:
            """é¡¶éƒ¨ `clude chat` çª—å£ï¼šæ‰¿è½½ enhanced é¡¶æ é‡Œçš„å…³é”®è¿è¡Œæ€ä¿¡æ¯ã€‚"""
            hp = self.query_one("#header_panel", _Log)
            hp.clear()

            # ç¬¬ä¸€è¡Œï¼šå¯¹é½ enhancedï¼ˆæ¨¡å¼/çŠ¶æ€/æ“ä½œ/è¿è¡Œä¿¡æ¯æ¨ªå‘æŽ’å¸ƒï¼‰
            row1 = Table.grid(expand=True)
            row1.add_column(justify="left", ratio=5, no_wrap=True)
            row1.add_column(justify="left", ratio=2, no_wrap=True)
            row1.add_column(justify="left", ratio=3, no_wrap=True)
            row1.add_column(justify="right", ratio=4, no_wrap=True)

            t_mode = Text("æ¨¡å¼: Clude Code é£Žæ ¼ï¼ˆopencodeï¼‰")
            t_state = Text(f"çŠ¶æ€: {self._state}")
            t_op = Text(f"æ“ä½œ: {self._operation}")
            t_run = Text(f"è¿è¡Œ: step={self._last_step}  ev={self._last_event}", style="dim")

            row1.add_row(t_mode, t_state, t_op, t_run)
            hp.write(row1)

            # ç¬¬äºŒè¡Œï¼šContext/Output/TPS
            hp.write(Text(f"  {self._render_top_metrics()}", style="dim"))

        def _refresh_status(self) -> None:
            """å³ä¾§â€œçŠ¶æ€â€çª—æ ¼ï¼šä¿ç•™çŽ¯å¢ƒ/æ¨¡åž‹ä¿¡æ¯ï¼Œé¿å…ä¸Žé¡¶éƒ¨é‡å¤ã€‚"""
            status = self.query_one("#status", _Log)
            status.clear()
            t = Table(show_header=False, box=None, pad_edge=False)
            t.add_column(justify="left", style="bold", width=6)
            t.add_column(justify="left")

            t.add_row("æ¨¡åž‹", self._model[:48])
            if self._base_url:
                t.add_row("åœ°å€", self._base_url[:80])
            t.add_row("çŠ¶æ€", str(self._state))
            t.add_row("æ­¥éª¤", str(self._last_step))
            t.add_row("äº‹ä»¶", str(self._last_event))
            t.add_row("ä»»åŠ¡", f"{self._active_tasks} æ´»è·ƒ / {len(self._recent_completed)} æœ€è¿‘å®Œæˆ")
            status.write(t)

        def _refresh_ops(self) -> None:
            """åˆ·æ–°å³ä¾§â€œæ“ä½œé¢æ¿â€çª—æ ¼ï¼ˆå¯¹é½ enhanced çš„å¿«ç…§ä¿¡æ¯ï¼‰ã€‚"""
            ops = self.query_one("#ops", _Log)
            ops.clear()
            # ç»“æž„åŒ–ï¼šLLM + Tool å¿«ç…§ï¼ˆä¾¿äºŽæŽ’æŸ¥ï¼‰
            llm_t = Table(show_header=False, box=None, pad_edge=False)
            llm_t.add_column(justify="left", style="bold", width=8)
            llm_t.add_column(justify="left")
            if self._last_llm_messages is not None:
                llm_t.add_row("LLM", f"messages={self._last_llm_messages}")
            llm_t.add_row("ç”¨é‡", self._render_top_metrics())
            ops.write(llm_t)

            ops.write(Text(""))
            if self._last_tool:
                args = f" {self._last_tool_args}" if self._last_tool_args else ""
                t = Text()
                t.append("tool: ", style="bold yellow")
                t.append(f"{self._last_tool}{args}")
                ops.write(t)
            if self._last_tool_result:
                ops.write(self._last_tool_result)
            if self._busy:
                ops.write(Text("â€¦æ‰§è¡Œä¸­ï¼ˆopencode TUIï¼‰", style="dim"))

        def _set_follow(self, follow: bool) -> None:
            self._follow = bool(follow)
            for wid in ("#conversation", "#status", "#ops", "#events"):
                try:
                    self.query_one(wid, _Log).auto_scroll = self._follow
                except Exception:
                    pass

        def action_toggle_follow(self) -> None:
            self._set_follow(not self._follow)
            self.query_one("#events", _Log).write(
                f"[dim]follow={'on' if self._follow else 'off'}[/dim]"
            )

        def action_jump_bottom(self) -> None:
            # å›žåˆ°åº•éƒ¨å¹¶å¼€å¯ follow
            self._set_follow(True)
            for wid in ("#conversation", "#status", "#ops", "#events"):
                try:
                    self.query_one(wid, _Log).scroll_end(animate=False)
                except Exception:
                    pass

        def _render_top_metrics(self) -> str:
            if self._max_tokens > 0:
                pct = (self._llm_prompt / self._max_tokens) * 100 if self._max_tokens else 0.0
                ctx = f"Context: {self._llm_prompt}/{self._max_tokens} ({pct:.0f}%)"
            else:
                ctx = f"Context: {self._llm_prompt}"
            return f"{ctx}    Output: {self._llm_completion}/âˆž    {self._tps:.1f} tokens/sec"

        def _append_event_line(self, et: str, data: dict[str, Any], *, step: int | str | None = None) -> None:
            events = self.query_one("#events", _Log)

            # äº‹ä»¶æ‘˜è¦è¡Œï¼ˆä¸€çœ¼èƒ½çœ‹æ‡‚ + å¯å®šä½ï¼‰
            head = Text()
            head.append(f"{step} " if step is not None else "", style="dim")
            head.append(et, style="bold")

            # ç®€çŸ­æ‘˜è¦å­—æ®µï¼ˆå¯¹è°ƒè¯•æœ€æœ‰ä»·å€¼ï¼‰
            summary = ""
            if et == "state":
                summary = f"state={data.get('state')}"
            elif et == "plan_step_start":
                summary = f"{data.get('idx')}/{data.get('total')} step_id={data.get('step_id')}"
            elif et == "llm_request_params":
                summary = f"model={data.get('model')} api={data.get('api_mode')} messages={data.get('messages_count')}"
            elif et == "llm_usage":
                summary = f"prompt={data.get('prompt_tokens_est')} output={data.get('completion_tokens_est')} elapsed_ms={data.get('elapsed_ms')}"
            elif et == "tool_call_parsed":
                summary = f"tool={data.get('tool')}"
            elif et == "tool_result":
                summary = f"tool={data.get('tool')} ok={data.get('ok')}"

            if summary:
                head.append(" ", style="dim")
                head.append(summary, style="dim")
            events.write(head)

            # å…³é”®äº‹ä»¶ï¼šè¾“å‡ºæ ¼å¼åŒ– JSONï¼ˆå¯æ»šè½®æŸ¥çœ‹å®Œæ•´ç»†èŠ‚ï¼‰
            if et in {"llm_request_params", "llm_usage", "tool_call_parsed", "tool_result", "plan_generated", "replan_generated", "plan_parse_failed"}:
                try:
                    s = json.dumps(data, ensure_ascii=False, default=str, indent=2)
                except Exception:
                    s = str(data)
                if len(s) > 8000:
                    s = s[:7999] + "â€¦"
                events.write(Syntax(s, "json", word_wrap=True, line_numbers=False))

            if self._follow:
                try:
                    events.scroll_end(animate=False)
                except Exception:
                    pass

        def _apply_event(self, ev: dict[str, Any]) -> None:
            et = str(ev.get("event", ""))
            data = ev.get("data", {}) or {}
            if "step" in ev and ev.get("step") is not None:
                self._last_step = ev.get("step")  # type: ignore[assignment]
            self._last_event = et or self._last_event
            trace_id = ev.get("trace_id")

            conversation = self.query_one("#conversation", _Log)
            status = self.query_one("#status", _Log)
            ops = self.query_one("#ops", _Log)

            self._append_event_line(et, data, step=ev.get("step"))

            def _push_block(title: str, lines: list[str], *, color: str = "cyan") -> None:
                """åœ¨å¯¹è¯çª—æ ¼è¾“å‡º Claude Code é£Žæ ¼é˜¶æ®µå—ï¼ˆå¯¹é½ enhanced çš„è§†è§‰è¯­è¨€ï¼‰ã€‚"""
                title = (title or "").strip()
                if not title:
                    return
                conversation.write(Text(f"â”Œâ”€ {title}", style=color))
                for ln in lines:
                    ln = (ln or "").strip()
                    if not ln:
                        continue
                    conversation.write(Text(f"â”‚ {ln}", style=color))
                conversation.write(Text("â””â”€", style=color))
                if self._follow:
                    conversation.scroll_end(animate=False)

            # --- çŠ¶æ€æœº ---
            if et == "state":
                st = str(data.get("state", "")).strip()
                if st:
                    self._state = st
                self._operation = str(data.get("reason") or data.get("step") or data.get("mode") or "è¿è¡Œä¸­")
                self._active_tasks = 1 if self._busy else 0
                self._refresh_header_panel()
                self._refresh_status()
                # å¯¹è¯åŒºï¼šç»™ä¸€æ¡â€œè¿‡ç¨‹è§£é‡Šâ€å—ï¼ˆæ›´åƒ Claude Code çš„å¯è¯»å™äº‹ï¼‰
                self._push_structured_block(
                    title="çŠ¶æ€åˆ‡æ¢",
                    level="progress" if self._state in {"PLANNING", "EXECUTING"} else "info",
                    step=ev.get("step"),
                    ev=et,
                    trace_id=trace_id,
                    summary=f"state={self._state}",
                    decision=str(data.get("reason") or data.get("step") or data.get("mode") or ""),
                )
                return

            # å¼€åœºï¼šé¡¹ç›®è®°å¿†åŠ è½½çŠ¶æ€ï¼ˆå¯¹é½ enhanced çš„â€œé¡¹ç›®è®°å¿†å·²åŠ è½½ï¼ˆCLUDE.mdï¼‰â€å—ï¼‰
            if et == "project_memory":
                # å·²åœ¨ on_mount è¾“å‡ºè¿‡ä¸€æ¬¡ï¼Œé¿å…ç”¨æˆ·è¾“å…¥åŽå†æ¬¡é‡å¤åˆ·å±
                if self._project_memory_shown:
                    return
                loaded = bool(data.get("loaded"))
                path = str(data.get("path", ""))
                truncated = bool(data.get("truncated", False))
                length = data.get("length")
                legacy = bool(data.get("legacy_name", False))
                if loaded:
                    _push_block(
                        "é¡¹ç›®è®°å¿†å·²åŠ è½½ï¼ˆCLUDE.mdï¼‰",
                        [
                            f"path={path}",
                            f"length={length}",
                            f"truncated={truncated}",
                            f"legacy_name={legacy}",
                        ],
                        color="cyan",
                    )
                else:
                    _push_block(
                        "æœªåŠ è½½é¡¹ç›®è®°å¿†ï¼ˆCLUDE.mdï¼‰",
                        [f"path={path}", "åŽŸå› ï¼šæ–‡ä»¶ä¸å­˜åœ¨/ä¸ºç©º/è¯»å–å¤±è´¥"],
                        color="cyan",
                    )
                self._project_memory_shown = True
                return

            # è§„åˆ’/æ‰§è¡Œé˜¶æ®µï¼ˆå¯¹é½ enhancedï¼‰
            if et == "plan_step_start":
                idx = data.get("idx")
                total = data.get("total")
                step_id = data.get("step_id")
                self._state = "EXECUTING"
                self._operation = f"æ‰§è¡Œæ­¥éª¤ {idx}/{total}: {step_id}"
                self._active_tasks = 1 if self._busy else 0
                self._refresh_header_panel()
                self._refresh_status()
                self._push_structured_block(
                    title="æ‰§è¡Œæ­¥éª¤å¼€å§‹",
                    level="progress",
                    step=ev.get("step"),
                    ev=et,
                    trace_id=trace_id,
                    summary=f"{idx}/{total}  step_id={step_id}",
                    decision="å¼€å§‹æ‰§è¡Œæœ¬æ­¥éª¤ï¼›åŽç»­å°†æ ¹æ®æ¨¡åž‹è¾“å‡ºè°ƒç”¨å·¥å…·å¹¶å›žå–‚ç»“æžœã€‚",
                    evidence=[f"step_id={step_id}"],
                )
                return

            if et == "user_message":
                txt = str(data.get("text", "")).strip()
                if txt:
                    t = Text()
                    t.append("you: ", style="bold blue")
                    t.append(txt)
                    conversation.write(t)
                    if self._follow:
                        conversation.scroll_end(animate=False)
                return

            if et in {"intent_classified"}:
                cat = data.get("category")
                conf = data.get("confidence")
                self._push_structured_block(
                    title="æ„å›¾è¯†åˆ«",
                    level="info",
                    step=ev.get("step"),
                    ev=et,
                    trace_id=trace_id,
                    summary=f"category={cat} confidence={conf}",
                    decision="ç”¨äºŽå†³å®šæ˜¯å¦è¿›å…¥ planning é˜¶æ®µï¼Œä»¥åŠå·¥å…·/éªŒè¯ç­–ç•¥çš„ä¼˜å…ˆçº§ã€‚",
                )
                return

            if et in {"planning_llm_request"}:
                self._state = "PLANNING"
                self._operation = "è§„åˆ’ï¼šLLM è¯·æ±‚"
                self._active_tasks = 1
                self._refresh_header_panel()
                self._refresh_status()
                self._push_structured_block(
                    title="è¿›å…¥è§„åˆ’é˜¶æ®µï¼ˆç”Ÿæˆ Planï¼‰",
                    level="progress",
                    step=ev.get("step"),
                    ev=et,
                    trace_id=trace_id,
                    summary=f"attempt={data.get('attempt')}",
                    decision="å°†ä»»åŠ¡æ‹†æˆå¯æ‰§è¡Œæ­¥éª¤ï¼Œé™ä½Žä¸€æ¬¡æ€§é•¿ä¸Šä¸‹æ–‡å¤±è´¥æ¦‚çŽ‡ï¼Œå¹¶æé«˜å¯è¿½æº¯æ€§ã€‚",
                )
                return

            if et in {"plan_generated"}:
                title = str(data.get("title") or "").strip()
                steps = data.get("steps")
                preview = data.get("steps_preview") or []
                evs: list[str] = []
                if isinstance(preview, list):
                    for p in preview[:8]:
                        evs.append(str(p))
                self._push_structured_block(
                    title="è®¡åˆ’å·²ç”Ÿæˆï¼ˆPlanï¼‰",
                    level="success",
                    step=ev.get("step"),
                    ev=et,
                    trace_id=trace_id,
                    summary=f"title={title} steps={steps}",
                    decision="æŽ¥ä¸‹æ¥ä¼šæŒ‰æ­¥éª¤æ‰§è¡Œï¼šæ¯æ­¥ä¼šè§¦å‘ LLMâ†’å·¥å…·â†’å›žå–‚â†’ï¼ˆå¯é€‰ï¼‰éªŒè¯çš„é—­çŽ¯ã€‚",
                    evidence=evs,
                    hint="æ›´å¤šç»“æž„åŒ–ç»†èŠ‚è§â€œäº‹ä»¶â€çª—æ ¼ï¼ˆplan_generated JSONï¼‰ã€‚",
                )
                return

            if et in {"plan_parse_failed"}:
                self._push_structured_block(
                    title="è®¡åˆ’è§£æžå¤±è´¥",
                    level="error",
                    step=ev.get("step"),
                    ev=et,
                    trace_id=trace_id,
                    summary=f"attempt={data.get('attempt')} error={data.get('error')}",
                    decision="å°†è¦æ±‚æ¨¡åž‹ä»…è¾“å‡ºä¸¥æ ¼ JSONï¼Œè§¦å‘é‡è¯•ï¼ˆæˆ–é™çº§åˆ° ReActï¼‰ã€‚",
                    hint="å»ºè®®ç¼©å°ä»»åŠ¡ã€æé«˜ç»“æž„åŒ–çº¦æŸï¼Œæˆ–æŒ‡å®šå…¥å£æ–‡ä»¶ã€‚",
                )
                return

            if et in {"assistant_text", "assistant"}:
                txt = str(data.get("text", "")).strip()
                if txt:
                    t = Text()
                    t.append("assistant: ", style="bold magenta")
                    t.append(txt)
                    conversation.write(t)
                    if self._follow:
                        conversation.scroll_end(animate=False)
                # å¯¹é½ enhancedï¼šassistant_text è§†ä¸ºæœ¬è½®å·²ç»“æŸ
                self._state = "DONE"
                self._operation = "æœ¬è½®ç»“æŸ"
                self._active_tasks = 0
                self._refresh_header_panel()
                self._refresh_status()
                self._refresh_ops()
                return

            if et == "display":
                content = str(data.get("content", "")).strip()
                level = str(data.get("level") or "info")
                title = str(data.get("title") or "Agent è¾“å‡º").strip()
                thought = str(data.get("thought") or "").strip()
                explanation = str(data.get("explanation") or "").strip()
                ev_lines = data.get("evidence")
                evidence: list[str] | None = None
                if isinstance(ev_lines, list):
                    evidence = [str(x) for x in ev_lines if str(x).strip()]
                if content:
                    self._push_structured_block(
                        title=title,
                        level=level,
                        step=ev.get("step"),
                        ev=et,
                        trace_id=trace_id,
                        summary=content,
                        decision=(thought or explanation),
                        evidence=evidence,
                        hint="ï¼ˆdisplay å·¥å…·è¾“å‡ºï¼‰",
                        # display çš„æ ¸å¿ƒä»·å€¼å°±æ˜¯â€œè¿‡ç¨‹å¯è§â€ï¼Œå› æ­¤å¼ºåˆ¶æ˜¾ç¤º Whyï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰
                        force_show_decision=True,
                    )
                return

            if et == "llm_request":
                self._state = "EXECUTING"
                self._operation = "LLM è¯·æ±‚"
                mc = data.get("messages")
                if isinstance(mc, int) and mc >= 0:
                    self._last_llm_messages = mc
                self._active_tasks = 1
                self._refresh_header_panel()
                self._refresh_status()
                self._refresh_ops()
                conversation.write(Text("ðŸ¤– LLM è¯·æ±‚ä¸­...", style="dim"))
                if self._follow:
                    conversation.scroll_end(animate=False)
                return

            if et == "llm_request_params":
                pt = data.get("prompt_tokens_est")
                if isinstance(pt, int) and pt >= 0:
                    self._llm_prompt = pt
                mc = data.get("messages_count")
                if isinstance(mc, int) and mc >= 0:
                    self._last_llm_messages = mc
                self._state = "EXECUTING"
                self._operation = "LLM è¯·æ±‚"
                self._active_tasks = 1
                self._refresh_header_panel()
                self._refresh_status()
                self._refresh_ops()
                self._push_structured_block(
                    title="LLM è¯·æ±‚å‚æ•°",
                    level="info",
                    step=ev.get("step"),
                    ev=et,
                    trace_id=trace_id,
                    summary=f"model={data.get('model')} api={data.get('api_mode')} base_url={data.get('base_url')}",
                    decision=f"temperature={data.get('temperature')} max_tokens={data.get('max_tokens')}",
                    evidence=[
                        f"prompt_tokens_est={data.get('prompt_tokens_est')}",
                        f"messages_count={data.get('messages_count')}",
                    ],
                    hint="å®Œæ•´å‚æ•°è§â€œäº‹ä»¶â€çª—æ ¼ï¼ˆllm_request_params JSONï¼‰ã€‚",
                )
                return

            if et == "llm_usage":
                pt = data.get("prompt_tokens_est")
                if isinstance(pt, int) and pt >= 0:
                    self._llm_prompt = pt
                ct = data.get("completion_tokens_est")
                if isinstance(ct, int) and ct >= 0:
                    self._llm_completion = ct
                elapsed_ms = data.get("elapsed_ms") or 0
                self._tps = (self._llm_completion / elapsed_ms) * 1000 if elapsed_ms else 0.0
                self._state = "EXECUTING"
                self._operation = "LLM è¿”å›ž"
                self._active_tasks = 0
                self._recent_completed.append("LLM")
                self._refresh_header_panel()
                self._refresh_status()
                self._refresh_ops()
                return

            if et == "tool_call_parsed":
                tool = str(data.get("tool", ""))
                args_str = str(data.get("args", {}) or {})
                if len(args_str) > 180:
                    args_str = args_str[:179] + "â€¦"
                self._last_tool = tool
                self._last_tool_args = args_str
                self._state = "EXECUTING"
                self._operation = f"å·¥å…·: {tool}"
                self._active_tasks = 1
                self._refresh_header_panel()
                self._refresh_status()
                self._refresh_ops()
                args = data.get("args", {}) or {}
                evs = self._summarize_tool_args(tool, args if isinstance(args, dict) else {})
                self._push_structured_block(
                    title=f"å·¥å…·è°ƒç”¨: {tool}",
                    level="progress",
                    step=ev.get("step"),
                    ev=et,
                    trace_id=trace_id,
                    summary="æ¨¡åž‹å·²è§£æžå‡ºå·¥å…·è°ƒç”¨ï¼Œå°†è¿›è¡Œç­–ç•¥æ ¡éªŒå¹¶æ‰§è¡Œå·¥å…·ã€‚",
                    decision="å¯¹è¯åŒºä»…å±•ç¤ºå…³é”®å‚æ•°æ‘˜è¦ï¼›è¯¦æƒ…è§â€œäº‹ä»¶/æ“ä½œé¢æ¿â€ã€‚",
                    evidence=evs or [f"args={args_str}"],
                )
                return

            if et == "tool_result":
                tool = str(data.get("tool", ""))
                ok = bool(data.get("ok"))
                err_obj = data.get("error")
                err = str(err_obj or "")
                if len(err) > 160:
                    err = err[:159] + "â€¦"
                icon = "âœ“ " if ok else "âœ— "
                icon_style = "green" if ok else "red"
                tr = Text()
                tr.append(icon, style=icon_style)
                tr.append(tool)
                if err:
                    tr.append("  ")
                    tr.append(err, style="dim")
                self._last_tool_result = tr
                self._state = "EXECUTING"
                self._operation = f"å·¥å…·å®Œæˆ: {tool}"
                self._active_tasks = 0
                self._recent_completed.append(f"{'âœ“' if ok else 'âœ—'} {tool}")
                self._refresh_header_panel()
                self._refresh_status()
                self._refresh_ops()
                level = "success" if ok else "error"
                code = ""
                if isinstance(err_obj, dict):
                    code = str(err_obj.get("code") or "")
                self._push_structured_block(
                    title=f"å·¥å…·ç»“æžœ: {tool}",
                    level=level,
                    step=ev.get("step"),
                    ev=et,
                    trace_id=trace_id,
                    summary=f"ok={ok}" + (f" code={code}" if code else "") + (f" err={err}" if err and not ok else ""),
                    decision="å·¥å…·ç»“æžœå·²å›žå–‚ç»™æ¨¡åž‹ï¼ˆä½œä¸ºåŽç»­æŽ¨ç†ä¾æ®ï¼‰ã€‚",
                    hint="æ›´å®Œæ•´çš„ payload/åŽŸå§‹é”™è¯¯è§â€œäº‹ä»¶/æ“ä½œé¢æ¿â€ã€‚",
                )
                return

            if et in {"policy_deny_tool", "policy_deny_cmd", "denied_by_user"}:
                self._push_structured_block(
                    title="ç­–ç•¥/ç¡®è®¤æ‹¦æˆª",
                    level="error",
                    step=ev.get("step"),
                    ev=et,
                    trace_id=trace_id,
                    summary=str(data),
                    decision="ä¸ºé¿å…å±é™©æ“ä½œï¼Œæœ¬æ¬¡è°ƒç”¨è¢«ç­–ç•¥æˆ–ç”¨æˆ·ç¡®è®¤æ‹’ç»ã€‚",
                    hint="å¦‚éœ€ç»§ç»­ï¼šè°ƒæ•´ allowed_tools/disallowed_tools æˆ–å…³é—­ confirm_write/confirm_execï¼ˆä¸æŽ¨èåœ¨ä¸å¯ä¿¡é¡¹ç›®ä¸­å…³é—­ï¼‰ã€‚",
                )
                return

        def _drain_events(self) -> None:
            drained = 0
            while drained < 200:
                try:
                    ev = q.get_nowait()
                except Empty:
                    break
                self._apply_event(ev)
                drained += 1

        def on_input_submitted(self, event: Input.Submitted) -> None:
            txt = (event.value or "").strip()
            self.query_one("#input", Input).value = ""
            if not txt:
                return
            if self._busy:
                self.query_one("#events", _Log).write("[yellow]å½“å‰æ­£åœ¨æ‰§è¡Œä¸Šä¸€æ¡è¯·æ±‚ï¼Œè¯·ç¨å€™â€¦[/yellow]")
                return
            if txt.lower() in {"exit", "quit", "/exit", "/quit"}:
                self.exit()
                return

            # å…ˆå†™å…¥æœ¬åœ°å¯¹è¯æ¡†ï¼ˆä¸Ž AgentLoop çš„ user_message äº‹ä»¶ä¿æŒä¸€è‡´ï¼‰
            try:
                q.put_nowait({"event": "user_message", "data": {"text": txt}})
            except Exception:
                pass

            self._busy = True

            def _worker() -> None:
                def _confirm(_msg: str) -> bool:
                    # è¯´æ˜Žï¼šTUI ç‰ˆæš‚æœªå®žçŽ°äº¤äº’ç¡®è®¤ï¼ˆModalï¼‰ï¼Œå…ˆé»˜è®¤æ‹’ç»ï¼Œé¿å…å¡ä½ç»ˆç«¯è¾“å…¥ã€‚
                    try:
                        q.put_nowait(
                            {
                                "event": "display",
                                "data": {
                                    "content": "TUI(opencode) æ¨¡å¼æš‚ä¸æ”¯æŒäº¤äº’ç¡®è®¤(confirm)ã€‚å¦‚éœ€å†™æ–‡ä»¶/æ‰§è¡Œå‘½ä»¤ï¼Œè¯·ç”¨ classic/enhancedï¼Œæˆ–ä¸´æ—¶å…³é—­ confirm_write/confirm_execã€‚",
                                    "level": "warning",
                                },
                            }
                        )
                    except Exception:
                        pass
                    return False

                def _on_event(e: dict[str, Any]) -> None:
                    try:
                        q.put_nowait({"event": e.get("event"), "data": e.get("data", {}) or {}, "step": e.get("step")})
                    except Exception:
                        pass

                try:
                    run_turn(txt, _confirm, _on_event)
                finally:
                    self._busy = False

            Thread(target=_worker, daemon=True).start()

    OpencodeTUI().run()



