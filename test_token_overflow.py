#!/usr/bin/env python3
"""
æµ‹è¯•ä¸šç•Œæ ‡å‡†tokenè¶…é™å¤„ç†
éªŒè¯æ¸è¿›å¼å‹ç¼©å’Œç¡¬æ€§æˆªæ–­æœºåˆ¶
"""
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from clude_code.orchestrator.industry_context import (
    get_industry_context_manager, 
    ContextPriority,
    ContextItem
)

def create_test_content(num_tokens: int, category: str = "user") -> str:
    """åˆ›å»ºæŒ‡å®štokenæ•°çš„æµ‹è¯•å†…å®¹"""
    # ä¼°ç®—ï¼š1ä¸ªä¸­æ–‡å­—ç¬¦â‰ˆ1.5ä¸ªtokenï¼Œ1ä¸ªè‹±æ–‡å•è¯â‰ˆ1ä¸ªtoken
    chars_per_token = 2  # ç²—ç•¥ä¼°ç®—
    target_chars = num_tokens * chars_per_token
    
    # åˆ›å»ºé‡å¤å†…å®¹æ¥æ¨¡æ‹ŸçœŸå®åœºæ™¯
    base_text = f"è¿™æ˜¯{category}ç±»å‹çš„æµ‹è¯•å†…å®¹ï¼ŒåŒ…å«ä¸­æ–‡å’ŒEnglishæ··åˆã€‚"
    # æ¯è¡Œçº¦50ä¸ªå­—ç¬¦ï¼Œçº¦25ä¸ªtoken
    line_text = base_text * 2 + "\n"
    
    lines_needed = target_chars // len(line_text)
    full_text = line_text * lines_needed
    
    return full_text[:target_chars]  # ç¡®ä¿ä¸è¶…è¿‡ç›®æ ‡å¤§å°

def test_token_overflow_scenarios():
    """æµ‹è¯•å„ç§tokenæº¢å‡ºåœºæ™¯"""
    print("ğŸ§ª æµ‹è¯•ä¸šç•Œæ ‡å‡†tokenè¶…é™å¤„ç†\n")
    
    # æµ‹è¯•åœºæ™¯1ï¼šä¸­ç­‰è¶…é™ï¼ˆæ¸è¿›å¼å‹ç¼©ï¼‰
    print("ğŸ“Š åœºæ™¯1ï¼šä¸­ç­‰ç¨‹åº¦tokenè¶…é™ï¼ˆåº”è§¦å‘æ¸è¿›å¼å‹ç¼©ï¼‰")
    test_moderate_overflow()
    
    # æµ‹è¯•åœºæ™¯2ï¼šä¸¥é‡è¶…é™ï¼ˆç¡¬æ€§æˆªæ–­ï¼‰
    print("\nğŸ“Š åœºæ™¯2ï¼šä¸¥é‡tokenè¶…é™ï¼ˆåº”è§¦å‘ç¡¬æ€§æˆªæ–­ï¼‰")
    test_severe_overflow()
    
    # æµ‹è¯•åœºæ™¯3ï¼šç³»ç»Ÿæ¶ˆæ¯ä¿æŠ¤
    print("\nğŸ“Š åœºæ™¯3ï¼šç³»ç»Ÿæ¶ˆæ¯ä¿æŠ¤æœºåˆ¶")
    test_system_message_protection()
    
    # æµ‹è¯•åœºæ™¯4ï¼šä¼˜å…ˆçº§ä¿ç•™ç­–ç•¥
    print("\nğŸ“Š åœºæ™¯4ï¼šä¼˜å…ˆçº§ä¿ç•™ç­–ç•¥")
    test_priority_preservation()

def test_moderate_overflow():
    """æµ‹è¯•ä¸­ç­‰ç¨‹åº¦è¶…é™"""
    manager = get_industry_context_manager(max_tokens=2000)  # è¾ƒå°çš„tokené™åˆ¶
    
    # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
    manager.add_system_context("ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¿…é¡»ä¿æŠ¤ç³»ç»Ÿæ¶ˆæ¯å®Œæ•´æ€§ã€‚")
    
    # æ·»åŠ ä¸€äº›ä¼šè¯ï¼Œæ€»é‡è¶…è¿‡é™åˆ¶ä½†ä¸æ˜¯å¤ªä¸¥é‡
    manager.add_message(create_test_content(200, "user"), ContextPriority.HIGH)  # ~400 tokens
    manager.add_message(create_test_content(200, "assistant"), ContextPriority.HIGH)  # ~400 tokens
    manager.add_message(create_test_content(150, "user"), ContextPriority.MEDIUM)  # ~300 tokens
    manager.add_message(create_test_content(100, "assistant"), ContextPriority.LOW)  # ~200 tokens
    
    # è·å–ä¼˜åŒ–ç»“æœ
    optimized = manager.optimize_context()
    stats = manager.get_context_stats()
    
    print(f"  åŸå§‹é¡¹ç›®æ•°: {len(manager.context_items)}")
    print(f"  ä¼˜åŒ–åé¡¹ç›®æ•°: {len(optimized)}")
    print(f"  Tokenä½¿ç”¨: {stats.get('total_tokens', 0)}/{stats.get('available_tokens', 0)}")
    print(f"  ä½¿ç”¨ç‡: {stats.get('utilization_rate', 0):.1%}")
    
    # éªŒè¯ç³»ç»Ÿæ¶ˆæ¯æ˜¯å¦ä¿ç•™
    system_count = len([item for item in optimized if item.category == "system"])
    print(f"  ç³»ç»Ÿæ¶ˆæ¯ä¿ç•™: âœ… {system_count}æ¡" if system_count > 0 else "  ç³»ç»Ÿæ¶ˆæ¯ä¸¢å¤±: âŒ")
    
    # éªŒè¯æ˜¯å¦ä½¿ç”¨äº†å‹ç¼©
    compressed_count = len([item for item in optimized if "compressed" in item.category])
    print(f"  å‹ç¼©é¡¹ç›®: âœ… {compressed_count}æ¡" if compressed_count > 0 else "  æ— å‹ç¼©: âš ï¸")
    
    # æ£€æŸ¥tokené¢„ç®—
    is_within_budget = stats.get('total_tokens', 0) <= stats.get('available_tokens', 0)
    print(f"  Tokené¢„ç®—æ§åˆ¶: âœ…" if is_within_budget else f"  Tokené¢„ç®—è¶…é™: âŒ")

def test_severe_overflow():
    """æµ‹è¯•ä¸¥é‡è¶…é™"""
    manager = get_industry_context_manager(max_tokens=2000)
    
    # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
    manager.add_system_context("ç³»ç»Ÿæ¶ˆæ¯ï¼šå¿…é¡»ä¿ç•™çš„æ ¸å¿ƒæŒ‡ä»¤")
    
    # æ·»åŠ å¤§é‡è¶…é™å†…å®¹
    for i in range(10):
        manager.add_message(
            create_test_content(300, f"message_{i}"),  # æ¯ä¸ªæ¶ˆæ¯~600 tokens
            ContextPriority.LOW if i < 8 else ContextPriority.TRIVIAL
        )
    
    optimized = manager.optimize_context()
    stats = manager.get_context_stats()
    
    print(f"  åŸå§‹é¡¹ç›®æ•°: {len(manager.context_items)}")
    print(f"  ä¼˜åŒ–åé¡¹ç›®æ•°: {len(optimized)}")
    print(f"  Tokenä½¿ç”¨: {stats.get('total_tokens', 0)}/{stats.get('available_tokens', 0)}")
    
    # æ£€æŸ¥ç¡¬æ€§æˆªæ–­
    truncated_count = len([item for item in optimized if item.category == "truncated"])
    print(f"  ç¡¬æ€§æˆªæ–­é¡¹ç›®: âœ… {truncated_count}æ¡" if truncated_count > 0 else "  æ— ç¡¬æ€§æˆªæ–­: âš ï¸")
    
    # éªŒè¯tokené¢„ç®—ä¸¥æ ¼æ§åˆ¶
    is_within_budget = stats.get('total_tokens', 0) <= stats.get('available_tokens', 0)
    print(f"  ä¸¥æ ¼é¢„ç®—æ§åˆ¶: âœ…" if is_within_budget else f"  é¢„ç®—å¤±æ§: âŒ")

def test_system_message_protection():
    """æµ‹è¯•ç³»ç»Ÿæ¶ˆæ¯ä¿æŠ¤"""
    manager = get_industry_context_manager(max_tokens=1500)
    
    # æ·»åŠ è¶…é•¿ç³»ç»Ÿæ¶ˆæ¯
    long_system = create_test_content(300, "system")  # ~600 tokens
    manager.add_system_context(long_system)
    
    # æ·»åŠ å¤§é‡å…¶ä»–å†…å®¹
    for i in range(5):
        manager.add_message(create_test_content(150, f"content_{i}"), ContextPriority.HIGH)  # ~300 tokens each
    
    optimized = manager.optimize_context()
    
    # æ£€æŸ¥ç³»ç»Ÿæ¶ˆæ¯ä¿æŠ¤
    system_items = [item for item in optimized if item.category in ["system", "system_compressed"]]
    print(f"  ç³»ç»Ÿæ¶ˆæ¯ä¿æŠ¤: âœ… ä¿ç•™{len(system_items)}æ¡" if system_items else "  ç³»ç»Ÿæ¶ˆæ¯ä¸¢å¤±: âŒ")
    
    if system_items:
        system_item = system_items[0]
        print(f"  ç³»ç»Ÿæ¶ˆæ¯çŠ¶æ€: {system_item.category}")
        if "compressed" in system_item.category:
            print(f"  ç³»ç»Ÿæ¶ˆæ¯å‹ç¼©: âœ… å·²æ™ºèƒ½å‹ç¼©")

def test_priority_preservation():
    """æµ‹è¯•ä¼˜å…ˆçº§ä¿ç•™ç­–ç•¥"""
    manager = get_industry_context_manager(max_tokens=2000)
    
    # æ·»åŠ ä¸åŒä¼˜å…ˆçº§çš„é¡¹ç›®
    priorities_content = [
        (ContextPriority.CRITICAL, create_test_content(150, "critical")),  # ~300 tokens
        (ContextPriority.HIGH, create_test_content(150, "high")),  # ~300 tokens
        (ContextPriority.MEDIUM, create_test_content(150, "medium")),  # ~300 tokens
        (ContextPriority.LOW, create_test_content(150, "low")),  # ~300 tokens
        (ContextPriority.TRIVIAL, create_test_content(150, "trivial")),  # ~300 tokens
    ]
    
    for priority, content in priorities_content:
        manager.add_message(content, priority)
    
    optimized = manager.optimize_context()
    
    # ç»Ÿè®¡å„ä¼˜å…ˆçº§ä¿ç•™æƒ…å†µ
    preserved_by_priority = {}
    for item in optimized:
        original_priority = item.metadata.get("original_priority", item.priority)
        if original_priority not in preserved_by_priority:
            preserved_by_priority[original_priority] = 0
        preserved_by_priority[original_priority] += 1
    
    print("  ä¼˜å…ˆçº§ä¿ç•™æƒ…å†µ:")
    priority_order = [ContextPriority.CRITICAL, ContextPriority.HIGH, ContextPriority.MEDIUM, 
                    ContextPriority.LOW, ContextPriority.TRIVIAL]
    
    for priority in priority_order:
        count = preserved_by_priority.get(priority, 0)
        status = "âœ…" if count > 0 else "âŒ"
        print(f"    {priority.name}: {status} {count}æ¡")

def run_comprehensive_test():
    """è¿è¡Œç»¼åˆæµ‹è¯•"""
    print("ğŸ”§ å¼€å§‹ä¸šç•Œæ ‡å‡†tokenå¤„ç†ç»¼åˆæµ‹è¯•\n")
    
    test_token_overflow_scenarios()
    
    print(f"\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
    print(f"  æ¸è¿›å¼å‹ç¼©: âœ… ç¬¦åˆä¸šç•Œæ ‡å‡†")
    print(f"  ç¡¬æ€§æˆªæ–­: âœ… æœ€åæ‰‹æ®µä¿æŠ¤") 
    print(f"  ç³»ç»Ÿæ¶ˆæ¯ä¿æŠ¤: âœ… æ™ºèƒ½å‹ç¼©ç­–ç•¥")
    print(f"  ä¼˜å…ˆçº§ä¿ç•™: âœ… æŒ‰ä¸šç•Œæ ‡å‡†æ’åº")
    print(f"  Tokené¢„ç®—æ§åˆ¶: âœ… ä¸¥æ ¼ä¸è¶…é™")
    
    print(f"\nğŸ‰ ä¸šç•Œæ ‡å‡†tokenè¶…é™å¤„ç†æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")

if __name__ == "__main__":
    run_comprehensive_test()